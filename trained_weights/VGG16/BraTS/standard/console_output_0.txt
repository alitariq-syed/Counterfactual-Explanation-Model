save_path:  ./trained_weights/VGG16/BraTS/standard
resuming training

 Namespace(alter_class=0, alter_class_2=0, analysis_class=0, analyze_filter_importance=False, cfe_epochs=100, choose_subclass=True, counterfactual_PP=True, create_counterfactual_combined=True, dataset='BraTS', filter_category_method='own_reduce_loss', filter_modified_directly=True, filter_visualization=True, find_filter_class=False, find_global_filters=False, fine_tune=False, fixed_classes=True, fixed_classes_reduce_loss=True, full_standard=True, high_capacity_model=True, imagenet_weights=True, interpretable=False, l1_weight=2, load_counterfactual_net=True, loss_compute=True, model='VGG16/', resume=True, resume_counterfactual_net=False, save_directory='./trained_weights/', save_filter_fmap=False, save_filter_importance=False, save_logFile=True, save_path='./trained_weights/VGG16/BraTS/standard', save_top_layer=True, test=False, test_counterfactual_net=False, test_filter_importance=False, train=False, train_counterfactual_net=True, train_using_builtin_fit_method=True, visualize_fmaps=False) 

batch_size:  32
BraTS 2020 dataset
num classes: 2
using imagenet_weights
Found 16059 images belonging to 1 classes.
Found 1784 images belonging to 1 classes.
Found 16059 images belonging to 1 classes.
Found 1784 images belonging to 1 classes.
Found 4398 images belonging to 1 classes.
Found 4398 images belonging to 1 classes.
loading VGG model
using VGG16 imagenet weights for BraTS dataset
input_1
block1_conv1
block1_conv2
block1_pool
block2_conv1
block2_conv2
block2_pool
block3_conv1
block3_conv2
block3_conv3
block3_pool
block4_conv1
block4_conv2
block4_conv3
block4_pool
block5_conv1
block5_conv2
block5_conv3
block5_pool
block1_conv1 		 (None, 240, 240, 64)
block1_conv2 		 (None, 240, 240, 64)
block2_conv1 		 (None, 120, 120, 128)
block2_conv2 		 (None, 120, 120, 128)
block3_conv1 		 (None, 60, 60, 256)
block3_conv2 		 (None, 60, 60, 256)
block3_conv3 		 (None, 60, 60, 256)
block4_conv1 		 (None, 30, 30, 512)
block4_conv2 		 (None, 30, 30, 512)
block4_conv3 		 (None, 30, 30, 512)
block5_conv1 		 (None, 15, 15, 512)
block5_conv2 		 (None, 15, 15, 512)
block5_conv3 		 (None, 15, 15, 512)
total neurons:  4224
Model: "base_model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 240, 240, 3) 0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 240, 240, 64) 1792        input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 240, 240, 64) 36928       block1_conv1[0][0]               
__________________________________________________________________________________________________
block1_pool (MaxPooling2D)      (None, 120, 120, 64) 0           block1_conv2[0][0]               
__________________________________________________________________________________________________
block2_conv1 (Conv2D)           (None, 120, 120, 128 73856       block1_pool[0][0]                
__________________________________________________________________________________________________
block2_conv2 (Conv2D)           (None, 120, 120, 128 147584      block2_conv1[0][0]               
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 60, 60, 128)  0           block2_conv2[0][0]               
__________________________________________________________________________________________________
block3_conv1 (Conv2D)           (None, 60, 60, 256)  295168      block2_pool[0][0]                
__________________________________________________________________________________________________
block3_conv2 (Conv2D)           (None, 60, 60, 256)  590080      block3_conv1[0][0]               
__________________________________________________________________________________________________
block3_conv3 (Conv2D)           (None, 60, 60, 256)  590080      block3_conv2[0][0]               
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 30, 30, 256)  0           block3_conv3[0][0]               
__________________________________________________________________________________________________
block4_conv1 (Conv2D)           (None, 30, 30, 512)  1180160     block3_pool[0][0]                
__________________________________________________________________________________________________
block4_conv2 (Conv2D)           (None, 30, 30, 512)  2359808     block4_conv1[0][0]               
__________________________________________________________________________________________________
block4_conv3 (Conv2D)           (None, 30, 30, 512)  2359808     block4_conv2[0][0]               
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 15, 15, 512)  0           block4_conv3[0][0]               
__________________________________________________________________________________________________
block5_conv1 (Conv2D)           (None, 15, 15, 512)  2359808     block4_pool[0][0]                
__________________________________________________________________________________________________
block5_conv2 (Conv2D)           (None, 15, 15, 512)  2359808     block5_conv1[0][0]               
__________________________________________________________________________________________________
block5_conv3 (Conv2D)           (None, 15, 15, 512)  2359808     block5_conv2[0][0]               
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 7, 7, 512)    0           block5_conv3[0][0]               
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 512)          0           max_pooling2d[0][0]              
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 512)]        0                                            
__________________________________________________________________________________________________
tf.math.multiply (TFOpLambda)   (None, 512)          0           global_average_pooling2d[0][0]   
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            1026        tf.math.multiply[0][0]           
__________________________________________________________________________________________________
activation (Activation)         (None, 2)            0           dense[0][0]                      
==================================================================================================
Total params: 14,715,714
Trainable params: 1,026
Non-trainable params: 14,714,688
__________________________________________________________________________________________________
weights loaded
threshold:  0.5
l1 weight:  2
training CF model for alter class:  non_tumor
Training CF model for PPs
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 240, 240, 3) 0                                            
__________________________________________________________________________________________________
counterfactual_model (Functiona (None, 512)          14977344    input_3[0][0]                    
__________________________________________________________________________________________________
base_model (Functional)         [(None, 2), (None, 1 14715714    input_3[0][0]                    
                                                                 counterfactual_model[0][0]       
==================================================================================================
Total params: 14,978,370
Trainable params: 262,656
Non-trainable params: 14,715,714
__________________________________________________________________________________________________
training for fixed alter class:  non_tumor
  0%|          | 0/502 [00:00<?, ?it/s]epoch 0: 100%|##########| 502/502 [02:56<00:00,  2.84it/s, acc=1, loss=[0.07761746, 1.6221268, -0.04284002, 0.0, 43.223686, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 1: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09143714, 0.20888941, -0.038466685, 0.0, 5.96893, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 2: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09126214, 0.118661866, -0.038653344, 0.0, 3.3832011, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 3: 100%|##########| 502/502 [02:42<00:00,  3.08it/s, acc=1, loss=[0.09099257, 0.08415271, -0.038793527, 0.0, 2.3849463, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 4: 100%|##########| 502/502 [02:43<00:00,  3.06it/s, acc=1, loss=[0.091026984, 0.06575877, -0.038816653, 0.0, 1.8511118, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 5: 100%|##########| 502/502 [02:43<00:00,  3.08it/s, acc=1, loss=[0.090975255, 0.054503314, -0.03885853, 0.0, 1.5227561, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 6: 100%|##########| 502/502 [02:42<00:00,  3.08it/s, acc=1, loss=[0.09092912, 0.0471214, -0.03888939, 0.0, 1.3068997, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 7: 100%|##########| 502/502 [02:42<00:00,  3.08it/s, acc=1, loss=[0.0908675, 0.04185885, -0.038920853, 0.0, 1.1522474, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 8: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.09088034, 0.037735626, -0.03893301, 0.0, 1.0311693, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 9: 100%|##########| 502/502 [02:41<00:00,  3.11it/s, acc=1, loss=[0.09083964, 0.03457141, -0.038955946, 0.0, 0.93737316, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 10: 100%|##########| 502/502 [02:44<00:00,  3.06it/s, acc=1, loss=[0.09088639, 0.0320759, -0.038953148, 0.0, 0.8649845, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 11: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.090891965, 0.030132927, -0.038963508, 0.0, 0.8074323, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 12: 100%|##########| 502/502 [02:41<00:00,  3.12it/s, acc=1, loss=[0.09087926, 0.02834087, -0.038978416, 0.0, 0.75421697, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 13: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.09089121, 0.026940906, -0.03898495, 0.0, 0.712903, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 14: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.090890385, 0.025657121, -0.03899379, 0.0, 0.6746602, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 15: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.09090346, 0.024545172, -0.038996294, 0.0, 0.64163023, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 16: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.090878345, 0.023577088, -0.03900924, 0.0, 0.6123838, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 17: 100%|##########| 502/502 [02:39<00:00,  3.14it/s, acc=1, loss=[0.09094782, 0.022671087, -0.038995277, 0.0, 0.58613, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 18: 100%|##########| 502/502 [02:42<00:00,  3.08it/s, acc=1, loss=[0.0909043, 0.022035517, -0.039014563, 0.0, 0.56648636, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 19: 100%|##########| 502/502 [02:43<00:00,  3.06it/s, acc=1, loss=[0.09093769, 0.021360781, -0.03901023, 0.0, 0.54672974, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 20: 100%|##########| 502/502 [02:43<00:00,  3.08it/s, acc=1, loss=[0.090989284, 0.020743232, -0.039003048, 0.0, 0.5285525, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 21: 100%|##########| 502/502 [02:42<00:00,  3.08it/s, acc=1, loss=[0.0909795, 0.020179745, -0.039011195, 0.0, 0.5112236, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 22: 100%|##########| 502/502 [02:44<00:00,  3.06it/s, acc=1, loss=[0.0909956, 0.019693721, -0.03901206, 0.0, 0.49667534, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 23: 100%|##########| 502/502 [02:41<00:00,  3.10it/s, acc=1, loss=[0.09097451, 0.019290252, -0.039022658, 0.0, 0.4839692, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 24: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.09098887, 0.01885936, -0.03902328, 0.0, 0.47103482, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 25: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.09103908, 0.018434068, -0.0390127, 0.0, 0.45876908, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 26: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.091051385, 0.01801985, -0.0390133, 0.0, 0.44626817, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 27: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.091047995, 0.017760808, -0.039017137, 0.0, 0.438164, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 28: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.091037795, 0.017481413, -0.039023366, 0.0, 0.42952955, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 29: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09104972, 0.017188067, -0.03902292, 0.0, 0.42062077, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 30: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09106165, 0.016928596, -0.039022822, 0.0, 0.4129362, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 31: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09111123, 0.01663563, -0.039010543, 0.0, 0.40485972, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 32: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09109442, 0.016432235, -0.03901923, 0.0, 0.39824498, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 33: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09110275, 0.016205044, -0.03901972, 0.0, 0.39134666, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 34: 100%|##########| 502/502 [02:42<00:00,  3.10it/s, acc=1, loss=[0.09108533, 0.016034177, -0.039028484, 0.0, 0.385721, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 35: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.091135986, 0.015822921, -0.039017536, 0.0, 0.37996164, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 36: 100%|##########| 502/502 [02:43<00:00,  3.06it/s, acc=1, loss=[0.09113367, 0.015674071, -0.039021272, 0.0, 0.37510374, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 37: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.091131195, 0.015538263, -0.03902497, 0.0, 0.37076923, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 38: 100%|##########| 502/502 [02:42<00:00,  3.08it/s, acc=1, loss=[0.091145225, 0.015393732, -0.039023206, 0.0, 0.36657536, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 39: 100%|##########| 502/502 [02:43<00:00,  3.06it/s, acc=1, loss=[0.0911307, 0.015279243, -0.039030124, 0.0, 0.36257976, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 40: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.091156185, 0.015111726, -0.039025284, 0.0, 0.35778645, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 41: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09118358, 0.014963647, -0.03901934, 0.0, 0.353724, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 42: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.091167845, 0.014872058, -0.039025523, 0.0, 0.35057685, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 43: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.091185294, 0.014741127, -0.03902286, 0.0, 0.3467911, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 44: 100%|##########| 502/502 [02:41<00:00,  3.11it/s, acc=1, loss=[0.09117927, 0.0146486405, -0.039027713, 0.0, 0.3436601, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 45: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.0911879, 0.014535939, -0.039026525, 0.0, 0.34034464, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 46: 100%|##########| 502/502 [02:44<00:00,  3.06it/s, acc=1, loss=[0.09123286, 0.014347328, -0.039014995, 0.0, 0.3352239, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 47: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09120001, 0.014285108, -0.03902747, 0.0, 0.3324503, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 48: 100%|##########| 502/502 [02:44<00:00,  3.06it/s, acc=1, loss=[0.09123014, 0.014150906, -0.039020978, 0.0, 0.32864144, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 49: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.09123055, 0.014070582, -0.039022636, 0.0, 0.3260223, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 50: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.091235526, 0.014010189, -0.039024126, 0.0, 0.32411328, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 51: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.09122543, 0.013966764, -0.039028212, 0.0, 0.3225916, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 52: 100%|##########| 502/502 [02:42<00:00,  3.09it/s, acc=1, loss=[0.09121668, 0.013889929, -0.039031852, 0.0, 0.32014766, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 53: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.0912778, 0.013736915, -0.039016653, 0.0, 0.3162028, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 54: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.091239676, 0.013704305, -0.039028063, 0.0, 0.31474334, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 55: 100%|##########| 502/502 [02:42<00:00,  3.08it/s, acc=1, loss=[0.09125268, 0.013622159, -0.03902721, 0.0, 0.3120596, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 56: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.091261715, 0.013550814, -0.039026268, 0.0, 0.30988085, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 57: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.09126952, 0.013480986, -0.03902558, 0.0, 0.3077874, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 58: 100%|##########| 502/502 [02:41<00:00,  3.11it/s, acc=1, loss=[0.09127947, 0.013400625, -0.039024334, 0.0, 0.3053365, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 59: 100%|##########| 502/502 [02:42<00:00,  3.08it/s, acc=1, loss=[0.09128036, 0.013340065, -0.03902485, 0.0, 0.30353817, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 60: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.091292955, 0.013261363, -0.039023727, 0.0, 0.301115, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 61: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.09130818, 0.013190716, -0.039020102, 0.0, 0.299146, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 62: 100%|##########| 502/502 [02:42<00:00,  3.09it/s, acc=1, loss=[0.09129742, 0.013155751, -0.039024163, 0.0, 0.2978272, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 63: 100%|##########| 502/502 [02:43<00:00,  3.06it/s, acc=1, loss=[0.091296166, 0.013115632, -0.039026022, 0.0, 0.29648075, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 64: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09130024, 0.013048248, -0.039025348, 0.0, 0.29453942, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 65: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09130446, 0.013007546, -0.039024316, 0.0, 0.29344198, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 66: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09131823, 0.012955743, -0.039022308, 0.0, 0.2918857, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 67: 100%|##########| 502/502 [02:44<00:00,  3.05it/s, acc=1, loss=[0.091325544, 0.012890825, -0.039021168, 0.0, 0.28994438, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 68: 100%|##########| 502/502 [02:43<00:00,  3.06it/s, acc=1, loss=[0.091310054, 0.012875304, -0.03902773, 0.0, 0.28902677, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 69: 100%|##########| 502/502 [02:41<00:00,  3.10it/s, acc=1, loss=[0.09132615, 0.012814144, -0.03902415, 0.0, 0.28740823, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 70: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09132936, 0.012760837, -0.03902433, 0.0, 0.28572744, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 71: 100%|##########| 502/502 [02:43<00:00,  3.08it/s, acc=1, loss=[0.0913479, 0.0126916785, -0.03902001, 0.0, 0.28385532, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 72: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09133144, 0.012668356, -0.039025776, 0.0, 0.28274634, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 73: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09132265, 0.0126269, -0.03903002, 0.0, 0.28127998, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 74: 100%|##########| 502/502 [02:41<00:00,  3.10it/s, acc=1, loss=[0.09134483, 0.012555106, -0.039024465, 0.0, 0.27928793, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 75: 100%|##########| 502/502 [02:43<00:00,  3.08it/s, acc=1, loss=[0.09134528, 0.012518181, -0.039026313, 0.0, 0.27796915, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 76: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.091344185, 0.01247824, -0.03902767, 0.0, 0.2769178, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 77: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.09134198, 0.01245334, -0.039030015, 0.0, 0.2758872, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 78: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.09134274, 0.012407292, -0.039031476, 0.0, 0.27442774, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 79: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.09134976, 0.01236561, -0.03903085, 0.0, 0.27305132, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 80: 100%|##########| 502/502 [02:42<00:00,  3.09it/s, acc=1, loss=[0.091353476, 0.0123398695, -0.039030787, 0.0, 0.27220285, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 81: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.091349274, 0.012321285, -0.039032463, 0.0, 0.27154806, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 82: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09136946, 0.012271091, -0.039029468, 0.0, 0.26993877, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 83: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09136638, 0.012241229, -0.03903137, 0.0, 0.26884592, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 84: 100%|##########| 502/502 [02:43<00:00,  3.08it/s, acc=1, loss=[0.09137644, 0.012189945, -0.039028425, 0.0, 0.26746026, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 85: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09137198, 0.01216022, -0.039031237, 0.0, 0.26639047, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 86: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09137053, 0.012130105, -0.039032966, 0.0, 0.26524687, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 87: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09136425, 0.01211381, -0.0390351, 0.0, 0.2647212, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 88: 100%|##########| 502/502 [02:41<00:00,  3.10it/s, acc=1, loss=[0.09137103, 0.012079683, -0.03903429, 0.0, 0.2636906, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 89: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.09136235, 0.012064477, -0.03903627, 0.0, 0.26312575, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 90: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.09136142, 0.0120357005, -0.03903722, 0.0, 0.26215738, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 91: 100%|##########| 502/502 [02:41<00:00,  3.10it/s, acc=1, loss=[0.09137605, 0.012003046, -0.03903357, 0.0, 0.2614219, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 92: 100%|##########| 502/502 [02:43<00:00,  3.07it/s, acc=1, loss=[0.09136635, 0.0120001, -0.039038483, 0.0, 0.26086625, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 93: 100%|##########| 502/502 [02:42<00:00,  3.10it/s, acc=1, loss=[0.09137637, 0.011953532, -0.03903543, 0.0, 0.25969502, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 94: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.09137555, 0.01192518, -0.0390365, 0.0, 0.25878432, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 95: 100%|##########| 502/502 [02:40<00:00,  3.12it/s, acc=1, loss=[0.091385946, 0.011891316, -0.039034624, 0.0, 0.25776523, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 96: 100%|##########| 502/502 [02:40<00:00,  3.13it/s, acc=1, loss=[0.09138239, 0.011862464, -0.039036162, 0.0, 0.25679228, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 97: 100%|##########| 502/502 [02:41<00:00,  3.11it/s, acc=1, loss=[0.0913764, 0.011848275, -0.03903855, 0.0, 0.25615823, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 98: 100%|##########| 502/502 [02:41<00:00,  3.11it/s, acc=1, loss=[0.09137417, 0.01183304, -0.03903999, 0.0, 0.25558645, 0.0]]
  0%|          | 0/502 [00:00<?, ?it/s]epoch 99: 100%|##########| 502/502 [02:42<00:00,  3.08it/s, acc=1, loss=[0.091375366, 0.011809758, -0.03903883, 0.0, 0.2550723, 0.0]]
