save_path:  ./trained_weights/VGG16/BraTS/standard
resuming training

 Namespace(alter_class=1, alter_class_2=0, analysis_class=0, analyze_filter_importance=False, cfe_epochs=100, choose_subclass=True, counterfactual_PP=True, create_counterfactual_combined=True, dataset='BraTS', filter_category_method='own_reduce_loss', filter_modified_directly=True, filter_visualization=True, find_filter_class=False, find_global_filters=False, fine_tune=False, fixed_classes=True, fixed_classes_reduce_loss=True, full_standard=True, high_capacity_model=True, imagenet_weights=True, interpretable=False, l1_weight=2, load_counterfactual_net=True, loss_compute=True, model='VGG16/', resume=True, resume_counterfactual_net=False, save_directory='./trained_weights/', save_filter_fmap=False, save_filter_importance=False, save_logFile=True, save_path='./trained_weights/VGG16/BraTS/standard', save_top_layer=True, test=False, test_counterfactual_net=False, test_filter_importance=False, train=False, train_counterfactual_net=True, train_using_builtin_fit_method=True, visualize_fmaps=False) 

batch_size:  32
BraTS 2020 dataset
num classes: 2
using imagenet_weights
Found 17365 images belonging to 1 classes.
Found 1929 images belonging to 1 classes.
Found 17365 images belonging to 1 classes.
Found 1929 images belonging to 1 classes.
Found 4974 images belonging to 1 classes.
Found 4974 images belonging to 1 classes.
loading VGG model
using VGG16 imagenet weights for BraTS dataset
input_1
block1_conv1
block1_conv2
block1_pool
block2_conv1
block2_conv2
block2_pool
block3_conv1
block3_conv2
block3_conv3
block3_pool
block4_conv1
block4_conv2
block4_conv3
block4_pool
block5_conv1
block5_conv2
block5_conv3
block5_pool
block1_conv1 		 (None, 240, 240, 64)
block1_conv2 		 (None, 240, 240, 64)
block2_conv1 		 (None, 120, 120, 128)
block2_conv2 		 (None, 120, 120, 128)
block3_conv1 		 (None, 60, 60, 256)
block3_conv2 		 (None, 60, 60, 256)
block3_conv3 		 (None, 60, 60, 256)
block4_conv1 		 (None, 30, 30, 512)
block4_conv2 		 (None, 30, 30, 512)
block4_conv3 		 (None, 30, 30, 512)
block5_conv1 		 (None, 15, 15, 512)
block5_conv2 		 (None, 15, 15, 512)
block5_conv3 		 (None, 15, 15, 512)
total neurons:  4224
Model: "base_model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 240, 240, 3) 0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 240, 240, 64) 1792        input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 240, 240, 64) 36928       block1_conv1[0][0]               
__________________________________________________________________________________________________
block1_pool (MaxPooling2D)      (None, 120, 120, 64) 0           block1_conv2[0][0]               
__________________________________________________________________________________________________
block2_conv1 (Conv2D)           (None, 120, 120, 128 73856       block1_pool[0][0]                
__________________________________________________________________________________________________
block2_conv2 (Conv2D)           (None, 120, 120, 128 147584      block2_conv1[0][0]               
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 60, 60, 128)  0           block2_conv2[0][0]               
__________________________________________________________________________________________________
block3_conv1 (Conv2D)           (None, 60, 60, 256)  295168      block2_pool[0][0]                
__________________________________________________________________________________________________
block3_conv2 (Conv2D)           (None, 60, 60, 256)  590080      block3_conv1[0][0]               
__________________________________________________________________________________________________
block3_conv3 (Conv2D)           (None, 60, 60, 256)  590080      block3_conv2[0][0]               
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 30, 30, 256)  0           block3_conv3[0][0]               
__________________________________________________________________________________________________
block4_conv1 (Conv2D)           (None, 30, 30, 512)  1180160     block3_pool[0][0]                
__________________________________________________________________________________________________
block4_conv2 (Conv2D)           (None, 30, 30, 512)  2359808     block4_conv1[0][0]               
__________________________________________________________________________________________________
block4_conv3 (Conv2D)           (None, 30, 30, 512)  2359808     block4_conv2[0][0]               
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 15, 15, 512)  0           block4_conv3[0][0]               
__________________________________________________________________________________________________
block5_conv1 (Conv2D)           (None, 15, 15, 512)  2359808     block4_pool[0][0]                
__________________________________________________________________________________________________
block5_conv2 (Conv2D)           (None, 15, 15, 512)  2359808     block5_conv1[0][0]               
__________________________________________________________________________________________________
block5_conv3 (Conv2D)           (None, 15, 15, 512)  2359808     block5_conv2[0][0]               
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 7, 7, 512)    0           block5_conv3[0][0]               
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 512)          0           max_pooling2d[0][0]              
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 512)]        0                                            
__________________________________________________________________________________________________
tf.math.multiply (TFOpLambda)   (None, 512)          0           global_average_pooling2d[0][0]   
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            1026        tf.math.multiply[0][0]           
__________________________________________________________________________________________________
activation (Activation)         (None, 2)            0           dense[0][0]                      
==================================================================================================
Total params: 14,715,714
Trainable params: 1,026
Non-trainable params: 14,714,688
__________________________________________________________________________________________________
weights loaded
threshold:  0.5
l1 weight:  2
training CF model for alter class:  tumor
Training CF model for PPs
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 240, 240, 3) 0                                            
__________________________________________________________________________________________________
counterfactual_model (Functiona (None, 512)          14977344    input_3[0][0]                    
__________________________________________________________________________________________________
base_model (Functional)         [(None, 2), (None, 1 14715714    input_3[0][0]                    
                                                                 counterfactual_model[0][0]       
==================================================================================================
Total params: 14,978,370
Trainable params: 262,656
Non-trainable params: 14,715,714
__________________________________________________________________________________________________
training for fixed alter class:  tumor
  0%|          | 0/543 [00:00<?, ?it/s]epoch 0: 100%|##########| 543/543 [03:07<00:00,  2.90it/s, acc=0.956, loss=[0.098295026, 1.1511642, -0.15470473, 0.0, 23.798882, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 1: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.97, loss=[0.079178385, 0.38564944, -0.15295988, 0.0, 7.9550743, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 2: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.979, loss=[0.061532184, 0.38141513, -0.1829068, 0.0, 7.3177094, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 3: 100%|##########| 543/543 [02:56<00:00,  3.07it/s, acc=0.981, loss=[0.059087187, 0.36560604, -0.18370229, 0.0, 6.7953305, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 4: 100%|##########| 543/543 [02:53<00:00,  3.12it/s, acc=0.982, loss=[0.05714679, 0.35710084, -0.18388966, 0.0, 6.5330586, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 5: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.983, loss=[0.055671073, 0.35106295, -0.18379904, 0.0, 6.3547945, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 6: 100%|##########| 543/543 [02:53<00:00,  3.12it/s, acc=0.984, loss=[0.054044507, 0.3469823, -0.1836684, 0.0, 6.2278347, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 7: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.984, loss=[0.053252347, 0.3433803, -0.18358156, 0.0, 6.1222157, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 8: 100%|##########| 543/543 [02:53<00:00,  3.12it/s, acc=0.985, loss=[0.052089076, 0.3414569, -0.18384944, 0.0, 6.0587344, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 9: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.986, loss=[0.05148379, 0.33941105, -0.18387751, 0.0, 5.996191, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 10: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.986, loss=[0.05075535, 0.33838338, -0.18441005, 0.0, 5.961493, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 11: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.986, loss=[0.050188094, 0.33779627, -0.18532649, 0.0, 5.931361, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 12: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.986, loss=[0.04959955, 0.33704686, -0.18565798, 0.0, 5.9068694, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 13: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.987, loss=[0.049361475, 0.33705422, -0.18675542, 0.0, 5.898785, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 14: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.987, loss=[0.048955664, 0.33804542, -0.18865599, 0.0, 5.9077983, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 15: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.987, loss=[0.0485255, 0.34005797, -0.19142336, 0.0, 5.9421177, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 16: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.987, loss=[0.048206877, 0.34063676, -0.19281754, 0.0, 5.943587, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 17: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.988, loss=[0.047957413, 0.3403457, -0.19345722, 0.0, 5.92929, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 18: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.988, loss=[0.047562983, 0.34238216, -0.19601777, 0.0, 5.9625344, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 19: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.988, loss=[0.04739837, 0.34249324, -0.19693018, 0.0, 5.9571114, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 20: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.988, loss=[0.047145437, 0.34256196, -0.19769679, 0.0, 5.9502187, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 21: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.988, loss=[0.046857603, 0.3427451, -0.19838838, 0.0, 5.947437, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 22: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.988, loss=[0.04651726, 0.34292868, -0.1989813, 0.0, 5.944299, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 23: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.988, loss=[0.046683125, 0.3422436, -0.19920902, 0.0, 5.9258637, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 24: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.989, loss=[0.046289682, 0.34235728, -0.19960083, 0.0, 5.925719, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 25: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.989, loss=[0.046160657, 0.34235537, -0.2001861, 0.0, 5.9194374, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 26: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.989, loss=[0.045909822, 0.3425195, -0.20065114, 0.0, 5.921334, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 27: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.989, loss=[0.045904674, 0.34245902, -0.20119327, 0.0, 5.9179797, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 28: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.989, loss=[0.045761712, 0.3420655, -0.20114438, 0.0, 5.9113393, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 29: 100%|##########| 543/543 [02:54<00:00,  3.10it/s, acc=0.989, loss=[0.045686267, 0.34199366, -0.20150764, 0.0, 5.913219, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 30: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.989, loss=[0.04583431, 0.3413299, -0.20164287, 0.0, 5.913657, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 31: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.989, loss=[0.04754519, 0.33502194, -0.19886042, 0.0, 5.897697, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 32: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.989, loss=[0.048676275, 0.32749543, -0.19453551, 0.0, 5.8366385, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 33: 100%|##########| 543/543 [02:54<00:00,  3.10it/s, acc=0.99, loss=[0.048330177, 0.32607734, -0.1940124, 0.0, 5.809957, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 34: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.99, loss=[0.048366524, 0.32471585, -0.1936275, 0.0, 5.7772927, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 35: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.989, loss=[0.0482195, 0.32420954, -0.19369724, 0.0, 5.762631, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 36: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.989, loss=[0.048418153, 0.32292682, -0.19326814, 0.0, 5.73376, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 37: 100%|##########| 543/543 [02:54<00:00,  3.10it/s, acc=0.99, loss=[0.048074402, 0.32282627, -0.19341561, 0.0, 5.72684, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 38: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.99, loss=[0.047779035, 0.32254976, -0.19343676, 0.0, 5.7149763, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 39: 100%|##########| 543/543 [02:54<00:00,  3.10it/s, acc=0.99, loss=[0.04785527, 0.32189327, -0.19334336, 0.0, 5.699087, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 40: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.99, loss=[0.047522176, 0.32186115, -0.19338985, 0.0, 5.6946115, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 41: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.99, loss=[0.047492217, 0.32135907, -0.1933324, 0.0, 5.67921, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 42: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.99, loss=[0.04716775, 0.3214129, -0.19350863, 0.0, 5.6755347, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 43: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.99, loss=[0.04710269, 0.3208436, -0.19326194, 0.0, 5.6620107, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 44: 100%|##########| 543/543 [02:54<00:00,  3.10it/s, acc=0.99, loss=[0.047102354, 0.32064182, -0.19331487, 0.0, 5.6556635, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 45: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.99, loss=[0.046740618, 0.32072288, -0.19348106, 0.0, 5.653918, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 46: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.99, loss=[0.046654858, 0.32057855, -0.19362642, 0.0, 5.646798, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 47: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.99, loss=[0.04635477, 0.32048756, -0.19355188, 0.0, 5.6439147, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 48: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.991, loss=[0.046348557, 0.3202483, -0.19360343, 0.0, 5.636324, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 49: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.991, loss=[0.04625875, 0.31973988, -0.19331364, 0.0, 5.625819, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 50: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.991, loss=[0.046061166, 0.31980485, -0.1934829, 0.0, 5.6241693, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 51: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.99, loss=[0.045965962, 0.3196571, -0.19354805, 0.0, 5.618527, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 52: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.99, loss=[0.045857385, 0.3195152, -0.19357543, 0.0, 5.6144547, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 53: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.99, loss=[0.045790702, 0.31939682, -0.19362672, 0.0, 5.6089683, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 54: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.991, loss=[0.04555711, 0.31929404, -0.19358867, 0.0, 5.606389, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 55: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.991, loss=[0.045571145, 0.31921345, -0.19373272, 0.0, 5.602303, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 56: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.991, loss=[0.045428034, 0.31895688, -0.19365723, 0.0, 5.5945177, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 57: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.991, loss=[0.045257293, 0.31888494, -0.19367054, 0.0, 5.5905247, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 58: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.991, loss=[0.045159567, 0.31867555, -0.19360836, 0.0, 5.585109, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 59: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.991, loss=[0.044912595, 0.31902853, -0.19387497, 0.0, 5.5898037, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 60: 100%|##########| 543/543 [02:54<00:00,  3.11it/s, acc=0.991, loss=[0.04510297, 0.31846976, -0.19373965, 0.0, 5.5777287, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 61: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.991, loss=[0.044742923, 0.3187003, -0.19380212, 0.0, 5.580757, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 62: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.991, loss=[0.04487373, 0.3184744, -0.1939247, 0.0, 5.5731716, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 63: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.991, loss=[0.044633314, 0.3181578, -0.19360505, 0.0, 5.5663314, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 64: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.991, loss=[0.044514973, 0.31836116, -0.19386153, 0.0, 5.5679564, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 65: 100%|##########| 543/543 [02:53<00:00,  3.13it/s, acc=0.991, loss=[0.04446662, 0.3180698, -0.19374199, 0.0, 5.560984, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 66: 100%|##########| 543/543 [02:53<00:00,  3.12it/s, acc=0.991, loss=[0.044357598, 0.31816897, -0.1939038, 0.0, 5.560431, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 67: 100%|##########| 543/543 [02:53<00:00,  3.12it/s, acc=0.991, loss=[0.044443052, 0.3176061, -0.19362798, 0.0, 5.5493374, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 68: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.991, loss=[0.044214007, 0.3179707, -0.19391058, 0.0, 5.553952, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 69: 100%|##########| 543/543 [02:53<00:00,  3.12it/s, acc=0.991, loss=[0.04414608, 0.3177012, -0.19376491, 0.0, 5.547452, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 70: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.991, loss=[0.044019204, 0.31779954, -0.19387987, 0.0, 5.548825, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 71: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.991, loss=[0.044057634, 0.31769055, -0.19396962, 0.0, 5.545312, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 72: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.991, loss=[0.043887135, 0.31758556, -0.1938829, 0.0, 5.5416694, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 73: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.991, loss=[0.044005662, 0.31725124, -0.19385126, 0.0, 5.5326314, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 74: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.043601975, 0.3176554, -0.19397871, 0.0, 5.5407352, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 75: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.04369224, 0.3171606, -0.1937819, 0.0, 5.529899, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 76: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.043677017, 0.31720197, -0.19391023, 0.0, 5.5298963, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 77: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.0435767, 0.3170691, -0.19389802, 0.0, 5.525533, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 78: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.043366544, 0.31723922, -0.1939615, 0.0, 5.527271, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 79: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.043224417, 0.31719932, -0.19393389, 0.0, 5.5258484, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 80: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.043307748, 0.31692123, -0.19390239, 0.0, 5.5187206, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 81: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.0431124, 0.3171864, -0.19412051, 0.0, 5.5228696, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 82: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.043121565, 0.31683326, -0.19386102, 0.0, 5.5156403, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 83: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.042952415, 0.31726047, -0.19423516, 0.0, 5.5214143, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 84: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.043127116, 0.3165983, -0.19387902, 0.0, 5.5092273, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 85: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.0429642, 0.3166424, -0.1938595, 0.0, 5.509334, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 86: 100%|##########| 543/543 [02:54<00:00,  3.12it/s, acc=0.992, loss=[0.042770375, 0.31707722, -0.19417495, 0.0, 5.516849, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 87: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.992, loss=[0.042778786, 0.31666973, -0.19400835, 0.0, 5.507306, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 88: 100%|##########| 543/543 [02:54<00:00,  3.10it/s, acc=0.992, loss=[0.042587597, 0.31682208, -0.19407667, 0.0, 5.510474, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 89: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.992, loss=[0.042640753, 0.31664482, -0.19408926, 0.0, 5.5047545, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 90: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.992, loss=[0.04261749, 0.31641123, -0.19392508, 0.0, 5.5004797, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 91: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.992, loss=[0.042479172, 0.3166473, -0.19410881, 0.0, 5.503845, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 92: 100%|##########| 543/543 [02:55<00:00,  3.09it/s, acc=0.992, loss=[0.042424917, 0.3163254, -0.19385725, 0.0, 5.4970155, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 93: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.992, loss=[0.04231685, 0.31672704, -0.19421837, 0.0, 5.502973, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 94: 100%|##########| 543/543 [02:55<00:00,  3.09it/s, acc=0.992, loss=[0.04237033, 0.3163113, -0.19402286, 0.0, 5.4934587, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 95: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.992, loss=[0.04224484, 0.31653437, -0.19424069, 0.0, 5.4951053, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 96: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.992, loss=[0.042201538, 0.31620142, -0.19394897, 0.0, 5.489186, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 97: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.992, loss=[0.042151965, 0.31615928, -0.19396219, 0.0, 5.4875555, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 98: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.992, loss=[0.04219004, 0.31612918, -0.19403833, 0.0, 5.486111, 0.0]]
  0%|          | 0/543 [00:00<?, ?it/s]epoch 99: 100%|##########| 543/543 [02:55<00:00,  3.10it/s, acc=0.992, loss=[0.04200468, 0.31637388, -0.1941737, 0.0, 5.48926, 0.0]]
