{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run -i my_interpretable_CNN.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in range(2):\n",
    "#     %run -i my_interpretable_CNN.py --alter_class=$index --cfe_epochs=1 --save_logFile=True\n",
    "#     #%reset -f\n",
    "#     %load_ext autoreload\n",
    "#     %autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in range(2):\n",
    "#     %run -n my_interpretable_CNN.py --alter_class=$index --cfe_epochs=1 --save_logFile=True\n",
    "#     #%reset -f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i my_interpretable_CNN.py --train_counterfactual_net True --find_global_filters False --counterfactual_PP True --resume True --alter_class 9 --cfe_epochs 1 --l1_weight 2 --save_directory \"./trained_weights/\" --save_logFile False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i my_interpretable_CNN.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from IPython import get_ipython\n",
    "# import IPython\n",
    "\n",
    "# for i in range(2):\n",
    "#     %run -i my_interpretable_CNN.py --choose_subclass True --train_counterfactual_net True --find_global_filters False --counterfactual_PP True --resume True --alter_class $i --cfe_epochs 1 --l1_weight 2 --save_directory \"./trained_weights/\" --save_logFile False\n",
    "# #     IPython.Application.instance().kernel.do_shutdown(True)\n",
    "#     %run -i my_interpretable_CNN.py --choose_subclass True --train_counterfactual_net True --find_global_filters False --counterfactual_PP True --resume True --alter_class 9 --cfe_epochs 1 --l1_weight 2 --save_directory \"./trained_weights/\" --save_logFile False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.6.0\n",
      "...GPU set_memory_growth successfully set...\n",
      "loading VGG model\n",
      "using VGG16 imagenet weights for CUB200 dataset\n",
      "total neurons:  4224\n",
      "batch_size:  16\n",
      "CUB200-2011 dataset\n",
      "using official split\n",
      "num classes: 200\n",
      "using imagenet_weights\n",
      "Found 27 images belonging to 1 classes.\n",
      "Found 3 images belonging to 1 classes.\n",
      "Found 27 images belonging to 1 classes.\n",
      "Found 3 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "train for ALL classes\n",
      "not saving log file\n",
      "\n",
      " Namespace(filter_visualization=True, user_evaluation=False, train_counterfactual_net=True, train_all_classes=True, train_singular_counterfactual_net=False, choose_subclass=True, counterfactual_PP=True, resume_counterfactual_net=False, test_counterfactual_net=False, load_counterfactual_net=True, resume=True, alter_class=0, analysis_class=9, find_global_filters=False, alter_class_2=0, cfe_epochs=1, l1_weight=2, save_logFile=False, dataset='CUB200', save_directory='./trained_weights/', train_using_builtin_fit_method=True, train=False, fine_tune=False, test=False, model='VGG16/', imagenet_weights=True) \n",
      "\n",
      "Model: \"base_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 02:55:40.237671: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-07 02:55:40.971746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2143 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "2022-07-07 02:55:43.015887: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2022-07-07 02:55:45.101796: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 898.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:55:45.705586: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.74GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:55:45.705637: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:55:45.734736: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 898.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:55:46.108585: W tensorflow/core/common_runtime/bfc_allocator.cc:338] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2022-07-07 02:55:46.706842: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:55:47.491122: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:55:48.217467: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:55:50.381027: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-07-07 02:55:51.386983: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:55:52.264743: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:55:52.934185: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Medical Imaging Diagnostic (MID) Lab\\XAI in MID\\Counterfactual-Explanation-Model\\train_CFE_model.py\", line 232, in <module>\n",
      "    combined, generator = train_counterfactual_net(model,weights_path, counterfactual_generator, train_gen,args.test_counterfactual_net, args.resume_counterfactual_net,epochs=cf_epochs,L1_weight=L1_weight,for_class=for_class,label_map=label_map,logging=logging,args=args) \n",
      "  File \"E:\\Medical Imaging Diagnostic (MID) Lab\\XAI in MID\\Counterfactual-Explanation-Model\\codes\\train_counterfactual_net.py\", line 260, in train_counterfactual_net\n",
      "    train_step(x_batch_test, alter_class,combined,Weight,model,L1_weight,args.counterfactual_PP, for_alter_class)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 917, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3038, in __call__\n",
      "    filtered_flat_args) = self._maybe_define_function(args, kwargs)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 668, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fmatrix (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 512)          0           global_average_pooling2d[0][0]   \n",
      "                                                                 fmatrix[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          102600      tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 200)          0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 14,817,288\n",
      "Trainable params: 102,600\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n",
      "weights loaded\n",
      "threshold:  0.5\n",
      "l1 weight:  2\n",
      "training CF model for alter class:  001.Black_footed_Albatross\n",
      "Training CF model for PPs\n",
      "training for alter class\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "counterfactual_model (Functiona (None, 512)          14977344    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Functional)         [(None, 200), (None, 14817288    input_1[0][0]                    \n",
      "                                                                 counterfactual_model[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 15,079,944\n",
      "Trainable params: 262,656\n",
      "Non-trainable params: 14,817,288\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "epoch 0:  50%|#####     | 1/2 [00:11<00:11, 11.66s/it, acc=0, loss=[34.570004, 7.257439, 0.06654137, 0.0, 254.4375, 0.0]]\n",
      "epoch 0: 100%|##########| 2/2 [00:18<00:00,  8.61s/it, acc=0, loss=[28.998074, 6.1395802, 0.023022003, 0.0, 253.5824, 0.0]]\n",
      "epoch 0: 100%|##########| 2/2 [00:18<00:00,  9.06s/it, acc=0, loss=[28.998074, 6.1395802, 0.023022003, 0.0, 253.5824, 0.0]]\n",
      "not saving log file\n",
      "\n",
      " Namespace(filter_visualization=True, user_evaluation=False, train_counterfactual_net=True, train_all_classes=True, train_singular_counterfactual_net=False, choose_subclass=True, counterfactual_PP=True, resume_counterfactual_net=False, test_counterfactual_net=False, load_counterfactual_net=True, resume=True, alter_class=1, analysis_class=9, find_global_filters=False, alter_class_2=0, cfe_epochs=1, l1_weight=2, save_logFile=False, dataset='CUB200', save_directory='./trained_weights/', train_using_builtin_fit_method=True, train=False, fine_tune=False, test=False, model='VGG16/', imagenet_weights=True) \n",
      "\n",
      "Model: \"base_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fmatrix (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 512)          0           global_average_pooling2d[0][0]   \n",
      "                                                                 fmatrix[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          102600      tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 200)          0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 14,817,288\n",
      "Trainable params: 102,600\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n",
      "weights loaded\n",
      "threshold:  0.5\n",
      "l1 weight:  2\n",
      "training CF model for alter class:  002.Laysan_Albatross\n",
      "Training CF model for PPs\n",
      "training for alter class\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "counterfactual_model (Functiona (None, 512)          14977344    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Functional)         [(None, 200), (None, 14817288    input_1[0][0]                    \n",
      "                                                                 counterfactual_model[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 15,079,944\n",
      "Trainable params: 262,656\n",
      "Non-trainable params: 14,817,288\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 994, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    E:\\Medical Imaging Diagnostic (MID) Lab\\XAI in MID\\Counterfactual-Explanation-Model\\codes\\train_counterfactual_net.py:112 train_step  *\n",
      "        optimizer.apply_gradients(zip(gradients, combined.trainable_variables))#,name='opt_grad'+str(np.random.randint(10)))\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:628 apply_gradients  **\n",
      "        self._create_all_weights(var_list)\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:815 _create_all_weights\n",
      "        self._create_slots(var_list)\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:118 _create_slots\n",
      "        self.add_slot(var, \"momentum\")\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:901 add_slot\n",
      "        weight = tf.Variable(\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:268 __call__\n",
      "        return cls._variable_v2_call(*args, **kwargs)\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:250 _variable_v2_call\n",
      "        return previous_getter(\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n",
      "        return captured_getter(captured_previous, **kwargs)\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:764 invalid_creator_scope\n",
      "        raise ValueError(\n",
      "\n",
      "    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
      "\n",
      "2022-07-07 02:56:09.191854: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-07 02:56:09.896247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2143 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "2022-07-07 02:56:11.846058: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2022-07-07 02:56:13.982374: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 898.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:56:14.582986: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.74GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:56:14.583037: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:56:14.612133: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 898.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:56:14.986979: W tensorflow/core/common_runtime/bfc_allocator.cc:338] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2022-07-07 02:56:15.584562: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:56:16.450726: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:56:17.196551: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:56:19.475977: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-07-07 02:56:20.429324: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:56:21.279213: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-07 02:56:21.965875: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Medical Imaging Diagnostic (MID) Lab\\XAI in MID\\Counterfactual-Explanation-Model\\train_CFE_model.py\", line 232, in <module>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.6.0\n",
      "...GPU set_memory_growth successfully set...\n",
      "loading VGG model\n",
      "using VGG16 imagenet weights for CUB200 dataset\n",
      "total neurons:  4224\n",
      "batch_size:  16\n",
      "CUB200-2011 dataset\n",
      "using official split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    combined, generator = train_counterfactual_net(model,weights_path, counterfactual_generator, train_gen,args.test_counterfactual_net, args.resume_counterfactual_net,epochs=cf_epochs,L1_weight=L1_weight,for_class=for_class,label_map=label_map,logging=logging,args=args) \n",
      "  File \"E:\\Medical Imaging Diagnostic (MID) Lab\\XAI in MID\\Counterfactual-Explanation-Model\\codes\\train_counterfactual_net.py\", line 260, in train_counterfactual_net\n",
      "    train_step(x_batch_test, alter_class,combined,Weight,model,L1_weight,args.counterfactual_PP, for_alter_class)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 917, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3038, in __call__\n",
      "    filtered_flat_args) = self._maybe_define_function(args, kwargs)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 668, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 994, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    E:\\Medical Imaging Diagnostic (MID) Lab\\XAI in MID\\Counterfactual-Explanation-Model\\codes\\train_counterfactual_net.py:112 train_step  *"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num classes: 200\n",
      "using imagenet_weights\n",
      "Found 27 images belonging to 1 classes.\n",
      "Found 3 images belonging to 1 classes.\n",
      "Found 27 images belonging to 1 classes.\n",
      "Found 3 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "train for ALL classes\n",
      "not saving log file\n",
      "\n",
      " Namespace(filter_visualization=True, user_evaluation=False, train_counterfactual_net=True, train_all_classes=True, train_singular_counterfactual_net=False, choose_subclass=True, counterfactual_PP=True, resume_counterfactual_net=False, test_counterfactual_net=False, load_counterfactual_net=True, resume=True, alter_class=0, analysis_class=9, find_global_filters=False, alter_class_2=0, cfe_epochs=1, l1_weight=2, save_logFile=False, dataset='CUB200', save_directory='./trained_weights/', train_using_builtin_fit_method=True, train=False, fine_tune=False, test=False, model='VGG16/', imagenet_weights=True) \n",
      "\n",
      "Model: \"base_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fmatrix (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 512)          0           global_average_pooling2d[0][0]   \n",
      "                                                                 fmatrix[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          102600      tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 200)          0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 14,817,288\n",
      "Trainable params: 102,600\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n",
      "weights loaded\n",
      "threshold:  0.5\n",
      "l1 weight:  2\n",
      "training CF model for alter class:  001.Black_footed_Albatross\n",
      "Training CF model for PPs\n",
      "training for alter class\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "counterfactual_model (Functiona (None, 512)          14977344    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Functional)         [(None, 200), (None, 14817288    input_1[0][0]                    \n",
      "                                                                 counterfactual_model[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 15,079,944\n",
      "Trainable params: 262,656\n",
      "Non-trainable params: 14,817,288\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "epoch 0:  50%|#####     | 1/2 [00:11<00:11, 11.81s/it, acc=0, loss=[35.868187, 7.6162896, 0.042850696, 0.0, 263.5, 0.0]]\n",
      "epoch 0: 100%|##########| 2/2 [00:18<00:00,  8.71s/it, acc=0, loss=[30.680996, 6.3669176, 0.0022791624, 0.0, 260.56818, 0.0]]\n",
      "epoch 0: 100%|##########| 2/2 [00:18<00:00,  9.17s/it, acc=0, loss=[30.680996, 6.3669176, 0.0022791624, 0.0, 260.56818, 0.0]]\n",
      "not saving log file\n",
      "\n",
      " Namespace(filter_visualization=True, user_evaluation=False, train_counterfactual_net=True, train_all_classes=True, train_singular_counterfactual_net=False, choose_subclass=True, counterfactual_PP=True, resume_counterfactual_net=False, test_counterfactual_net=False, load_counterfactual_net=True, resume=True, alter_class=1, analysis_class=9, find_global_filters=False, alter_class_2=0, cfe_epochs=1, l1_weight=2, save_logFile=False, dataset='CUB200', save_directory='./trained_weights/', train_using_builtin_fit_method=True, train=False, fine_tune=False, test=False, model='VGG16/', imagenet_weights=True) \n",
      "\n",
      "Model: \"base_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        optimizer.apply_gradients(zip(gradients, combined.trainable_variables))#,name='opt_grad'+str(np.random.randint(10)))\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:628 apply_gradients  **\n",
      "        self._create_all_weights(var_list)\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:815 _create_all_weights\n",
      "        self._create_slots(var_list)\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:118 _create_slots\n",
      "        self.add_slot(var, \"momentum\")\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:901 add_slot\n",
      "        weight = tf.Variable(\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:268 __call__\n",
      "        return cls._variable_v2_call(*args, **kwargs)\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:250 _variable_v2_call\n",
      "        return previous_getter(\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n",
      "        return captured_getter(captured_previous, **kwargs)\n",
      "    C:\\Users\\Ali\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:764 invalid_creator_scope\n",
      "        raise ValueError(\n",
      "\n",
      "    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fmatrix (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 512)          0           global_average_pooling2d[0][0]   \n",
      "                                                                 fmatrix[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          102600      tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 200)          0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 14,817,288\n",
      "Trainable params: 102,600\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n",
      "weights loaded\n",
      "threshold:  0.5\n",
      "l1 weight:  2\n",
      "training CF model for alter class:  002.Laysan_Albatross\n",
      "Training CF model for PPs\n",
      "training for alter class\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "counterfactual_model (Functiona (None, 512)          14977344    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Functional)         [(None, 200), (None, 14817288    input_1[0][0]                    \n",
      "                                                                 counterfactual_model[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 15,079,944\n",
      "Trainable params: 262,656\n",
      "Non-trainable params: 14,817,288\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# from IPython import get_ipython\n",
    "# import IPython\n",
    "\n",
    "# for i in range(2):\n",
    "# #     %run -i train_CFE_model.py\n",
    "#     !python train_CFE_model.py\n",
    "#     %reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3352\\411407525.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-m train_CFE_model.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'reset'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-f'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2405\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2406\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2407\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2408\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"m\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mmodulename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"m\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m             \u001b[0mmodpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_mod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodulename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%r is not a valid modulename on sys.path'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mmodulename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\utils\\module_paths.py\u001b[0m in \u001b[0;36mfind_mod\u001b[1;34m(module_name)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m \u001b[0mabove\u001b[0m \u001b[0mconditions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0mmodule_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodule_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\importlib\\util.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mparent_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparent_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfromlist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__path__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0mparent_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__path__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Medical Imaging Diagnostic (MID) Lab\\XAI in MID\\Counterfactual-Explanation-Model\\train_CFE_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#%%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained_weights_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mload_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtop_activation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mload_base_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Medical Imaging Diagnostic (MID) Lab\\XAI in MID\\Counterfactual-Explanation-Model\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mKAGGLE\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_all_classes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1821\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unrecognized arguments: %s'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\argparse.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2575\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2576\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'prog'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'message'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2577\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\argparse.py\u001b[0m in \u001b[0;36mexit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2563\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2564\u001b[1;33m         \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2566\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%run -i train_CFE_model.py --alter_class 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i train_CFE_model.py --alter_class 12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
