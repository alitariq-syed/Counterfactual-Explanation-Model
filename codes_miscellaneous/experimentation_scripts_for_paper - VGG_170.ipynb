{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run -i my_interpretable_CNN.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in range(2):\n",
    "#     %run -i my_interpretable_CNN.py --alter_class=$index --cfe_epochs=1 --save_logFile=True\n",
    "#     #%reset -f\n",
    "#     %load_ext autoreload\n",
    "#     %autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in range(2):\n",
    "#     %run -n my_interpretable_CNN.py --alter_class=$index --cfe_epochs=1 --save_logFile=True\n",
    "#     #%reset -f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.3.0\n",
      "...GPU set_memory_growth successfully set...\n",
      "not saving log file\n",
      "save_path:  ./trained_weights/VGG16/CUB200/standard\n",
      "resuming training\n",
      "\n",
      " Namespace(alter_class=170, analyze_filter_importance=False, cfe_epochs=200, create_counterfactual_combined=True, dataset='CUB200', filter_category_method='own_reduce_loss', filter_modified_directly=True, find_filter_class=False, fine_tune=False, fixed_classes=True, fixed_classes_reduce_loss=True, full_standard=True, high_capacity_model=True, imagenet_weights=True, interpretable=False, l1_weight=2.0, load_counterfactual_net=True, loss_compute=True, model='VGG16/', resume=True, resume_counterfactual_net=False, save_directory='./trained_weights/', save_filter_fmap=False, save_filter_importance=False, save_logFile=False, save_path='./trained_weights/VGG16/CUB200/standard', save_top_layer=True, test=True, test_counterfactual_net=False, test_filter_importance=False, train=False, train_counterfactual_net='True', train_using_builtin_fit_method=True, visualize_fmaps=False) \n",
      "\n",
      "batch_size:  32\n",
      "CUB200-2011 dataset\n",
      "using official split\n",
      "num classes: 200\n",
      "using imagenet_weights\n",
      "Found 5400 images belonging to 200 classes.\n",
      "Found 594 images belonging to 200 classes.\n",
      "Found 5400 images belonging to 200 classes.\n",
      "Found 594 images belonging to 200 classes.\n",
      "Found 5794 images belonging to 200 classes.\n",
      "Found 5794 images belonging to 200 classes.\n",
      "loading VGG model\n",
      "using VGG16 imagenet weights for CUB200 dataset\n",
      "input_1\n",
      "block1_conv1\n",
      "block1_conv2\n",
      "block1_pool\n",
      "block2_conv1\n",
      "block2_conv2\n",
      "block2_pool\n",
      "block3_conv1\n",
      "block3_conv2\n",
      "block3_conv3\n",
      "block3_pool\n",
      "block4_conv1\n",
      "block4_conv2\n",
      "block4_conv3\n",
      "block4_pool\n",
      "block5_conv1\n",
      "block5_conv2\n",
      "block5_conv3\n",
      "block5_pool\n",
      "Model: \"VGG_base_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 512)]        0           global_average_pooling2d[0][0]   \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          102600      tf_op_layer_Mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 200)          0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 14,817,288\n",
      "Trainable params: 102,600\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n",
      "weights loaded\n",
      "Testing...\n",
      "100%|████████████████████████████████████████████████████████████| 19/19 [00:09<00:00,  1.94it/s, acc=0.672, loss=2.17]\n",
      "\n",
      "Test loss: 2.1682725\n",
      "Test accuracy: 0.67171717\n",
      "threshold:  0.5\n",
      "l1 weight:  2.0\n",
      "training CF model for alter class:  171.Myrtle_Warbler\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "counterfactual_model (Functiona (None, 512)          14977344    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "VGG_base_model (Functional)     [(None, 200), (None, 14817288    input_3[0][0]                    \n",
      "                                                                 counterfactual_model[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 15,079,944\n",
      "Trainable params: 262,656\n",
      "Non-trainable params: 14,817,288\n",
      "__________________________________________________________________________________________________\n",
      "training for fixed alter class:  171.Myrtle_Warbler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|█████| 169/169 [03:04<00:00,  1.09s/it, acc=0.815, loss=[2.0876894, 5.0512295, -0.313748, 0.0, 91.39897]]\n",
      "epoch 1: 100%|██| 169/169 [02:14<00:00,  1.25it/s, acc=0.982, loss=[0.71550995, 1.8239104, -0.2680564, 0.0, 32.818604]]\n",
      "epoch 2: 100%|██| 169/169 [02:16<00:00,  1.23it/s, acc=0.987, loss=[0.69043833, 1.5230461, -0.26677153, 0.0, 26.86107]]\n",
      "epoch 3: 100%|██| 169/169 [02:15<00:00,  1.24it/s, acc=0.99, loss=[0.65197396, 1.3973665, -0.27125525, 0.0, 24.455252]]\n",
      "epoch 4: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.992, loss=[0.63090014, 1.3125447, -0.27306497, 0.0, 22.887451]]\n",
      "epoch 5: 100%|███| 169/169 [02:14<00:00,  1.25it/s, acc=0.993, loss=[0.620161, 1.2530514, -0.27424133, 0.0, 21.788708]]\n",
      "epoch 6: 100%|██| 169/169 [02:14<00:00,  1.25it/s, acc=0.993, loss=[0.6169241, 1.2034482, -0.27440938, 0.0, 20.893244]]\n",
      "epoch 7: 100%|███| 169/169 [02:14<00:00,  1.25it/s, acc=0.994, loss=[0.6077646, 1.167242, -0.27533254, 0.0, 20.247349]]\n",
      "epoch 8: 100%|██| 169/169 [02:14<00:00,  1.25it/s, acc=0.994, loss=[0.59403366, 1.1426808, -0.2769558, 0.0, 19.802391]]\n",
      "epoch 9: 100%|████| 169/169 [02:14<00:00,  1.25it/s, acc=0.993, loss=[0.588677, 1.114839, -0.27724758, 0.0, 19.320513]]\n",
      "epoch 10: 100%|████| 169/169 [02:14<00:00,  1.26it/s, acc=0.993, loss=[0.5828728, 1.091507, -0.2779182, 0.0, 18.92135]]\n",
      "epoch 11: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.993, loss=[0.57244325, 1.0751545, -0.27932307, 0.0, 18.648668]\n",
      "epoch 12: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.994, loss=[0.56754524, 1.0540935, -0.2800684, 0.0, 18.303007]]\n",
      "epoch 13: 100%|██| 169/169 [02:14<00:00,  1.25it/s, acc=0.994, loss=[0.56016654, 1.0377761, -0.2808017, 0.0, 18.02669]]\n",
      "epoch 14: 100%|██| 169/169 [02:14<00:00,  1.26it/s, acc=0.994, loss=[0.5535527, 1.022367, -0.28165472, 0.0, 17.763683]]\n",
      "epoch 15: 100%|███| 169/169 [02:14<00:00,  1.26it/s, acc=0.995, loss=[0.5446604, 1.01094, -0.28314286, 0.0, 17.586292]]\n",
      "epoch 16: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.995, loss=[0.5400429, 0.9966599, -0.28405377, 0.0, 17.342888]]\n",
      "epoch 17: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.995, loss=[0.5379505, 0.98018765, -0.28447574, 0.0, 17.078217]\n",
      "epoch 18: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.995, loss=[0.5318629, 0.9718124, -0.28563884, 0.0, 16.932322]]\n",
      "epoch 19: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.995, loss=[0.52776587, 0.9598755, -0.2859565, 0.0, 16.725714]]\n",
      "epoch 20: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.995, loss=[0.5247653, 0.95065933, -0.28656352, 0.0, 16.560404]\n",
      "epoch 21: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.995, loss=[0.52050054, 0.94343394, -0.28711736, 0.0, 16.424557\n",
      "epoch 22: 100%|███| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.5178032, 0.9351994, -0.287583, 0.0, 16.280695]]\n",
      "epoch 23: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.51272863, 0.9298056, -0.28840235, 0.0, 16.177391]\n",
      "epoch 24: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.5083727, 0.92359936, -0.28922322, 0.0, 16.05794]]\n",
      "epoch 25: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.50317585, 0.9201723, -0.29018015, 0.0, 16.001232]\n",
      "epoch 26: 100%|██| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.49998814, 0.914635, -0.29058683, 0.0, 15.89571]]\n",
      "epoch 27: 100%|█| 169/169 [02:15<00:00,  1.25it/s, acc=0.996, loss=[0.4975001, 0.90913635, -0.29082066, 0.0, 15.796227]\n",
      "epoch 28: 100%|██| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4952053, 0.9041666, -0.2910919, 0.0, 15.707593]]\n",
      "epoch 29: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.49106115, 0.9017583, -0.29169816, 0.0, 15.659516]\n",
      "epoch 30: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.48731443, 0.89840066, -0.292214, 0.0, 15.594797]]\n",
      "epoch 31: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.48577672, 0.8924778, -0.29233035, 0.0, 15.4842825\n",
      "epoch 32: 100%|███| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4815487, 0.891171, -0.2930913, 0.0, 15.459072]]\n",
      "epoch 33: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.995, loss=[0.47918984, 0.8874217, -0.2934888, 0.0, 15.391889]]\n",
      "epoch 34: 100%|██| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.47498146, 0.885239, -0.2940174, 0.0, 15.351147]]\n",
      "epoch 35: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4738305, 0.8801945, -0.29419416, 0.0, 15.252836]]\n",
      "epoch 36: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.47168177, 0.8769698, -0.29444993, 0.0, 15.188917]\n",
      "epoch 37: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.46829814, 0.87583244, -0.29488307, 0.0, 15.183802\n",
      "epoch 38: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4658518, 0.8725233, -0.29519954, 0.0, 15.118775]]\n",
      "epoch 39: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.46437457, 0.86904085, -0.29538172, 0.0, 15.05646]\n",
      "epoch 40: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.46011308, 0.8691294, -0.29604176, 0.0, 15.059419]\n",
      "epoch 41: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.45914325, 0.86433697, -0.29609504, 0.0, 14.97177]\n",
      "epoch 42: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.45785165, 0.86215055, -0.29631644, 0.0, 14.920426\n",
      "epoch 43: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.45610923, 0.85957426, -0.2965737, 0.0, 14.883074]\n",
      "epoch 44: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.45573896, 0.85608625, -0.29659906, 0.0, 14.814719\n",
      "epoch 45: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.45330608, 0.8548252, -0.2969731, 0.0, 14.793639]]\n",
      "epoch 46: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.45139787, 0.85323006, -0.29717892, 0.0, 14.761217\n",
      "epoch 47: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.45085633, 0.84958285, -0.29724786, 0.0, 14.691875\n",
      "epoch 48: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.44761097, 0.8491221, -0.29785985, 0.0, 14.694219]\n",
      "epoch 49: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.44669238, 0.846341, -0.29808453, 0.0, 14.646265]]\n",
      "epoch 50: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.44461113, 0.84484917, -0.2983208, 0.0, 14.620378]\n",
      "epoch 51: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.44303286, 0.8429232, -0.29845655, 0.0, 14.58358]]\n",
      "epoch 52: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.44232702, 0.84063005, -0.2986955, 0.0, 14.54894]]\n",
      "epoch 53: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.44090953, 0.8377151, -0.2987854, 0.0, 14.495685]]\n",
      "epoch 54: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.43808845, 0.83745867, -0.29920998, 0.0, 14.493405\n",
      "epoch 55: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.436284, 0.83529085, -0.29956266, 0.0, 14.456978]]\n",
      "epoch 56: 100%|██| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.4332825, 0.8350383, -0.2999309, 0.0, 14.461231]]\n",
      "epoch 57: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.43240157, 0.83144313, -0.30000424, 0.0, 14.398606\n",
      "epoch 58: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.43060714, 0.8296323, -0.30044526, 0.0, 14.3698225\n",
      "epoch 59: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.43000486, 0.8266339, -0.30050403, 0.0, 14.323657]\n",
      "epoch 60: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.42940181, 0.8236743, -0.30061352, 0.0, 14.282914]\n",
      "epoch 61: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.42874485, 0.8206742, -0.30059096, 0.0, 14.237549]\n",
      "epoch 62: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.4280527, 0.8178197, -0.30060577, 0.0, 14.188362]]\n",
      "epoch 63: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.4275551, 0.8147026, -0.30070865, 0.0, 14.143553]]\n",
      "epoch 64: 100%|████| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.4271986, 0.811742, -0.300715, 0.0, 14.091778]]\n",
      "epoch 65: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.42537025, 0.8102713, -0.30083227, 0.0, 14.069157]\n",
      "epoch 66: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4242145, 0.80712193, -0.30084872, 0.0, 13.999198]\n",
      "epoch 67: 100%|██| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.42250225, 0.807236, -0.3012357, 0.0, 14.012512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68: 100%|███| 169/169 [02:16<00:00,  1.24it/s, acc=0.996, loss=[0.4218565, 0.8049227, -0.301283, 0.0, 13.966224]]\n",
      "epoch 69: 100%|██| 169/169 [02:15<00:00,  1.25it/s, acc=0.996, loss=[0.419747, 0.8038495, -0.30161014, 0.0, 13.948964]]\n",
      "epoch 70: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.41836092, 0.80209064, -0.30165002, 0.0, 13.914386\n",
      "epoch 71: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.41780132, 0.8010138, -0.3018847, 0.0, 13.8906555]\n",
      "epoch 72: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.41700295, 0.7989789, -0.3019766, 0.0, 13.849421]]\n",
      "epoch 73: 100%|███| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4148562, 0.7989314, -0.3022269, 0.0, 13.84825]]\n",
      "epoch 74: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4141181, 0.79800725, -0.30239677, 0.0, 13.831423]\n",
      "epoch 75: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.41495952, 0.79463726, -0.3020942, 0.0, 13.764545]\n",
      "epoch 76: 100%|██| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4121442, 0.7956271, -0.3025477, 0.0, 13.784023]]\n",
      "epoch 77: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.41114143, 0.79515845, -0.30273378, 0.0, 13.771882\n",
      "epoch 78: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.41023174, 0.7933334, -0.30277383, 0.0, 13.744205]\n",
      "epoch 79: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.40981066, 0.79158753, -0.30283526, 0.0, 13.704142\n",
      "epoch 80: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.40826374, 0.79137486, -0.3029969, 0.0, 13.700813]\n",
      "epoch 81: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.40750238, 0.7907202, -0.30319032, 0.0, 13.687007]\n",
      "epoch 82: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.40729576, 0.7881822, -0.3031523, 0.0, 13.642814]]\n",
      "epoch 83: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.40626788, 0.7875926, -0.30327168, 0.0, 13.626232]\n",
      "epoch 84: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.40504777, 0.7876717, -0.3035269, 0.0, 13.626849]]\n",
      "epoch 85: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.40471515, 0.7862984, -0.3034712, 0.0, 13.603488]]\n",
      "epoch 86: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4038223, 0.7856789, -0.30358908, 0.0, 13.593997]]\n",
      "epoch 87: 100%|██| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4032035, 0.7845127, -0.3037093, 0.0, 13.569774]]\n",
      "epoch 88: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.40322992, 0.78236496, -0.30366132, 0.0, 13.524285\n",
      "epoch 89: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.4018115, 0.7832928, -0.30393744, 0.0, 13.550481]]\n",
      "epoch 90: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.40207192, 0.7808382, -0.30379897, 0.0, 13.496179]\n",
      "epoch 91: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.40114757, 0.7808478, -0.30391654, 0.0, 13.501541]\n",
      "epoch 92: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.40025094, 0.7798984, -0.30402595, 0.0, 13.482926]\n",
      "epoch 93: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.40047857, 0.7780733, -0.3040259, 0.0, 13.445451]]\n",
      "epoch 94: 100%|██| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.3998614, 0.7774434, -0.3041144, 0.0, 13.434974]]\n",
      "epoch 95: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.39753258, 0.77852374, -0.30434987, 0.0, 13.458888\n",
      "epoch 96: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.39759701, 0.77639455, -0.3044367, 0.0, 13.413769]\n",
      "epoch 97: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.39606202, 0.7765807, -0.30467257, 0.0, 13.421474]\n",
      "epoch 98: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.39629206, 0.7751416, -0.30459544, 0.0, 13.39232]]\n",
      "epoch 99: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3958123, 0.77354664, -0.3046146, 0.0, 13.358727]]\n",
      "epoch 100: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.39446795, 0.7742809, -0.30483064, 0.0, 13.37198]\n",
      "epoch 101: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.39422306, 0.7731448, -0.30493435, 0.0, 13.356077\n",
      "epoch 102: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.39361408, 0.772167, -0.3049814, 0.0, 13.333518]]\n",
      "epoch 103: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.3935739, 0.77130455, -0.30499056, 0.0, 13.317862\n",
      "epoch 104: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.39308175, 0.77045655, -0.30507708, 0.0, 13.30122\n",
      "epoch 105: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.39256543, 0.769778, -0.30498773, 0.0, 13.287537]\n",
      "epoch 106: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.39097148, 0.77054656, -0.3052632, 0.0, 13.305596\n",
      "epoch 107: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.3913924, 0.7683406, -0.30522057, 0.0, 13.264792]\n",
      "epoch 108: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.996, loss=[0.38983178, 0.76894724, -0.30545664, 0.0, 13.27890\n",
      "epoch 109: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.38955715, 0.7675695, -0.30548114, 0.0, 13.248459\n",
      "epoch 110: 100%|█| 169/169 [02:15<00:00,  1.25it/s, acc=0.996, loss=[0.38846692, 0.767776, -0.3056594, 0.0, 13.253945]]\n",
      "epoch 111: 100%|█| 169/169 [02:16<00:00,  1.24it/s, acc=0.996, loss=[0.38823825, 0.76624733, -0.30569044, 0.0, 13.22337\n",
      "epoch 112: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.3873712, 0.7662755, -0.30581596, 0.0, 13.228797]\n",
      "epoch 113: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.38650697, 0.7654688, -0.30594498, 0.0, 13.210367\n",
      "epoch 114: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.38520762, 0.76623935, -0.30618483, 0.0, 13.22602\n",
      "epoch 115: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.38555488, 0.7642871, -0.30614296, 0.0, 13.184727\n",
      "epoch 116: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.3848562, 0.76378834, -0.30616122, 0.0, 13.179671\n",
      "epoch 117: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.38459262, 0.7637045, -0.30621836, 0.0, 13.178747\n",
      "epoch 118: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.38347948, 0.7631292, -0.30641022, 0.0, 13.166667\n",
      "epoch 119: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.38342872, 0.76219654, -0.3063099, 0.0, 13.149531\n",
      "epoch 120: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.3825525, 0.7621048, -0.30655992, 0.0, 13.152305]\n",
      "epoch 121: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.38176817, 0.7615132, -0.306566, 0.0, 13.1404705]\n",
      "epoch 122: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.38079703, 0.761463, -0.30680367, 0.0, 13.14152]]\n",
      "epoch 123: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.38004032, 0.76084113, -0.30691776, 0.0, 13.12413\n",
      "epoch 124: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3803889, 0.75945956, -0.30693418, 0.0, 13.103673\n",
      "epoch 125: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.37939996, 0.7596369, -0.30712146, 0.0, 13.105707\n",
      "epoch 126: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.37871832, 0.7592146, -0.3072388, 0.0, 13.096831]\n",
      "epoch 127: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3787568, 0.75803685, -0.30720586, 0.0, 13.074027\n",
      "epoch 128: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.37810495, 0.75770426, -0.3073076, 0.0, 13.067184\n",
      "epoch 129: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.37696126, 0.7584285, -0.3074923, 0.0, 13.083518]\n",
      "epoch 130: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.37662625, 0.7571166, -0.30757272, 0.0, 13.054056\n",
      "epoch 131: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.37631458, 0.7564717, -0.30744502, 0.0, 13.046042\n",
      "epoch 132: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.37570482, 0.7558425, -0.30759072, 0.0, 13.031188\n",
      "epoch 133: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.3757841, 0.7554371, -0.30767918, 0.0, 13.024655]\n",
      "epoch 134: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.3748668, 0.7553544, -0.30782074, 0.0, 13.022744]\n",
      "epoch 135: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.37435922, 0.75537074, -0.30790976, 0.0, 13.02508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.37486187, 0.7535401, -0.30778766, 0.0, 12.98348]\n",
      "epoch 137: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.37340495, 0.754269, -0.3080944, 0.0, 13.000617]]\n",
      "epoch 138: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.37322912, 0.7536792, -0.30802575, 0.0, 12.989768\n",
      "epoch 139: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.37297368, 0.7528816, -0.3080798, 0.0, 12.970537]\n",
      "epoch 140: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.37245795, 0.75275505, -0.3081618, 0.0, 12.970846\n",
      "epoch 141: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.996, loss=[0.37167034, 0.7529845, -0.30817482, 0.0, 12.976209\n",
      "epoch 142: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.37151024, 0.7520284, -0.3081847, 0.0, 12.952415]\n",
      "epoch 143: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.37144586, 0.7511862, -0.30818814, 0.0, 12.937993\n",
      "epoch 144: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.37106946, 0.75108075, -0.3082476, 0.0, 12.938177\n",
      "epoch 145: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.37047225, 0.75048965, -0.3083012, 0.0, 12.922585\n",
      "epoch 146: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3698725, 0.75075865, -0.3084436, 0.0, 12.933864]\n",
      "epoch 147: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36964226, 0.75028765, -0.30846864, 0.0, 12.92011\n",
      "epoch 148: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3686725, 0.75023603, -0.30852568, 0.0, 12.920426\n",
      "epoch 149: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3680719, 0.7496227, -0.30860814, 0.0, 12.905141]\n",
      "epoch 150: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36758378, 0.7494313, -0.30863544, 0.0, 12.906373\n",
      "epoch 151: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36780158, 0.74837077, -0.3086018, 0.0, 12.883568\n",
      "epoch 152: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36654565, 0.7491177, -0.30881757, 0.0, 12.899346\n",
      "epoch 153: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36663705, 0.7477898, -0.30860427, 0.0, 12.866494\n",
      "epoch 154: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3665405, 0.7475071, -0.30873567, 0.0, 12.863968]\n",
      "epoch 155: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3661802, 0.74772525, -0.30879477, 0.0, 12.870932\n",
      "epoch 156: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36573935, 0.7470166, -0.3087368, 0.0, 12.851147]\n",
      "epoch 157: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36518723, 0.7473376, -0.3089327, 0.0, 12.860639]\n",
      "epoch 158: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36485028, 0.7463417, -0.30885205, 0.0, 12.839375\n",
      "epoch 159: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36465386, 0.7461798, -0.30892956, 0.0, 12.836291\n",
      "epoch 160: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.997, loss=[0.36412665, 0.74610084, -0.3089938, 0.0, 12.832655\n",
      "epoch 161: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36389115, 0.74531746, -0.309035, 0.0, 12.8174305\n",
      "epoch 162: 100%|█| 169/169 [02:14<00:00,  1.25it/s, acc=0.997, loss=[0.36349553, 0.74542075, -0.30907723, 0.0, 12.82038\n",
      "epoch 163: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36354354, 0.744454, -0.30904436, 0.0, 12.801283]\n",
      "epoch 164: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36267346, 0.7449666, -0.30914247, 0.0, 12.812623\n",
      "epoch 165: 100%|██| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.362718, 0.743615, -0.30899423, 0.0, 12.785872]]\n",
      "epoch 166: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3619311, 0.74469024, -0.30928397, 0.0, 12.810404\n",
      "epoch 167: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.36185232, 0.74341345, -0.30919078, 0.0, 12.78192\n",
      "epoch 168: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.3611887, 0.7439847, -0.30935958, 0.0, 12.795241]\n",
      "epoch 169: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.36131856, 0.7429598, -0.30936065, 0.0, 12.772497\n",
      "epoch 170: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.36109158, 0.7423361, -0.3092991, 0.0, 12.761772]\n",
      "epoch 171: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.36052206, 0.74271506, -0.3094693, 0.0, 12.769601\n",
      "epoch 172: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3604331, 0.7422307, -0.30944136, 0.0, 12.762512]\n",
      "epoch 173: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.997, loss=[0.3603743, 0.7414294, -0.30944726, 0.0, 12.743405]\n",
      "epoch 174: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35938314, 0.7421643, -0.30957025, 0.0, 12.76091]\n",
      "epoch 175: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35996184, 0.74099404, -0.30951494, 0.0, 12.73613\n",
      "epoch 176: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35916007, 0.7409877, -0.30967194, 0.0, 12.735577\n",
      "epoch 177: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35919183, 0.74063337, -0.30961406, 0.0, 12.73120\n",
      "epoch 178: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.3584754, 0.740585, -0.30965623, 0.0, 12.727256]]\n",
      "epoch 179: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.3583071, 0.74051356, -0.30982026, 0.0, 12.732433\n",
      "epoch 180: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35834283, 0.7390617, -0.30971262, 0.0, 12.697053\n",
      "epoch 181: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.3577592, 0.7399815, -0.30988696, 0.0, 12.721831]\n",
      "epoch 182: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.3580843, 0.7385227, -0.30978745, 0.0, 12.69052]]\n",
      "epoch 183: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35684386, 0.7396533, -0.30993128, 0.0, 12.716099\n",
      "epoch 184: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35669246, 0.7390756, -0.31003436, 0.0, 12.703279\n",
      "epoch 185: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.3565351, 0.73840094, -0.30988383, 0.0, 12.688177\n",
      "epoch 186: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35619843, 0.7386874, -0.3100808, 0.0, 12.696314]\n",
      "epoch 187: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35563588, 0.73844874, -0.3100887, 0.0, 12.693418\n",
      "epoch 188: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35568538, 0.73751706, -0.31006905, 0.0, 12.67215\n",
      "epoch 189: 100%|██| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.355051, 0.7376054, -0.31013587, 0.0, 12.67394]]\n",
      "epoch 190: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35493174, 0.7374285, -0.31016767, 0.0, 12.673632\n",
      "epoch 191: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35502276, 0.7372129, -0.3101729, 0.0, 12.66981]]\n",
      "epoch 192: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35492074, 0.7364079, -0.31018573, 0.0, 12.648915\n",
      "epoch 193: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35442245, 0.73652786, -0.31023353, 0.0, 12.65507\n",
      "epoch 194: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.3538838, 0.7360086, -0.31022182, 0.0, 12.64269]]\n",
      "epoch 195: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35384345, 0.73624116, -0.31032062, 0.0, 12.64817\n",
      "epoch 196: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.3535389, 0.7360921, -0.31026417, 0.0, 12.646018]\n",
      "epoch 197: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.3533113, 0.7356617, -0.31035402, 0.0, 12.638375]\n",
      "epoch 198: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.35321042, 0.73516554, -0.3103366, 0.0, 12.624445\n",
      "epoch 199: 100%|█| 169/169 [02:14<00:00,  1.26it/s, acc=0.998, loss=[0.3524534, 0.73532784, -0.31045833, 0.0, 12.627958\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mE:\\Medical Imaging Diagnostic (MID) Lab\\XAI in MID\\my_implementation_interpretable_CNN\\my_interpretable_CNN.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0mipython\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[0mipython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reset -f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1109\u001b[1;33m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1110\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[1;31m#counterfactual_generator.load_weights(filepath=weights_path+'/counterfactual_generator_model.hdf5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "%run -i my_interpretable_CNN.py --train_counterfactual_net=True --alter_class=170 --cfe_epochs=200 --l1_weight=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
