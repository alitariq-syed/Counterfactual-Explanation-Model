{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-02T05:46:51.355891Z",
     "iopub.status.busy": "2020-12-02T05:46:51.355195Z",
     "iopub.status.idle": "2020-12-02T05:46:51.364899Z",
     "shell.execute_reply": "2020-12-02T05:46:51.365480Z"
    },
    "papermill": {
     "duration": 0.034974,
     "end_time": "2020-12-02T05:46:51.365646",
     "exception": false,
     "start_time": "2020-12-02T05:46:51.330672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:46:51.397975Z",
     "iopub.status.busy": "2020-12-02T05:46:51.397178Z",
     "iopub.status.idle": "2020-12-02T05:46:52.035175Z",
     "shell.execute_reply": "2020-12-02T05:46:52.034672Z"
    },
    "papermill": {
     "duration": 0.655323,
     "end_time": "2020-12-02T05:46:52.035282",
     "exception": false,
     "start_time": "2020-12-02T05:46:51.379959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-02T05:46:52.083545Z",
     "iopub.status.busy": "2020-12-02T05:46:52.082652Z",
     "iopub.status.idle": "2020-12-02T05:47:04.319825Z",
     "shell.execute_reply": "2020-12-02T05:47:04.319261Z"
    },
    "papermill": {
     "duration": 12.270234,
     "end_time": "2020-12-02T05:47:04.319946",
     "exception": false,
     "start_time": "2020-12-02T05:46:52.049712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir -p '/kaggle/temp/'\n",
    "# #!tar -xvzf '../input/200-bird-species-with-11788-images/CUB_200_2011.tgz' --directory '/kaggle/temp/'\n",
    "# !tar -xzf '../input/200-bird-species-with-11788-images/CUB_200_2011.tgz' --directory '/kaggle/temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:47:04.355204Z",
     "iopub.status.busy": "2020-12-02T05:47:04.354566Z",
     "iopub.status.idle": "2020-12-02T05:47:04.357672Z",
     "shell.execute_reply": "2020-12-02T05:47:04.358826Z"
    },
    "papermill": {
     "duration": 0.024228,
     "end_time": "2020-12-02T05:47:04.358969",
     "exception": false,
     "start_time": "2020-12-02T05:47:04.334741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# for dirname, _, filenames in os.walk('./'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:47:04.399315Z",
     "iopub.status.busy": "2020-12-02T05:47:04.398623Z",
     "iopub.status.idle": "2020-12-02T05:47:11.930448Z",
     "shell.execute_reply": "2020-12-02T05:47:11.929454Z"
    },
    "papermill": {
     "duration": 7.556338,
     "end_time": "2020-12-02T05:47:11.930596",
     "exception": false,
     "start_time": "2020-12-02T05:47:04.374258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.3.0\n",
      "...GPU set_memory_growth successfully set...\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import tensorflow as tf\n",
    "print('TF version: ', tf.__version__)\n",
    "\n",
    "#%% \n",
    "\"\"\"fix for issue: cuDNN failed to initialize\"\"\"\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices)>0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print('...GPU set_memory_growth successfully set...')\n",
    "\n",
    "else:\n",
    "    print('...GPU set_memory_growth not set...')\n",
    "\n",
    "#%%\n",
    "from tensorflow.keras.datasets import mnist, cifar10\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten,Softmax, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import math\n",
    "#from tf_explain_modified.core.grad_cam import GradCAM\n",
    "import datetime\n",
    "from tqdm import tqdm # to monitor progress\n",
    "import argparse\n",
    "import os, sys\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "# from models10 import MySubClassModel\n",
    "# from codes.compute_filter_importance import save_filter_importance, test_filter_importance,test_filter_importance_in_code_method, plot_filter_importance,check_top_filter_importance,save_filter_importance_batch, check_histogram_top_filter_result\n",
    "# from codes.load_cxr_dataset import create_cxr_dataframes, load_cxr_dataset\n",
    "# from codes.support_functions import print_filter_classes_1, print_filter_classes_2, save_interpretable_parameters\n",
    "# from codes.find_filter_class import find_filter_class\n",
    "# from codes.train_counterfactual_net import train_counterfactual_net\n",
    "# from codes.support_functions import get_heatmap_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:47:11.989291Z",
     "iopub.status.busy": "2020-12-02T05:47:11.981291Z",
     "iopub.status.idle": "2020-12-02T05:47:11.993816Z",
     "shell.execute_reply": "2020-12-02T05:47:11.994331Z"
    },
    "papermill": {
     "duration": 0.046688,
     "end_time": "2020-12-02T05:47:11.994513",
     "exception": false,
     "start_time": "2020-12-02T05:47:11.947825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_path:  ./trained_weights/efficientnet/CUB200/standard\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "KAGGLE = True\n",
    "parser = argparse.ArgumentParser(description='Interpretable CNN')\n",
    "parser.add_argument('--interpretable',default = False)\n",
    "parser.add_argument('--full_standard',default = True)## dont add extra cnn layer to be comparable with interpretable model. Make completely standalone model\n",
    "parser.add_argument('--train_using_builtin_fit_method',default = True)#for training base model easily\n",
    "\n",
    "parser.add_argument('--create_counterfactual_combined' ,default = False)## create CF model for a pretrained base model or train a new base model\n",
    "\n",
    "parser.add_argument('--train_counterfactual_net' ,default = False)## \n",
    "parser.add_argument('--resume_counterfactual_net' ,default = False)## \n",
    "parser.add_argument('--test_counterfactual_net' ,default = False)## \n",
    "parser.add_argument('--load_counterfactual_net',default = True)\n",
    "\n",
    "\n",
    "parser.add_argument('--resume', default =False) # load saved weights for base model\n",
    "parser.add_argument('--pretrained', default = False) # load self-pretrained model\n",
    "\n",
    "parser.add_argument('--find_filter_class', default = False) # load retrained model and assign class to each filter by check mean activation per filter per class\n",
    "\n",
    "parser.add_argument('--filter_modified_directly', default = True)\n",
    "parser.add_argument('--loss_compute', default = True)#False = forward only\n",
    "parser.add_argument('--high_capacity_model', default = True)#\n",
    "parser.add_argument('--fixed_classes', default = True)#idea 2: fine tune from forward only with fixed classes\n",
    "parser.add_argument('--fixed_classes_reduce_loss', default = True)#False = forward only masked with fixed filter class. issue: 100% training accuracy but 10% testing acc\n",
    "\n",
    "parser.add_argument('--test_filter_importance', default = False)#for testing idea 2\n",
    "parser.add_argument('--save_filter_importance', default = False)#for testing idea 2\n",
    "parser.add_argument('--analyze_filter_importance', default = False)#for testing idea 2\n",
    "parser.add_argument('--save_filter_fmap', default = False)#save filter fmap as well\n",
    "parser.add_argument('--save_top_layer', default = True)#save top layer filter data only\n",
    "\n",
    "parser.add_argument('--visualize_fmaps', default = False)\n",
    "\n",
    "#base model parameters\n",
    "parser.add_argument('--dataset',default = 'CUB200')#mnist, cifar10, CUB200, #cxr1000, #catsvsdogs, #VOC2010\n",
    "parser.add_argument('--save_directory',default = './trained_weights/')\n",
    "parser.add_argument('--train',default = True)\n",
    "parser.add_argument('--test', default = True)\n",
    "parser.add_argument('--model',default = 'efficientnet/')#myCNN, VGG16,resnet50, efficientnet\n",
    "parser.add_argument('--imagenet_weights',default = True) #use imageNet pretrained VGG\n",
    "\n",
    "parser.add_argument('--filter_category_method',default = 'own_reduce_loss')   # paper --> similar to paper implementation---assign filter with categories during training by accumulating batch-wise max activations\n",
    "                                                                    # own_reduce_loss --> our idea - pre-assign filter categories during forward pass over all the data, based on pretrained weights and feature maps\n",
    "\n",
    "\n",
    "#parser.add_argument('--test',default = True)\n",
    " \n",
    "if KAGGLE: args = parser.parse_known_args()[0] \n",
    "else: args = parser.parse_args()\n",
    "\n",
    "if args.interpretable:\n",
    "    if args.filter_category_method=='paper':\n",
    "        print('filter category assignment --> paper method')\n",
    "    else:\n",
    "        print('filter category assignment --> our idea')\n",
    "    weights_path = args.save_directory+args.model+args.dataset+'/interpretable/filter_category_method_'+str(args.filter_category_method)\n",
    "    log_path  = './logs/'+args.model+args.dataset+'/interpretable/filter_category_method_'+str(args.filter_category_method)\n",
    "    filter_data_path = './create_training_data/'+args.model+args.dataset+'/interpretable/filter_category_method_'+str(args.filter_category_method)\n",
    "else:\n",
    "    weights_path = args.save_directory+args.model+args.dataset+'/standard'\n",
    "    log_path  = './logs/'+args.model+args.dataset+'/standard'\n",
    "    filter_data_path = './create_training_data/'+args.model+args.dataset+'/standard' #directory for saving filter importance training data\n",
    "    \n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)    \n",
    "print('save_path: ',weights_path)\n",
    "\n",
    "parser.add_argument('--save_path',default = weights_path)\n",
    "if KAGGLE: args = parser.parse_known_args()[0] \n",
    "else: args = parser.parse_args()\n",
    "\n",
    "if args.resume:\n",
    "    print(\"resuming training\")\n",
    "#print(args)\n",
    "\n",
    "if args.model == 'VGG16/':\n",
    "    from tensorflow.keras.applications.vgg16 import VGG16,decode_predictions, preprocess_input\n",
    "elif args.model == 'resnet50/':\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input\n",
    "elif args.model == 'efficientnet/':\n",
    "    from tensorflow.keras.applications.efficientnet import EfficientNetB0, decode_predictions, preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE = False\n",
    "#(for jupyterbook issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:47:12.045274Z",
     "iopub.status.busy": "2020-12-02T05:47:12.033564Z",
     "iopub.status.idle": "2020-12-02T05:47:12.051929Z",
     "shell.execute_reply": "2020-12-02T05:47:12.051404Z"
    },
    "papermill": {
     "duration": 0.041573,
     "end_time": "2020-12-02T05:47:12.052019",
     "exception": false,
     "start_time": "2020-12-02T05:47:12.010446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUB200-2011 dataset\n",
      "official split not established for training on KAGGLE\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeeshan\\.conda\\envs\\tensorflow_23\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "batch_size = 32\n",
    "if args.dataset == 'mnist':\n",
    "    num_classes=10\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = np.expand_dims(x_train,-1)\n",
    "    x_test = np.expand_dims(x_test,-1)\n",
    "    input_shape = (batch_size,28,28,1)\n",
    "    label_map = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    \n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "elif args.dataset == 'cifar10':\n",
    "    num_classes=10\n",
    "    print('cifar-10 dataset')\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    input_shape = (batch_size,32,32,3)\n",
    "    label_map = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    \n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "elif args.dataset == 'CUB200':\n",
    "    print('CUB200-2011 dataset')\n",
    "    num_classes=200\n",
    "    input_shape = (batch_size,224,224,3)\n",
    "    official_split=True\n",
    "    lab_system=True\n",
    "    if KAGGLE:\n",
    "        if official_split:\n",
    "            print('official split not established for training on KAGGLE')\n",
    "            sys.exit()\n",
    "        else:\n",
    "            base_path = '/kaggle/temp/CUB_200_2011'\n",
    "    if lab_system:\n",
    "        base_path ='D:/Ali Tariq/CUB_200_2011'\n",
    "    else:\n",
    "        base_path = 'G:/CUB_200_2011/CUB_200_2011'\n",
    "    \n",
    "    if official_split:\n",
    "        data_dir =base_path+'/train_test_split/train/'\n",
    "        data_dir_test =base_path+'/train_test_split/test/'\n",
    "        label_map = np.loadtxt(fname=base_path + '/classes.txt',dtype='str')\n",
    "        label_map = label_map[:,1]\n",
    "        print('using official split')\n",
    "    else:\n",
    "        data_dir =base_path+'/images/'\n",
    "        label_map = np.loadtxt(fname=base_path + '/classes.txt',dtype='str')\n",
    "        label_map = label_map[:,1]\n",
    "\n",
    "elif args.dataset == 'cxr1000':\n",
    "    print('CXR-1000 dataset')\n",
    "    num_classes=15\n",
    "    input_shape = (batch_size,224,224,3)\n",
    "    label_map, train_df, test_df, valid_df = create_cxr_dataframes()\n",
    "    all_labels = label_map\n",
    "elif args.dataset == 'catsvsdogs':\n",
    "    print('catsvsdogs dataset')\n",
    "    num_classes=2\n",
    "    input_shape = (batch_size,224,224,3)\n",
    "    lab_system = False\n",
    "    if lab_system:\n",
    "        data_dir ='D:/Ali Tariq/catsvsdogs/train/'\n",
    "        data_dir_test ='D:/Ali Tariq/catsvsdogs/test/'    \n",
    "    else:\n",
    "        data_dir ='G:/catsvsdogs/train/'\n",
    "        data_dir_test ='G:/catsvsdogs/test/'\n",
    "\n",
    "    label_map = ['cat',  'dog']\n",
    "\n",
    "elif args.dataset == 'VOC2010':\n",
    "    print('VOC2010-animals dataset')\n",
    "    num_classes=6\n",
    "    input_shape = (batch_size,224,224,3)\n",
    "    lab_system = False\n",
    "    if lab_system:\n",
    "        data_dir ='D:/Ali Tariq/VOCdevkit/VOC_animals/'\n",
    "        #data_dir_test ='D:/Ali Tariq/catsvsdogs/test/'    \n",
    "    else:\n",
    "        #data_dir ='G:/VOCdevkit/VOC_animals_one/'\n",
    "        data_dir ='G:/VOCdevkit/VOC_animals/'\n",
    "        #data_dir_test ='G:/catsvsdogs/test/'\n",
    "\n",
    "    label_map = ['bird',  'cat', 'cow', 'dog', 'horse', 'sheep']#['cat']#\n",
    "\n",
    "else:\n",
    "    print('unknown dataset')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:47:12.090645Z",
     "iopub.status.busy": "2020-12-02T05:47:12.089989Z",
     "iopub.status.idle": "2020-12-02T05:47:12.095324Z",
     "shell.execute_reply": "2020-12-02T05:47:12.095802Z"
    },
    "papermill": {
     "duration": 0.027688,
     "end_time": "2020-12-02T05:47:12.095909",
     "exception": false,
     "start_time": "2020-12-02T05:47:12.068221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['001.Black_footed_Albatross', '002.Laysan_Albatross',\n",
       "       '003.Sooty_Albatross', '004.Groove_billed_Ani',\n",
       "       '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet',\n",
       "       '008.Rhinoceros_Auklet', '009.Brewer_Blackbird',\n",
       "       '010.Red_winged_Blackbird', '011.Rusty_Blackbird',\n",
       "       '012.Yellow_headed_Blackbird', '013.Bobolink',\n",
       "       '014.Indigo_Bunting', '015.Lazuli_Bunting', '016.Painted_Bunting',\n",
       "       '017.Cardinal', '018.Spotted_Catbird', '019.Gray_Catbird',\n",
       "       '020.Yellow_breasted_Chat', '021.Eastern_Towhee',\n",
       "       '022.Chuck_will_Widow', '023.Brandt_Cormorant',\n",
       "       '024.Red_faced_Cormorant', '025.Pelagic_Cormorant',\n",
       "       '026.Bronzed_Cowbird', '027.Shiny_Cowbird', '028.Brown_Creeper',\n",
       "       '029.American_Crow', '030.Fish_Crow', '031.Black_billed_Cuckoo',\n",
       "       '032.Mangrove_Cuckoo', '033.Yellow_billed_Cuckoo',\n",
       "       '034.Gray_crowned_Rosy_Finch', '035.Purple_Finch',\n",
       "       '036.Northern_Flicker', '037.Acadian_Flycatcher',\n",
       "       '038.Great_Crested_Flycatcher', '039.Least_Flycatcher',\n",
       "       '040.Olive_sided_Flycatcher', '041.Scissor_tailed_Flycatcher',\n",
       "       '042.Vermilion_Flycatcher', '043.Yellow_bellied_Flycatcher',\n",
       "       '044.Frigatebird', '045.Northern_Fulmar', '046.Gadwall',\n",
       "       '047.American_Goldfinch', '048.European_Goldfinch',\n",
       "       '049.Boat_tailed_Grackle', '050.Eared_Grebe', '051.Horned_Grebe',\n",
       "       '052.Pied_billed_Grebe', '053.Western_Grebe', '054.Blue_Grosbeak',\n",
       "       '055.Evening_Grosbeak', '056.Pine_Grosbeak',\n",
       "       '057.Rose_breasted_Grosbeak', '058.Pigeon_Guillemot',\n",
       "       '059.California_Gull', '060.Glaucous_winged_Gull',\n",
       "       '061.Heermann_Gull', '062.Herring_Gull', '063.Ivory_Gull',\n",
       "       '064.Ring_billed_Gull', '065.Slaty_backed_Gull',\n",
       "       '066.Western_Gull', '067.Anna_Hummingbird',\n",
       "       '068.Ruby_throated_Hummingbird', '069.Rufous_Hummingbird',\n",
       "       '070.Green_Violetear', '071.Long_tailed_Jaeger',\n",
       "       '072.Pomarine_Jaeger', '073.Blue_Jay', '074.Florida_Jay',\n",
       "       '075.Green_Jay', '076.Dark_eyed_Junco', '077.Tropical_Kingbird',\n",
       "       '078.Gray_Kingbird', '079.Belted_Kingfisher',\n",
       "       '080.Green_Kingfisher', '081.Pied_Kingfisher',\n",
       "       '082.Ringed_Kingfisher', '083.White_breasted_Kingfisher',\n",
       "       '084.Red_legged_Kittiwake', '085.Horned_Lark', '086.Pacific_Loon',\n",
       "       '087.Mallard', '088.Western_Meadowlark', '089.Hooded_Merganser',\n",
       "       '090.Red_breasted_Merganser', '091.Mockingbird', '092.Nighthawk',\n",
       "       '093.Clark_Nutcracker', '094.White_breasted_Nuthatch',\n",
       "       '095.Baltimore_Oriole', '096.Hooded_Oriole', '097.Orchard_Oriole',\n",
       "       '098.Scott_Oriole', '099.Ovenbird', '100.Brown_Pelican',\n",
       "       '101.White_Pelican', '102.Western_Wood_Pewee', '103.Sayornis',\n",
       "       '104.American_Pipit', '105.Whip_poor_Will', '106.Horned_Puffin',\n",
       "       '107.Common_Raven', '108.White_necked_Raven',\n",
       "       '109.American_Redstart', '110.Geococcyx', '111.Loggerhead_Shrike',\n",
       "       '112.Great_Grey_Shrike', '113.Baird_Sparrow',\n",
       "       '114.Black_throated_Sparrow', '115.Brewer_Sparrow',\n",
       "       '116.Chipping_Sparrow', '117.Clay_colored_Sparrow',\n",
       "       '118.House_Sparrow', '119.Field_Sparrow', '120.Fox_Sparrow',\n",
       "       '121.Grasshopper_Sparrow', '122.Harris_Sparrow',\n",
       "       '123.Henslow_Sparrow', '124.Le_Conte_Sparrow',\n",
       "       '125.Lincoln_Sparrow', '126.Nelson_Sharp_tailed_Sparrow',\n",
       "       '127.Savannah_Sparrow', '128.Seaside_Sparrow', '129.Song_Sparrow',\n",
       "       '130.Tree_Sparrow', '131.Vesper_Sparrow',\n",
       "       '132.White_crowned_Sparrow', '133.White_throated_Sparrow',\n",
       "       '134.Cape_Glossy_Starling', '135.Bank_Swallow', '136.Barn_Swallow',\n",
       "       '137.Cliff_Swallow', '138.Tree_Swallow', '139.Scarlet_Tanager',\n",
       "       '140.Summer_Tanager', '141.Artic_Tern', '142.Black_Tern',\n",
       "       '143.Caspian_Tern', '144.Common_Tern', '145.Elegant_Tern',\n",
       "       '146.Forsters_Tern', '147.Least_Tern', '148.Green_tailed_Towhee',\n",
       "       '149.Brown_Thrasher', '150.Sage_Thrasher',\n",
       "       '151.Black_capped_Vireo', '152.Blue_headed_Vireo',\n",
       "       '153.Philadelphia_Vireo', '154.Red_eyed_Vireo',\n",
       "       '155.Warbling_Vireo', '156.White_eyed_Vireo',\n",
       "       '157.Yellow_throated_Vireo', '158.Bay_breasted_Warbler',\n",
       "       '159.Black_and_white_Warbler', '160.Black_throated_Blue_Warbler',\n",
       "       '161.Blue_winged_Warbler', '162.Canada_Warbler',\n",
       "       '163.Cape_May_Warbler', '164.Cerulean_Warbler',\n",
       "       '165.Chestnut_sided_Warbler', '166.Golden_winged_Warbler',\n",
       "       '167.Hooded_Warbler', '168.Kentucky_Warbler',\n",
       "       '169.Magnolia_Warbler', '170.Mourning_Warbler',\n",
       "       '171.Myrtle_Warbler', '172.Nashville_Warbler',\n",
       "       '173.Orange_crowned_Warbler', '174.Palm_Warbler',\n",
       "       '175.Pine_Warbler', '176.Prairie_Warbler',\n",
       "       '177.Prothonotary_Warbler', '178.Swainson_Warbler',\n",
       "       '179.Tennessee_Warbler', '180.Wilson_Warbler',\n",
       "       '181.Worm_eating_Warbler', '182.Yellow_Warbler',\n",
       "       '183.Northern_Waterthrush', '184.Louisiana_Waterthrush',\n",
       "       '185.Bohemian_Waxwing', '186.Cedar_Waxwing',\n",
       "       '187.American_Three_toed_Woodpecker', '188.Pileated_Woodpecker',\n",
       "       '189.Red_bellied_Woodpecker', '190.Red_cockaded_Woodpecker',\n",
       "       '191.Red_headed_Woodpecker', '192.Downy_Woodpecker',\n",
       "       '193.Bewick_Wren', '194.Cactus_Wren', '195.Carolina_Wren',\n",
       "       '196.House_Wren', '197.Marsh_Wren', '198.Rock_Wren',\n",
       "       '199.Winter_Wren', '200.Common_Yellowthroat'], dtype='<U34')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:47:12.150292Z",
     "iopub.status.busy": "2020-12-02T05:47:12.142828Z",
     "iopub.status.idle": "2020-12-02T05:47:13.338468Z",
     "shell.execute_reply": "2020-12-02T05:47:13.339591Z"
    },
    "papermill": {
     "duration": 1.227013,
     "end_time": "2020-12-02T05:47:13.339775",
     "exception": false,
     "start_time": "2020-12-02T05:47:12.112762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet_weights\n",
      "Found 5400 images belonging to 200 classes.\n",
      "Found 594 images belonging to 200 classes.\n",
      "Found 5400 images belonging to 200 classes.\n",
      "Found 594 images belonging to 200 classes.\n",
      "Found 5794 images belonging to 200 classes.\n",
      "Found 5794 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "if args.imagenet_weights:\n",
    "    print('using imagenet_weights')\n",
    "\n",
    "    if args.dataset == 'cifar10':\n",
    "        imgDataGen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "                                        #rescale = 1./255)\n",
    "\n",
    "        train_gen = imgDataGen.flow(x_train, y_train, batch_size = batch_size,shuffle= False)\n",
    "        test_gen  = imgDataGen.flow(x_test, y_test, batch_size = batch_size,shuffle= False)\n",
    "    else:\n",
    "        augment = False\n",
    "        if not augment:\n",
    "            imgDataGen = ImageDataGenerator(preprocessing_function = preprocess_input, \n",
    "                                            #rescale = 1./255,\n",
    "                                            validation_split=0.1)\n",
    "        else:\n",
    "            imgDataGen = ImageDataGenerator(preprocessing_function = preprocess_input, \n",
    "                                        #rescale = 1./255,\n",
    "                                        validation_split=0.1,\n",
    "                                        \n",
    "                              height_shift_range= 0.2, \n",
    "                              width_shift_range=0.2, \n",
    "                              rotation_range=15, \n",
    "                              shear_range = 0.2,\n",
    "                              fill_mode = 'nearest',#''nearest#reflect\n",
    "                              zoom_range=0.2)\n",
    "        \n",
    "        train_gen = imgDataGen.flow_from_directory(data_dir,\n",
    "                                target_size=(input_shape[1], input_shape[2]),\n",
    "                                color_mode='rgb',\n",
    "                                class_mode='categorical',\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                seed=None,\n",
    "                                subset='training',\n",
    "                                interpolation='nearest')#,\n",
    "                                #all classes for base model; binary classes for CF model\n",
    "                                #classes = ['cat', 'dog'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = ['cat'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = label_map)\n",
    "        test_gen  = imgDataGen.flow_from_directory(data_dir,\n",
    "                                target_size=(input_shape[1], input_shape[2]),\n",
    "                                color_mode='rgb',\n",
    "                                class_mode='categorical',\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                seed=None,\n",
    "                                subset='validation',\n",
    "                                interpolation='nearest')#,\n",
    "                                #classes = ['cat', 'dog'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = ['cat'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                               # classes = label_map)\n",
    "        \n",
    "        # for visualization, dont use preprocessed image\n",
    "        imgDataGen_nopreprocess = ImageDataGenerator(#preprocessing_function = preprocess_input, \n",
    "                                        rescale = 1./255,\n",
    "                                        validation_split=0.1)\n",
    "        \n",
    "        train_gen_nopreprocess = imgDataGen_nopreprocess.flow_from_directory(data_dir,\n",
    "                                target_size=(input_shape[1], input_shape[2]),\n",
    "                                color_mode='rgb',\n",
    "                                class_mode='categorical',\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                seed=None,\n",
    "                                subset='training',\n",
    "                                interpolation='nearest'),\n",
    "                                #classes = ['cat', 'dog'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = ['cat'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = label_map)\n",
    "        test_gen_nopreprocess  = imgDataGen_nopreprocess.flow_from_directory(data_dir,\n",
    "                                target_size=(input_shape[1], input_shape[2]),\n",
    "                                color_mode='rgb',\n",
    "                                class_mode='categorical',\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                seed=None,\n",
    "                                subset='validation',\n",
    "                                interpolation='nearest'),\n",
    "                                #classes = ['cat', 'dog'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = ['cat'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = label_\n",
    "        if args.dataset == 'CUB200' and official_split:\n",
    "            #actual unseen test set\n",
    "            imgDataGen_official_split = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "            actual_test_gen  = imgDataGen_official_split.flow_from_directory(data_dir_test,\n",
    "                            target_size=(input_shape[1], input_shape[2]),\n",
    "                            color_mode='rgb',\n",
    "                            class_mode='categorical',\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            seed=None,\n",
    "                            #subset='validation',\n",
    "                            interpolation='nearest')\n",
    "            imgDataGen_official_split_nopreprocess = ImageDataGenerator(rescale = 1./255)\n",
    "            actual_test_gen_nopreprocess  = imgDataGen_official_split_nopreprocess.flow_from_directory(data_dir_test,\n",
    "                            target_size=(input_shape[1], input_shape[2]),\n",
    "                            color_mode='rgb',\n",
    "                            class_mode='categorical',\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            seed=None,\n",
    "                            #subset='validation',\n",
    "                            interpolation='nearest')\n",
    "elif args.dataset == 'cxr1000':\n",
    "    train_gen, test_gen, valid_gen = load_cxr_dataset(train_df, test_df, valid_df, all_labels, batch_size)\n",
    "    \n",
    "else:\n",
    "    print('not using imagenet_weights')\n",
    "\n",
    "    imgDataGen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    train_gen = imgDataGen.flow(x_train, y_train, batch_size = batch_size,shuffle= False)\n",
    "    test_gen  = imgDataGen.flow(x_test, y_test, batch_size = batch_size,shuffle= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:47:13.405065Z",
     "iopub.status.busy": "2020-12-02T05:47:13.404226Z",
     "iopub.status.idle": "2020-12-02T05:47:17.109487Z",
     "shell.execute_reply": "2020-12-02T05:47:17.109938Z"
    },
    "papermill": {
     "duration": 3.742196,
     "end_time": "2020-12-02T05:47:17.110077",
     "exception": false,
     "start_time": "2020-12-02T05:47:13.367881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VGG model\n",
      "using efficientnet imagenet weights for CUB200 dataset\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 15s 1us/step\n",
      "input_2\n",
      "rescaling\n",
      "normalization\n",
      "stem_conv_pad\n",
      "stem_conv\n",
      "stem_bn\n",
      "stem_activation\n",
      "block1a_dwconv\n",
      "block1a_bn\n",
      "block1a_activation\n",
      "block1a_se_squeeze\n",
      "block1a_se_reshape\n",
      "block1a_se_reduce\n",
      "block1a_se_expand\n",
      "block1a_se_excite\n",
      "block1a_project_conv\n",
      "block1a_project_bn\n",
      "block2a_expand_conv\n",
      "block2a_expand_bn\n",
      "block2a_expand_activation\n",
      "block2a_dwconv_pad\n",
      "block2a_dwconv\n",
      "block2a_bn\n",
      "block2a_activation\n",
      "block2a_se_squeeze\n",
      "block2a_se_reshape\n",
      "block2a_se_reduce\n",
      "block2a_se_expand\n",
      "block2a_se_excite\n",
      "block2a_project_conv\n",
      "block2a_project_bn\n",
      "block2b_expand_conv\n",
      "block2b_expand_bn\n",
      "block2b_expand_activation\n",
      "block2b_dwconv\n",
      "block2b_bn\n",
      "block2b_activation\n",
      "block2b_se_squeeze\n",
      "block2b_se_reshape\n",
      "block2b_se_reduce\n",
      "block2b_se_expand\n",
      "block2b_se_excite\n",
      "block2b_project_conv\n",
      "block2b_project_bn\n",
      "block2b_drop\n",
      "block2b_add\n",
      "block3a_expand_conv\n",
      "block3a_expand_bn\n",
      "block3a_expand_activation\n",
      "block3a_dwconv_pad\n",
      "block3a_dwconv\n",
      "block3a_bn\n",
      "block3a_activation\n",
      "block3a_se_squeeze\n",
      "block3a_se_reshape\n",
      "block3a_se_reduce\n",
      "block3a_se_expand\n",
      "block3a_se_excite\n",
      "block3a_project_conv\n",
      "block3a_project_bn\n",
      "block3b_expand_conv\n",
      "block3b_expand_bn\n",
      "block3b_expand_activation\n",
      "block3b_dwconv\n",
      "block3b_bn\n",
      "block3b_activation\n",
      "block3b_se_squeeze\n",
      "block3b_se_reshape\n",
      "block3b_se_reduce\n",
      "block3b_se_expand\n",
      "block3b_se_excite\n",
      "block3b_project_conv\n",
      "block3b_project_bn\n",
      "block3b_drop\n",
      "block3b_add\n",
      "block4a_expand_conv\n",
      "block4a_expand_bn\n",
      "block4a_expand_activation\n",
      "block4a_dwconv_pad\n",
      "block4a_dwconv\n",
      "block4a_bn\n",
      "block4a_activation\n",
      "block4a_se_squeeze\n",
      "block4a_se_reshape\n",
      "block4a_se_reduce\n",
      "block4a_se_expand\n",
      "block4a_se_excite\n",
      "block4a_project_conv\n",
      "block4a_project_bn\n",
      "block4b_expand_conv\n",
      "block4b_expand_bn\n",
      "block4b_expand_activation\n",
      "block4b_dwconv\n",
      "block4b_bn\n",
      "block4b_activation\n",
      "block4b_se_squeeze\n",
      "block4b_se_reshape\n",
      "block4b_se_reduce\n",
      "block4b_se_expand\n",
      "block4b_se_excite\n",
      "block4b_project_conv\n",
      "block4b_project_bn\n",
      "block4b_drop\n",
      "block4b_add\n",
      "block4c_expand_conv\n",
      "block4c_expand_bn\n",
      "block4c_expand_activation\n",
      "block4c_dwconv\n",
      "block4c_bn\n",
      "block4c_activation\n",
      "block4c_se_squeeze\n",
      "block4c_se_reshape\n",
      "block4c_se_reduce\n",
      "block4c_se_expand\n",
      "block4c_se_excite\n",
      "block4c_project_conv\n",
      "block4c_project_bn\n",
      "block4c_drop\n",
      "block4c_add\n",
      "block5a_expand_conv\n",
      "block5a_expand_bn\n",
      "block5a_expand_activation\n",
      "block5a_dwconv\n",
      "block5a_bn\n",
      "block5a_activation\n",
      "block5a_se_squeeze\n",
      "block5a_se_reshape\n",
      "block5a_se_reduce\n",
      "block5a_se_expand\n",
      "block5a_se_excite\n",
      "block5a_project_conv\n",
      "block5a_project_bn\n",
      "block5b_expand_conv\n",
      "block5b_expand_bn\n",
      "block5b_expand_activation\n",
      "block5b_dwconv\n",
      "block5b_bn\n",
      "block5b_activation\n",
      "block5b_se_squeeze\n",
      "block5b_se_reshape\n",
      "block5b_se_reduce\n",
      "block5b_se_expand\n",
      "block5b_se_excite\n",
      "block5b_project_conv\n",
      "block5b_project_bn\n",
      "block5b_drop\n",
      "block5b_add\n",
      "block5c_expand_conv\n",
      "block5c_expand_bn\n",
      "block5c_expand_activation\n",
      "block5c_dwconv\n",
      "block5c_bn\n",
      "block5c_activation\n",
      "block5c_se_squeeze\n",
      "block5c_se_reshape\n",
      "block5c_se_reduce\n",
      "block5c_se_expand\n",
      "block5c_se_excite\n",
      "block5c_project_conv\n",
      "block5c_project_bn\n",
      "block5c_drop\n",
      "block5c_add\n",
      "block6a_expand_conv\n",
      "block6a_expand_bn\n",
      "block6a_expand_activation\n",
      "block6a_dwconv_pad\n",
      "block6a_dwconv\n",
      "block6a_bn\n",
      "block6a_activation\n",
      "block6a_se_squeeze\n",
      "block6a_se_reshape\n",
      "block6a_se_reduce\n",
      "block6a_se_expand\n",
      "block6a_se_excite\n",
      "block6a_project_conv\n",
      "block6a_project_bn\n",
      "block6b_expand_conv\n",
      "block6b_expand_bn\n",
      "block6b_expand_activation\n",
      "block6b_dwconv\n",
      "block6b_bn\n",
      "block6b_activation\n",
      "block6b_se_squeeze\n",
      "block6b_se_reshape\n",
      "block6b_se_reduce\n",
      "block6b_se_expand\n",
      "block6b_se_excite\n",
      "block6b_project_conv\n",
      "block6b_project_bn\n",
      "block6b_drop\n",
      "block6b_add\n",
      "block6c_expand_conv\n",
      "block6c_expand_bn\n",
      "block6c_expand_activation\n",
      "block6c_dwconv\n",
      "block6c_bn\n",
      "block6c_activation\n",
      "block6c_se_squeeze\n",
      "block6c_se_reshape\n",
      "block6c_se_reduce\n",
      "block6c_se_expand\n",
      "block6c_se_excite\n",
      "block6c_project_conv\n",
      "block6c_project_bn\n",
      "block6c_drop\n",
      "block6c_add\n",
      "block6d_expand_conv\n",
      "block6d_expand_bn\n",
      "block6d_expand_activation\n",
      "block6d_dwconv\n",
      "block6d_bn\n",
      "block6d_activation\n",
      "block6d_se_squeeze\n",
      "block6d_se_reshape\n",
      "block6d_se_reduce\n",
      "block6d_se_expand\n",
      "block6d_se_excite\n",
      "block6d_project_conv\n",
      "block6d_project_bn\n",
      "block6d_drop\n",
      "block6d_add\n",
      "block7a_expand_conv\n",
      "block7a_expand_bn\n",
      "block7a_expand_activation\n",
      "block7a_dwconv\n",
      "block7a_bn\n",
      "block7a_activation\n",
      "block7a_se_squeeze\n",
      "block7a_se_reshape\n",
      "block7a_se_reduce\n",
      "block7a_se_expand\n",
      "block7a_se_excite\n",
      "block7a_project_conv\n",
      "block7a_project_bn\n",
      "top_conv\n",
      "top_bn\n",
      "top_activation\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "if args.imagenet_weights:\n",
    "    print('loading VGG model')\n",
    "    if args.dataset == 'cxr1000':\n",
    "        tr = 1\n",
    "        if tr:\n",
    "            print('using imagenet weights for CXR dataset')\n",
    "            vgg = VGG16(weights='imagenet',include_top = True)#top needed to get output dimensions at each layer\n",
    "                # EfficientNetB0(include_top=True,\n",
    "                #                weights=None,\n",
    "                #                input_shape=img_shape,\n",
    "                #                classes=len(all_labels),\n",
    "                #                classifier_activation='sigmoid')\n",
    "            base_model = tf.keras.Model(vgg.input,vgg.layers[-6].output)\n",
    "            #model.compile(optimizer = optimizers.RMSprop(), loss = 'binary_crossentropy',#adam #weighted_binary_crossentropy #lr=0.001/2#binary_crossentropy\n",
    "                                       #metrics = ['binary_accuracy'])#,tf.keras.metrics.AUC()])\n",
    "        else:\n",
    "            print('loading saved model - NOT IMPLEMENTED YET')\n",
    "            #model = load_model('../input/efnb0-saved-weights/xray_class_EfficientNetB4_15_class_CEL_heatmap_imagenet_pretrained_weights.05-0.1807.hdf5')\n",
    "        \n",
    "        #model.summary()\n",
    "    elif args.dataset == 'cifar10':\n",
    "        print('using imagenet weights for cifar10 dataset')\n",
    "        vgg = VGG16(weights='imagenet',include_top = False,input_shape=(32,32,3))#top needed to get output dimensions at each layer\n",
    "        freeze=True\n",
    "        if freeze:\n",
    "            for layer in vgg.layers:\n",
    "                layer.trainable = False\n",
    "        base_model = tf.keras.Model(vgg.input,vgg.layers[-2].output)\n",
    "    elif args.dataset == 'CUB200':\n",
    "        if args.model == 'VGG16/':\n",
    "           print('using VGG16 imagenet weights for CUB200 dataset')\n",
    "           vgg = VGG16(weights='imagenet',include_top = False,input_shape=(224,224,3))#top needed to get output dimensions at each layer\n",
    "           freeze=True\n",
    "           if freeze:\n",
    "               for layer in vgg.layers:\n",
    "                   print (layer.name)\n",
    "                   if layer.name == '----block5_conv3': continue\n",
    "                   else: layer.trainable = False\n",
    "           base_model = tf.keras.Model(vgg.input,vgg.layers[-2].output)\n",
    "        elif args.model == 'resnet50/':\n",
    "           print('using resnet50 imagenet weights for CUB200 dataset')\n",
    "           vgg = ResNet50(weights='imagenet',include_top = False,input_shape=(224,224,3))#top needed to get output dimensions at each layer\n",
    "           freeze=True\n",
    "           if freeze:\n",
    "               for layer in vgg.layers:\n",
    "                   print (layer.name)\n",
    "                   if layer.name == '----block5_conv3': continue\n",
    "                   else: layer.trainable = False\n",
    "           base_model = tf.keras.Model(vgg.input,vgg.output)\n",
    "        elif args.model == 'efficientnet/':\n",
    "               print('using efficientnet imagenet weights for CUB200 dataset')\n",
    "               vgg = EfficientNetB0(weights='imagenet',include_top = False,input_shape=(224,224,3))#top needed to get output dimensions at each layer\n",
    "               freeze=True\n",
    "               if freeze:\n",
    "                   for layer in vgg.layers:\n",
    "                       print (layer.name)\n",
    "                       if layer.name == '----block5_conv3': continue\n",
    "                       else: layer.trainable = False\n",
    "               base_model = tf.keras.Model(vgg.input,vgg.output)\n",
    "    elif args.dataset == 'catsvsdogs':\n",
    "        print('using imagenet weights for catsvsdogs dataset')\n",
    "        vgg = VGG16(weights='imagenet',include_top = False,input_shape=(224,224,3))#top needed to get output dimensions at each layer\n",
    "        freeze=True\n",
    "        if freeze:\n",
    "            for layer in vgg.layers:\n",
    "                layer.trainable = False\n",
    "        base_model = tf.keras.Model(vgg.input,vgg.layers[-2].output)\n",
    "    elif args.dataset == 'VOC2010':\n",
    "        print('using imagenet weights for VOC2010-animals dataset')\n",
    "        vgg = VGG16(weights='imagenet',include_top = False,input_shape=(224,224,3))#top needed to get output dimensions at each layer\n",
    "        freeze=True\n",
    "        if freeze:\n",
    "            for layer in vgg.layers:\n",
    "                layer.trainable = False\n",
    "        base_model = tf.keras.Model(vgg.input,vgg.layers[-2].output)\n",
    "else:\n",
    "    #base_model = VGG16(weights=None,include_top = False)\n",
    "    base_model = MyFunctionalModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 224, 224, 3)  7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 225, 225, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 112, 112, 32) 864         stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 112, 112, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 112, 112, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 112, 112, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 112, 112, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 112, 112, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 112, 112, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 112, 112, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 112, 112, 96) 1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 112, 112, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 112, 112, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 113, 113, 96) 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 56, 56, 96)   864         block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 56, 56, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 56, 56, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 56, 56, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 56, 56, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 56, 56, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 56, 56, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 56, 56, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 56, 56, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 56, 56, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 56, 56, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 56, 56, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 56, 56, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 56, 56, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 56, 56, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 56, 56, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 56, 56, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 56, 56, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 59, 59, 144)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 28, 28, 144)  3600        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 28, 28, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 28, 28, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 28, 28, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 28, 28, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 28, 28, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 28, 28, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 28, 28, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 28, 28, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 28, 28, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 28, 28, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 28, 28, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 28, 28, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 28, 28, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 28, 28, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 28, 28, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 28, 28, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 28, 28, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 29, 29, 240)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 14, 14, 240)  2160        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 14, 14, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 14, 14, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 14, 14, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 14, 14, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 14, 14, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 14, 14, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 14, 14, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 14, 14, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 14, 14, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 14, 14, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 14, 14, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 14, 14, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 14, 14, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 14, 14, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 14, 14, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 14, 14, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 14, 14, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 14, 14, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 14, 14, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 14, 14, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 14, 14, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 14, 14, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 14, 14, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 14, 14, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 14, 14, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 14, 14, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 14, 14, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 14, 14, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 14, 14, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 14, 14, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 14, 14, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 14, 14, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 14, 14, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 14, 14, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 14, 14, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 14, 14, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 14, 14, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 17, 17, 672)  0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 7, 7, 672)    16800       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 7, 7, 672)    2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 7, 7, 672)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 7, 7, 672)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 7, 7, 192)    129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 7, 7, 192)    768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 7, 7, 1152)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 7, 7, 1152)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 7, 7, 192)    768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 7, 7, 192)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 7, 7, 192)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 7, 7, 1152)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 7, 7, 1152)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 7, 7, 192)    768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 7, 7, 192)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 7, 7, 192)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 7, 7, 1152)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 7, 7, 1152)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 7, 7, 192)    768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 7, 7, 192)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 7, 7, 192)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 7, 7, 1152)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 7, 7, 1152)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 7, 7, 1152)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 7, 7, 320)    368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 7, 7, 320)    1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 7, 7, 1280)   409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 7, 7, 1280)   5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 7, 7, 1280)   0           top_bn[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,049,571\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,049,571\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:47:17.180013Z",
     "iopub.status.busy": "2020-12-02T05:47:17.179015Z",
     "iopub.status.idle": "2020-12-02T05:47:17.289185Z",
     "shell.execute_reply": "2020-12-02T05:47:17.290340Z"
    },
    "papermill": {
     "duration": 0.156274,
     "end_time": "2020-12-02T05:47:17.290542",
     "exception": false,
     "start_time": "2020-12-02T05:47:17.134268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 224, 224, 3)  7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 225, 225, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 112, 112, 32) 864         stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 112, 112, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 112, 112, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 112, 112, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 112, 112, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 112, 112, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 112, 112, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 112, 112, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 112, 112, 96) 1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 112, 112, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 112, 112, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 113, 113, 96) 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 56, 56, 96)   864         block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 56, 56, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 56, 56, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 56, 56, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 56, 56, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 56, 56, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 56, 56, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 56, 56, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 56, 56, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 56, 56, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 56, 56, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 56, 56, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 56, 56, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 56, 56, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 56, 56, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 56, 56, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 56, 56, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 56, 56, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 59, 59, 144)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 28, 28, 144)  3600        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 28, 28, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 28, 28, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 28, 28, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 28, 28, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 28, 28, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 28, 28, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 28, 28, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 28, 28, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 28, 28, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 28, 28, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 28, 28, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 28, 28, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 28, 28, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 28, 28, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 28, 28, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 28, 28, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 28, 28, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 29, 29, 240)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 14, 14, 240)  2160        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 14, 14, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 14, 14, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 14, 14, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 14, 14, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 14, 14, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 14, 14, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 14, 14, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 14, 14, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 14, 14, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 14, 14, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 14, 14, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 14, 14, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 14, 14, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 14, 14, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 14, 14, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 14, 14, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 14, 14, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 14, 14, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 14, 14, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 14, 14, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 14, 14, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 14, 14, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 14, 14, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 14, 14, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 14, 14, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 14, 14, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 14, 14, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 14, 14, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 14, 14, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 14, 14, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 14, 14, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 14, 14, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 14, 14, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 14, 14, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 14, 14, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 14, 14, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 14, 14, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 17, 17, 672)  0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 7, 7, 672)    16800       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 7, 7, 672)    2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 7, 7, 672)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 7, 7, 672)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 7, 7, 192)    129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 7, 7, 192)    768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 7, 7, 1152)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 7, 7, 1152)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 7, 7, 192)    768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 7, 7, 192)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 7, 7, 192)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 7, 7, 1152)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 7, 7, 1152)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 7, 7, 192)    768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 7, 7, 192)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 7, 7, 192)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 7, 7, 1152)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 7, 7, 1152)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 7, 7, 192)    768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 7, 7, 192)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 7, 7, 192)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 7, 7, 1152)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 7, 7, 1152)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 7, 7, 1152)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 7, 7, 320)    368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 7, 7, 320)    1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 7, 7, 1280)   409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 7, 7, 1280)   5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 7, 7, 1280)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1280)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1280)         0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200)          256200      dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,305,771\n",
      "Trainable params: 256,200\n",
      "Non-trainable params: 4,049,571\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#%% create base model\n",
    "if args.full_standard:\n",
    "    top_filters = base_model.output_shape[3] # flters in top conv layer (512 for VGG)\n",
    "    fmatrix = tf.keras.layers.Input(shape=(top_filters))\n",
    "    #flag = tf.keras.layers.Input(shape=(1))\n",
    "    \n",
    "    if args.model == 'VGG16/':\n",
    "        x =  MaxPool2D()(base_model.output)\n",
    "    elif args.model == 'resnet50/':\n",
    "        x =  base_model.output\n",
    "    elif args.model == 'efficientnet/':\n",
    "        x =  base_model.output\n",
    "    mean_fmap = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    #modify base model (once it has been pre-trained separately) to be used with CF model later\n",
    "    if args.create_counterfactual_combined:\n",
    "        #modified_fmap = tf.cond(tf.reduce_sum(fmatrix)>511, lambda: mean_fmap, lambda: mean_fmap*fmatrix)#modified_fmap = mean_fmap*fmatrix\n",
    "        modified_fmap = mean_fmap*fmatrix\n",
    "        pre_softmax = Dense(num_classes,activation=None)(modified_fmap)\n",
    "        x = tf.keras.layers.Activation('softmax')(pre_softmax)\n",
    "        model = tf.keras.Model(inputs=[base_model.input, fmatrix], outputs= [x,base_model.output, mean_fmap, modified_fmap,pre_softmax],name='VGG_base_model')\n",
    "        default_fmatrix = tf.ones((train_gen.batch_size,base_model.output.shape[3]))\n",
    "    else:\n",
    "        x = tf.keras.layers.Dropout(0.5)(mean_fmap)\n",
    "        \n",
    "        #x = Dense(512,activation='relu')(x)\n",
    "        #x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        \n",
    "        #x = Dense(512,activation='relu')(x)\n",
    "\n",
    "        x = Dense(num_classes,activation='softmax')(x)\n",
    "        if args.train_using_builtin_fit_method:\n",
    "            model = tf.keras.Model(inputs=base_model.input, outputs= [x])#, base_model.output])\n",
    "        else:\n",
    "            model = tf.keras.Model(inputs=base_model.input, outputs= [x, base_model.output])\n",
    "else:\n",
    "    model = MySubClassModel(num_classes=num_classes, base_model=base_model, args=args)\n",
    "    #model = base_model\n",
    "    model(tf.zeros(input_shape))\n",
    "    #model.build(input_shape = input_shape)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#model.load_weights('./trained_weights/VGG16/CUB200/standard/model.09-2.3280.hdf5')\n",
    "#load saved weights\n",
    "if args.resume:\n",
    "    #model.load_weights('./trained_weights/myCNN/cifar10/standard/model.hdf5')\n",
    "    #model.load_weights('./trained_weights/myCNN/cifar10/interpretable/filter_category_method_paper/from_pretrained_model.hdf5')\n",
    "    model.load_weights(filepath=weights_path+'/model.hdf5')\n",
    "    #model.load_weights('./trained_weights/myCNN/cifar10/interpretable/filter_category_method_paper/model.hdf5')\n",
    "\n",
    "    print(\"weights loaded\")\n",
    "if args.pretrained:\n",
    "    model.load_weights('./trained_weights/myCNN/cifar10/standard/model.hdf5')\n",
    "    print(\"pretrained weights loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T05:47:17.373894Z",
     "iopub.status.busy": "2020-12-02T05:47:17.372865Z",
     "iopub.status.idle": "2020-12-02T06:09:37.030831Z",
     "shell.execute_reply": "2020-12-02T06:09:37.029936Z"
    },
    "papermill": {
     "duration": 1339.700017,
     "end_time": "2020-12-02T06:09:37.030951",
     "exception": false,
     "start_time": "2020-12-02T05:47:17.330934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 5.3213 - accuracy: 0.0093\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.03367, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.01-5.1248.hdf5\n",
      "169/169 [==============================] - 47s 280ms/step - loss: 5.3213 - accuracy: 0.0093 - val_loss: 5.1248 - val_accuracy: 0.0337\n",
      "Epoch 2/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 5.0910 - accuracy: 0.0239\n",
      "Epoch 00002: val_accuracy improved from 0.03367 to 0.07407, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.02-4.9066.hdf5\n",
      "169/169 [==============================] - 41s 240ms/step - loss: 5.0910 - accuracy: 0.0239 - val_loss: 4.9066 - val_accuracy: 0.0741\n",
      "Epoch 3/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 4.8846 - accuracy: 0.0552\n",
      "Epoch 00003: val_accuracy improved from 0.07407 to 0.12626, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.03-4.7046.hdf5\n",
      "169/169 [==============================] - 41s 240ms/step - loss: 4.8846 - accuracy: 0.0552 - val_loss: 4.7046 - val_accuracy: 0.1263\n",
      "Epoch 4/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 4.6645 - accuracy: 0.0970\n",
      "Epoch 00004: val_accuracy improved from 0.12626 to 0.19024, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.04-4.5163.hdf5\n",
      "169/169 [==============================] - 42s 249ms/step - loss: 4.6645 - accuracy: 0.0970 - val_loss: 4.5163 - val_accuracy: 0.1902\n",
      "Epoch 5/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 4.4694 - accuracy: 0.1407 ETA: 0s - loss: 4.4717 - accuracy\n",
      "Epoch 00005: val_accuracy improved from 0.19024 to 0.26094, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.05-4.3396.hdf5\n",
      "169/169 [==============================] - 42s 249ms/step - loss: 4.4694 - accuracy: 0.1407 - val_loss: 4.3396 - val_accuracy: 0.2609\n",
      "Epoch 6/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 4.3000 - accuracy: 0.1787\n",
      "Epoch 00006: val_accuracy improved from 0.26094 to 0.30303, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.06-4.1750.hdf5\n",
      "169/169 [==============================] - 41s 246ms/step - loss: 4.3000 - accuracy: 0.1787 - val_loss: 4.1750 - val_accuracy: 0.3030\n",
      "Epoch 7/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 4.1300 - accuracy: 0.2319\n",
      "Epoch 00007: val_accuracy improved from 0.30303 to 0.35185, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.07-4.0208.hdf5\n",
      "169/169 [==============================] - 42s 246ms/step - loss: 4.1300 - accuracy: 0.2319 - val_loss: 4.0208 - val_accuracy: 0.3519\n",
      "Epoch 8/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.9678 - accuracy: 0.2630\n",
      "Epoch 00008: val_accuracy improved from 0.35185 to 0.38552, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.08-3.8772.hdf5\n",
      "169/169 [==============================] - 43s 253ms/step - loss: 3.9678 - accuracy: 0.2630 - val_loss: 3.8772 - val_accuracy: 0.3855\n",
      "Epoch 9/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.8190 - accuracy: 0.3004\n",
      "Epoch 00009: val_accuracy improved from 0.38552 to 0.41919, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.09-3.7430.hdf5\n",
      "169/169 [==============================] - 42s 248ms/step - loss: 3.8190 - accuracy: 0.3004 - val_loss: 3.7430 - val_accuracy: 0.4192\n",
      "Epoch 10/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.6825 - accuracy: 0.3300\n",
      "Epoch 00010: val_accuracy improved from 0.41919 to 0.45623, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.10-3.6185.hdf5\n",
      "169/169 [==============================] - 42s 249ms/step - loss: 3.6825 - accuracy: 0.3300 - val_loss: 3.6185 - val_accuracy: 0.4562\n",
      "Epoch 11/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.5558 - accuracy: 0.3600\n",
      "Epoch 00011: val_accuracy improved from 0.45623 to 0.47643, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.11-3.5019.hdf5\n",
      "169/169 [==============================] - 43s 252ms/step - loss: 3.5558 - accuracy: 0.3600 - val_loss: 3.5019 - val_accuracy: 0.4764\n",
      "Epoch 12/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.4341 - accuracy: 0.3943\n",
      "Epoch 00012: val_accuracy improved from 0.47643 to 0.48990, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.12-3.3933.hdf5\n",
      "169/169 [==============================] - 43s 255ms/step - loss: 3.4341 - accuracy: 0.3943 - val_loss: 3.3933 - val_accuracy: 0.4899\n",
      "Epoch 13/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.3113 - accuracy: 0.4174\n",
      "Epoch 00013: val_accuracy improved from 0.48990 to 0.51178, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.13-3.2923.hdf5\n",
      "169/169 [==============================] - 42s 246ms/step - loss: 3.3113 - accuracy: 0.4174 - val_loss: 3.2923 - val_accuracy: 0.5118\n",
      "Epoch 14/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.2151 - accuracy: 0.4374\n",
      "Epoch 00014: val_accuracy improved from 0.51178 to 0.52357, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.14-3.1982.hdf5\n",
      "169/169 [==============================] - 42s 247ms/step - loss: 3.2151 - accuracy: 0.4374 - val_loss: 3.1982 - val_accuracy: 0.5236\n",
      "Epoch 15/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.1158 - accuracy: 0.4524\n",
      "Epoch 00015: val_accuracy did not improve from 0.52357\n",
      "169/169 [==============================] - 42s 248ms/step - loss: 3.1158 - accuracy: 0.4524 - val_loss: 3.1101 - val_accuracy: 0.5236\n",
      "Epoch 16/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.0338 - accuracy: 0.4687\n",
      "Epoch 00016: val_accuracy improved from 0.52357 to 0.53872, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.16-3.0276.hdf5\n",
      "169/169 [==============================] - 42s 251ms/step - loss: 3.0338 - accuracy: 0.4687 - val_loss: 3.0276 - val_accuracy: 0.5387\n",
      "Epoch 17/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.9268 - accuracy: 0.4937\n",
      "Epoch 00017: val_accuracy improved from 0.53872 to 0.54377, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.17-2.9497.hdf5\n",
      "169/169 [==============================] - 42s 247ms/step - loss: 2.9268 - accuracy: 0.4937 - val_loss: 2.9497 - val_accuracy: 0.5438\n",
      "Epoch 18/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.8526 - accuracy: 0.5046\n",
      "Epoch 00018: val_accuracy improved from 0.54377 to 0.54882, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.18-2.8775.hdf5\n",
      "169/169 [==============================] - 42s 249ms/step - loss: 2.8526 - accuracy: 0.5046 - val_loss: 2.8775 - val_accuracy: 0.5488\n",
      "Epoch 19/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.7796 - accuracy: 0.5217\n",
      "Epoch 00019: val_accuracy improved from 0.54882 to 0.55724, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.19-2.8101.hdf5\n",
      "169/169 [==============================] - 44s 259ms/step - loss: 2.7796 - accuracy: 0.5217 - val_loss: 2.8101 - val_accuracy: 0.5572\n",
      "Epoch 20/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.7009 - accuracy: 0.5404\n",
      "Epoch 00020: val_accuracy improved from 0.55724 to 0.56229, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.20-2.7464.hdf5\n",
      "169/169 [==============================] - 42s 246ms/step - loss: 2.7009 - accuracy: 0.5404 - val_loss: 2.7464 - val_accuracy: 0.5623\n",
      "Epoch 21/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.6329 - accuracy: 0.5494\n",
      "Epoch 00021: val_accuracy improved from 0.56229 to 0.56566, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.21-2.6863.hdf5\n",
      "169/169 [==============================] - 41s 245ms/step - loss: 2.6329 - accuracy: 0.5494 - val_loss: 2.6863 - val_accuracy: 0.5657\n",
      "Epoch 22/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.5724 - accuracy: 0.5554\n",
      "Epoch 00022: val_accuracy improved from 0.56566 to 0.57071, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.22-2.6302.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 43s 252ms/step - loss: 2.5724 - accuracy: 0.5554 - val_loss: 2.6302 - val_accuracy: 0.5707\n",
      "Epoch 23/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.5141 - accuracy: 0.5644\n",
      "Epoch 00023: val_accuracy improved from 0.57071 to 0.57407, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.23-2.5768.hdf5\n",
      "169/169 [==============================] - 42s 250ms/step - loss: 2.5141 - accuracy: 0.5644 - val_loss: 2.5768 - val_accuracy: 0.5741\n",
      "Epoch 24/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.4571 - accuracy: 0.5800\n",
      "Epoch 00024: val_accuracy improved from 0.57407 to 0.58418, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.24-2.5275.hdf5\n",
      "169/169 [==============================] - 42s 246ms/step - loss: 2.4571 - accuracy: 0.5800 - val_loss: 2.5275 - val_accuracy: 0.5842\n",
      "Epoch 25/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.3969 - accuracy: 0.5906\n",
      "Epoch 00025: val_accuracy improved from 0.58418 to 0.59091, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.25-2.4804.hdf5\n",
      "169/169 [==============================] - 42s 248ms/step - loss: 2.3969 - accuracy: 0.5906 - val_loss: 2.4804 - val_accuracy: 0.5909\n",
      "Epoch 26/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.3503 - accuracy: 0.6000\n",
      "Epoch 00026: val_accuracy improved from 0.59091 to 0.59259, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.26-2.4367.hdf5\n",
      "169/169 [==============================] - 44s 263ms/step - loss: 2.3503 - accuracy: 0.6000 - val_loss: 2.4367 - val_accuracy: 0.5926\n",
      "Epoch 27/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.3197 - accuracy: 0.5963\n",
      "Epoch 00027: val_accuracy improved from 0.59259 to 0.59764, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.27-2.3942.hdf5\n",
      "169/169 [==============================] - 41s 243ms/step - loss: 2.3197 - accuracy: 0.5963 - val_loss: 2.3942 - val_accuracy: 0.5976\n",
      "Epoch 28/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.2547 - accuracy: 0.6122\n",
      "Epoch 00028: val_accuracy improved from 0.59764 to 0.60438, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.28-2.3546.hdf5\n",
      "169/169 [==============================] - 42s 250ms/step - loss: 2.2547 - accuracy: 0.6122 - val_loss: 2.3546 - val_accuracy: 0.6044\n",
      "Epoch 29/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.2135 - accuracy: 0.6161\n",
      "Epoch 00029: val_accuracy improved from 0.60438 to 0.60774, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.29-2.3171.hdf5\n",
      "169/169 [==============================] - 43s 256ms/step - loss: 2.2135 - accuracy: 0.6161 - val_loss: 2.3171 - val_accuracy: 0.6077\n",
      "Epoch 30/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.1759 - accuracy: 0.6207\n",
      "Epoch 00030: val_accuracy improved from 0.60774 to 0.60943, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.30-2.2816.hdf5\n",
      "169/169 [==============================] - 42s 249ms/step - loss: 2.1759 - accuracy: 0.6207 - val_loss: 2.2816 - val_accuracy: 0.6094\n",
      "Epoch 31/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.1403 - accuracy: 0.6276\n",
      "Epoch 00031: val_accuracy did not improve from 0.60943\n",
      "169/169 [==============================] - 41s 242ms/step - loss: 2.1403 - accuracy: 0.6276 - val_loss: 2.2472 - val_accuracy: 0.6077\n",
      "Epoch 32/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.0885 - accuracy: 0.6385\n",
      "Epoch 00032: val_accuracy improved from 0.60943 to 0.61111, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.32-2.2148.hdf5\n",
      "169/169 [==============================] - 42s 248ms/step - loss: 2.0885 - accuracy: 0.6385 - val_loss: 2.2148 - val_accuracy: 0.6111\n",
      "Epoch 33/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.0522 - accuracy: 0.6404\n",
      "Epoch 00033: val_accuracy improved from 0.61111 to 0.61448, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.33-2.1843.hdf5\n",
      "169/169 [==============================] - 42s 250ms/step - loss: 2.0522 - accuracy: 0.6404 - val_loss: 2.1843 - val_accuracy: 0.6145\n",
      "Epoch 34/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.0282 - accuracy: 0.6539\n",
      "Epoch 00034: val_accuracy improved from 0.61448 to 0.61953, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.34-2.1546.hdf5\n",
      "169/169 [==============================] - 42s 249ms/step - loss: 2.0282 - accuracy: 0.6539 - val_loss: 2.1546 - val_accuracy: 0.6195\n",
      "Epoch 35/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.9866 - accuracy: 0.6583\n",
      "Epoch 00035: val_accuracy did not improve from 0.61953\n",
      "169/169 [==============================] - 41s 240ms/step - loss: 1.9866 - accuracy: 0.6583 - val_loss: 2.1264 - val_accuracy: 0.6178\n",
      "Epoch 36/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.9475 - accuracy: 0.6665\n",
      "Epoch 00036: val_accuracy did not improve from 0.61953\n",
      "169/169 [==============================] - 42s 251ms/step - loss: 1.9475 - accuracy: 0.6665 - val_loss: 2.0996 - val_accuracy: 0.6145\n",
      "Epoch 37/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.9215 - accuracy: 0.6669\n",
      "Epoch 00037: val_accuracy did not improve from 0.61953\n",
      "169/169 [==============================] - 41s 243ms/step - loss: 1.9215 - accuracy: 0.6669 - val_loss: 2.0739 - val_accuracy: 0.6195\n",
      "Epoch 38/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.8943 - accuracy: 0.6698\n",
      "Epoch 00038: val_accuracy improved from 0.61953 to 0.62121, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.38-2.0493.hdf5\n",
      "169/169 [==============================] - 43s 252ms/step - loss: 1.8943 - accuracy: 0.6698 - val_loss: 2.0493 - val_accuracy: 0.6212\n",
      "Epoch 39/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.8730 - accuracy: 0.6722\n",
      "Epoch 00039: val_accuracy improved from 0.62121 to 0.62626, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.39-2.0256.hdf5\n",
      "169/169 [==============================] - 43s 256ms/step - loss: 1.8730 - accuracy: 0.6722 - val_loss: 2.0256 - val_accuracy: 0.6263\n",
      "Epoch 40/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.8365 - accuracy: 0.6880\n",
      "Epoch 00040: val_accuracy did not improve from 0.62626\n",
      "169/169 [==============================] - 43s 254ms/step - loss: 1.8365 - accuracy: 0.6880 - val_loss: 2.0031 - val_accuracy: 0.6263\n",
      "Epoch 41/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.8176 - accuracy: 0.6863 ETA: 1s - loss: 1.8153 - accu\n",
      "Epoch 00041: val_accuracy did not improve from 0.62626\n",
      "169/169 [==============================] - 43s 251ms/step - loss: 1.8176 - accuracy: 0.6863 - val_loss: 1.9811 - val_accuracy: 0.6212\n",
      "Epoch 42/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.7809 - accuracy: 0.6909\n",
      "Epoch 00042: val_accuracy did not improve from 0.62626\n",
      "169/169 [==============================] - 41s 241ms/step - loss: 1.7809 - accuracy: 0.6909 - val_loss: 1.9604 - val_accuracy: 0.6195\n",
      "Epoch 43/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.7857 - accuracy: 0.6781\n",
      "Epoch 00043: val_accuracy did not improve from 0.62626\n",
      "169/169 [==============================] - 41s 244ms/step - loss: 1.7857 - accuracy: 0.6781 - val_loss: 1.9403 - val_accuracy: 0.6246\n",
      "Epoch 44/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.7460 - accuracy: 0.6856\n",
      "Epoch 00044: val_accuracy did not improve from 0.62626\n",
      "169/169 [==============================] - 40s 239ms/step - loss: 1.7460 - accuracy: 0.6856 - val_loss: 1.9209 - val_accuracy: 0.6229\n",
      "Epoch 45/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.7274 - accuracy: 0.6946\n",
      "Epoch 00045: val_accuracy did not improve from 0.62626\n",
      "169/169 [==============================] - 42s 248ms/step - loss: 1.7274 - accuracy: 0.6946 - val_loss: 1.9027 - val_accuracy: 0.6246\n",
      "Epoch 46/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.7045 - accuracy: 0.6965\n",
      "Epoch 00046: val_accuracy did not improve from 0.62626\n",
      "169/169 [==============================] - 42s 248ms/step - loss: 1.7045 - accuracy: 0.6965 - val_loss: 1.8850 - val_accuracy: 0.6246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6816 - accuracy: 0.7041\n",
      "Epoch 00047: val_accuracy did not improve from 0.62626\n",
      "169/169 [==============================] - 41s 241ms/step - loss: 1.6816 - accuracy: 0.7041 - val_loss: 1.8678 - val_accuracy: 0.6263\n",
      "Epoch 48/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6628 - accuracy: 0.7044\n",
      "Epoch 00048: val_accuracy did not improve from 0.62626\n",
      "169/169 [==============================] - 42s 250ms/step - loss: 1.6628 - accuracy: 0.7044 - val_loss: 1.8512 - val_accuracy: 0.6246\n",
      "Epoch 49/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6315 - accuracy: 0.7089\n",
      "Epoch 00049: val_accuracy did not improve from 0.62626\n",
      "169/169 [==============================] - 41s 245ms/step - loss: 1.6315 - accuracy: 0.7089 - val_loss: 1.8352 - val_accuracy: 0.6246\n",
      "Epoch 50/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6188 - accuracy: 0.6991\n",
      "Epoch 00050: val_accuracy improved from 0.62626 to 0.62795, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_transfer.50-1.8198.hdf5\n",
      "169/169 [==============================] - 42s 249ms/step - loss: 1.6188 - accuracy: 0.6991 - val_loss: 1.8198 - val_accuracy: 0.6279\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% Trains for 5 epochs.\n",
    "if args.train_using_builtin_fit_method:\n",
    "\n",
    "    model.compile(optimizer=optimizers.SGD(lr=0.01/10, momentum = 0.9), \n",
    "                  loss=[categorical_crossentropy], \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    #%%\n",
    "    save_path=weights_path+'/model_transfer.{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(save_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_weights_only = True)\n",
    "    callbacks_list = [checkpoint]\n",
    "    #%%\n",
    "    history = model.fit(train_gen, epochs=50, verbose=1, callbacks=callbacks_list, validation_data=test_gen, shuffle=True)\n",
    "    \n",
    "    plt.style.use('seaborn')\n",
    "    #plt.style.available\n",
    "    #['fivethirtyeight',\n",
    "     #'seaborn-pastel',\n",
    "     #'seaborn-whitegrid',\n",
    "     #'ggplot',\n",
    "     #'grayscale']\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    #plt.savefig(fname='model_accuracy_'+db+'.png')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    #plt.savefig(fname='model_loss_'+db+'.png')\n",
    "    \n",
    "    #%% stop execution\n",
    "    #sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath=weights_path+\"/model_transfer_epoch_50.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.applications.efficientnet.EfficientNetB0(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EfficientNetB0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.29073,
     "end_time": "2020-12-02T06:09:41.376678",
     "exception": false,
     "start_time": "2020-12-02T06:09:39.085948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Now fine tune all layers at small learning rate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.0327,
     "end_time": "2020-12-02T06:09:49.916900",
     "exception": false,
     "start_time": "2020-12-02T06:09:47.884200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# enable augmentation for increasing regularization for fine-tuning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T06:09:55.113260Z",
     "iopub.status.busy": "2020-12-02T06:09:55.112341Z",
     "iopub.status.idle": "2020-12-02T06:09:56.192708Z",
     "shell.execute_reply": "2020-12-02T06:09:56.192155Z"
    },
    "papermill": {
     "duration": 3.152934,
     "end_time": "2020-12-02T06:09:56.192822",
     "exception": false,
     "start_time": "2020-12-02T06:09:53.039888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using imagenet_weights\n",
      "Found 5400 images belonging to 200 classes.\n",
      "Found 594 images belonging to 200 classes.\n",
      "Found 5400 images belonging to 200 classes.\n",
      "Found 594 images belonging to 200 classes.\n",
      "Found 5794 images belonging to 200 classes.\n",
      "Found 5794 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "if args.imagenet_weights:\n",
    "    print('using imagenet_weights')\n",
    "\n",
    "    if args.dataset == 'cifar10':\n",
    "        imgDataGen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "                                        #rescale = 1./255)\n",
    "\n",
    "        train_gen = imgDataGen.flow(x_train, y_train, batch_size = batch_size,shuffle= False)\n",
    "        test_gen  = imgDataGen.flow(x_test, y_test, batch_size = batch_size,shuffle= False)\n",
    "    else:\n",
    "        augment = True\n",
    "        if not augment:\n",
    "            imgDataGen = ImageDataGenerator(preprocessing_function = preprocess_input, \n",
    "                                            #rescale = 1./255,\n",
    "                                            validation_split=0.1)\n",
    "        else:\n",
    "            imgDataGen = ImageDataGenerator(preprocessing_function = preprocess_input, \n",
    "                                        #rescale = 1./255,\n",
    "                                        validation_split=0.1,\n",
    "                                        \n",
    "                              height_shift_range= 0.2, \n",
    "                              width_shift_range=0.2, \n",
    "                              rotation_range=15, \n",
    "                              shear_range = 0.2,\n",
    "                              fill_mode = 'nearest',#''nearest#reflect\n",
    "                              zoom_range=0.2)\n",
    "        \n",
    "        train_gen = imgDataGen.flow_from_directory(data_dir,\n",
    "                                target_size=(input_shape[1], input_shape[2]),\n",
    "                                color_mode='rgb',\n",
    "                                class_mode='categorical',\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                seed=None,\n",
    "                                subset='training',\n",
    "                                interpolation='nearest')#,\n",
    "                                #all classes for base model; binary classes for CF model\n",
    "                                #classes = ['cat', 'dog'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = ['cat'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = label_map)\n",
    "        test_gen  = imgDataGen.flow_from_directory(data_dir,\n",
    "                                target_size=(input_shape[1], input_shape[2]),\n",
    "                                color_mode='rgb',\n",
    "                                class_mode='categorical',\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                seed=None,\n",
    "                                subset='validation',\n",
    "                                interpolation='nearest')#,\n",
    "                                #classes = ['cat', 'dog'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = ['cat'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                               # classes = label_map)\n",
    "        \n",
    "        # for visualization, dont use preprocessed image\n",
    "        imgDataGen_nopreprocess = ImageDataGenerator(#preprocessing_function = preprocess_input, \n",
    "                                        rescale = 1./255,\n",
    "                                        validation_split=0.1)\n",
    "        \n",
    "        train_gen_nopreprocess = imgDataGen_nopreprocess.flow_from_directory(data_dir,\n",
    "                                target_size=(input_shape[1], input_shape[2]),\n",
    "                                color_mode='rgb',\n",
    "                                class_mode='categorical',\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                seed=None,\n",
    "                                subset='training',\n",
    "                                interpolation='nearest'),\n",
    "                                #classes = ['cat', 'dog'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = ['cat'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = label_map)\n",
    "        test_gen_nopreprocess  = imgDataGen_nopreprocess.flow_from_directory(data_dir,\n",
    "                                target_size=(input_shape[1], input_shape[2]),\n",
    "                                color_mode='rgb',\n",
    "                                class_mode='categorical',\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                seed=None,\n",
    "                                subset='validation',\n",
    "                                interpolation='nearest'),\n",
    "                                #classes = ['cat', 'dog'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = ['cat'] if args.train_counterfactual_net else label_map)#['cat', 'dog'])\n",
    "                                #classes = label_map)\n",
    "        if args.dataset == 'CUB200' and official_split:\n",
    "            #actual unseen test set\n",
    "            imgDataGen_official_split = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "            actual_test_gen  = imgDataGen_official_split.flow_from_directory(data_dir_test,\n",
    "                            target_size=(input_shape[1], input_shape[2]),\n",
    "                            color_mode='rgb',\n",
    "                            class_mode='categorical',\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            seed=None,\n",
    "                            #subset='validation',\n",
    "                            interpolation='nearest')\n",
    "            imgDataGen_official_split_nopreprocess = ImageDataGenerator(rescale = 1./255)\n",
    "            actual_test_gen_nopreprocess  = imgDataGen_official_split_nopreprocess.flow_from_directory(data_dir_test,\n",
    "                            target_size=(input_shape[1], input_shape[2]),\n",
    "                            color_mode='rgb',\n",
    "                            class_mode='categorical',\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            seed=None,\n",
    "                            #subset='validation',\n",
    "                            interpolation='nearest')                            \n",
    "elif args.dataset == 'cxr1000':\n",
    "    train_gen, test_gen, valid_gen = load_cxr_dataset(train_df, test_df, valid_df, all_labels, batch_size)\n",
    "    \n",
    "else:\n",
    "    print('not using imagenet_weights')\n",
    "\n",
    "    imgDataGen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    train_gen = imgDataGen.flow(x_train, y_train, batch_size = batch_size,shuffle= False)\n",
    "    test_gen  = imgDataGen.flow(x_test, y_test, batch_size = batch_size,shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T06:10:00.229710Z",
     "iopub.status.busy": "2020-12-02T06:10:00.229009Z",
     "iopub.status.idle": "2020-12-02T09:00:35.976829Z",
     "shell.execute_reply": "2020-12-02T09:00:35.974177Z"
    },
    "papermill": {
     "duration": 10237.75517,
     "end_time": "2020-12-02T09:00:35.976976",
     "exception": false,
     "start_time": "2020-12-02T06:09:58.221806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 224, 224, 3)  7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 225, 225, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 112, 112, 32) 864         stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 112, 112, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 112, 112, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 112, 112, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 112, 112, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 112, 112, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 112, 112, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 112, 112, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 112, 112, 96) 1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 112, 112, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 112, 112, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 113, 113, 96) 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 56, 56, 96)   864         block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 56, 56, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 56, 56, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 56, 56, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 56, 56, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 56, 56, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 56, 56, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 56, 56, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 56, 56, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 56, 56, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 56, 56, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 56, 56, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 56, 56, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 56, 56, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 56, 56, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 56, 56, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 56, 56, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 56, 56, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 59, 59, 144)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 28, 28, 144)  3600        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 28, 28, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 28, 28, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 28, 28, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 28, 28, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 28, 28, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 28, 28, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 28, 28, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 28, 28, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 28, 28, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 28, 28, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 28, 28, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 28, 28, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 28, 28, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 28, 28, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 28, 28, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 28, 28, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 28, 28, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 29, 29, 240)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 14, 14, 240)  2160        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 14, 14, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 14, 14, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 14, 14, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 14, 14, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 14, 14, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 14, 14, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 14, 14, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 14, 14, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 14, 14, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 14, 14, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 14, 14, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 14, 14, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 14, 14, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 14, 14, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 14, 14, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 14, 14, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 14, 14, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 14, 14, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 14, 14, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 14, 14, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 14, 14, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 14, 14, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 14, 14, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 14, 14, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 14, 14, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 14, 14, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 14, 14, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 14, 14, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 14, 14, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 14, 14, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 14, 14, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 14, 14, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 14, 14, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 14, 14, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 14, 14, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 14, 14, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 14, 14, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 17, 17, 672)  0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 7, 7, 672)    16800       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 7, 7, 672)    2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 7, 7, 672)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 7, 7, 672)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 7, 7, 192)    129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 7, 7, 192)    768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 7, 7, 1152)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 7, 7, 1152)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 7, 7, 192)    768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 7, 7, 192)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 7, 7, 192)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 7, 7, 1152)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 7, 7, 1152)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 7, 7, 192)    768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 7, 7, 192)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 7, 7, 192)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 7, 7, 1152)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 7, 7, 1152)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 7, 7, 192)    768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 7, 7, 192)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 7, 7, 192)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 7, 7, 1152)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 7, 7, 1152)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 7, 7, 1152)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 7, 7, 320)    368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 7, 7, 320)    1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 7, 7, 1280)   409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 7, 7, 1280)   5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 7, 7, 1280)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1280)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1280)         0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200)          256200      dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,305,771\n",
      "Trainable params: 4,263,748\n",
      "Non-trainable params: 42,023\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  2/169 [..............................] - ETA: 21s - loss: 3.9214 - accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0879s vs `on_train_batch_end` time: 0.1564s). Check your callbacks.\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.5902 - accuracy: 0.2757\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47138, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.01-2.5573.hdf5\n",
      "169/169 [==============================] - 343s 2s/step - loss: 3.5902 - accuracy: 0.2757 - val_loss: 2.5573 - val_accuracy: 0.4714\n",
      "Epoch 2/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.3414 - accuracy: 0.3109\n",
      "Epoch 00002: val_accuracy did not improve from 0.47138\n",
      "169/169 [==============================] - 343s 2s/step - loss: 3.3414 - accuracy: 0.3109 - val_loss: 2.7203 - val_accuracy: 0.4562\n",
      "Epoch 3/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 3.1317 - accuracy: 0.3617\n",
      "Epoch 00003: val_accuracy did not improve from 0.47138\n",
      "169/169 [==============================] - 298s 2s/step - loss: 3.1317 - accuracy: 0.3617 - val_loss: 2.6955 - val_accuracy: 0.4579\n",
      "Epoch 4/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.9692 - accuracy: 0.3843\n",
      "Epoch 00004: val_accuracy improved from 0.47138 to 0.48148, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.04-2.6119.hdf5\n",
      "169/169 [==============================] - 324s 2s/step - loss: 2.9692 - accuracy: 0.3843 - val_loss: 2.6119 - val_accuracy: 0.4815\n",
      "Epoch 5/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.8140 - accuracy: 0.4170\n",
      "Epoch 00005: val_accuracy improved from 0.48148 to 0.51178, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.05-2.4672.hdf5\n",
      "169/169 [==============================] - 327s 2s/step - loss: 2.8140 - accuracy: 0.4170 - val_loss: 2.4672 - val_accuracy: 0.5118\n",
      "Epoch 6/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.6909 - accuracy: 0.4381\n",
      "Epoch 00006: val_accuracy improved from 0.51178 to 0.51515, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.06-2.3684.hdf5\n",
      "169/169 [==============================] - 343s 2s/step - loss: 2.6909 - accuracy: 0.4381 - val_loss: 2.3684 - val_accuracy: 0.5152\n",
      "Epoch 7/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.5812 - accuracy: 0.4583\n",
      "Epoch 00007: val_accuracy did not improve from 0.51515\n",
      "169/169 [==============================] - 313s 2s/step - loss: 2.5812 - accuracy: 0.4583 - val_loss: 2.3329 - val_accuracy: 0.5135\n",
      "Epoch 8/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.5077 - accuracy: 0.4700\n",
      "Epoch 00008: val_accuracy improved from 0.51515 to 0.52525, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.08-2.2614.hdf5\n",
      "169/169 [==============================] - 319s 2s/step - loss: 2.5077 - accuracy: 0.4700 - val_loss: 2.2614 - val_accuracy: 0.5253\n",
      "Epoch 9/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.4060 - accuracy: 0.4891\n",
      "Epoch 00009: val_accuracy improved from 0.52525 to 0.54882, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.09-2.1483.hdf5\n",
      "169/169 [==============================] - 337s 2s/step - loss: 2.4060 - accuracy: 0.4891 - val_loss: 2.1483 - val_accuracy: 0.5488\n",
      "Epoch 10/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.3412 - accuracy: 0.5069\n",
      "Epoch 00010: val_accuracy improved from 0.54882 to 0.56061, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.10-2.1240.hdf5\n",
      "169/169 [==============================] - 310s 2s/step - loss: 2.3412 - accuracy: 0.5069 - val_loss: 2.1240 - val_accuracy: 0.5606\n",
      "Epoch 11/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.2723 - accuracy: 0.5152\n",
      "Epoch 00011: val_accuracy improved from 0.56061 to 0.56734, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.11-2.0853.hdf5\n",
      "169/169 [==============================] - 335s 2s/step - loss: 2.2723 - accuracy: 0.5152 - val_loss: 2.0853 - val_accuracy: 0.5673\n",
      "Epoch 12/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.2020 - accuracy: 0.5283\n",
      "Epoch 00012: val_accuracy improved from 0.56734 to 0.57239, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.12-2.0450.hdf5\n",
      "169/169 [==============================] - 327s 2s/step - loss: 2.2020 - accuracy: 0.5283 - val_loss: 2.0450 - val_accuracy: 0.5724\n",
      "Epoch 13/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.1647 - accuracy: 0.5331\n",
      "Epoch 00013: val_accuracy improved from 0.57239 to 0.57912, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.13-2.0158.hdf5\n",
      "169/169 [==============================] - 348s 2s/step - loss: 2.1647 - accuracy: 0.5331 - val_loss: 2.0158 - val_accuracy: 0.5791\n",
      "Epoch 14/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.1111 - accuracy: 0.5559\n",
      "Epoch 00014: val_accuracy did not improve from 0.57912\n",
      "169/169 [==============================] - 311s 2s/step - loss: 2.1111 - accuracy: 0.5559 - val_loss: 1.9556 - val_accuracy: 0.5791\n",
      "Epoch 15/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.0965 - accuracy: 0.5452\n",
      "Epoch 00015: val_accuracy did not improve from 0.57912\n",
      "169/169 [==============================] - 336s 2s/step - loss: 2.0965 - accuracy: 0.5452 - val_loss: 1.9310 - val_accuracy: 0.5741\n",
      "Epoch 16/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.0228 - accuracy: 0.5648\n",
      "Epoch 00016: val_accuracy improved from 0.57912 to 0.58586, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.16-1.9233.hdf5\n",
      "169/169 [==============================] - 339s 2s/step - loss: 2.0228 - accuracy: 0.5648 - val_loss: 1.9233 - val_accuracy: 0.5859\n",
      "Epoch 17/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.9838 - accuracy: 0.5691\n",
      "Epoch 00017: val_accuracy improved from 0.58586 to 0.58923, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.17-1.8795.hdf5\n",
      "169/169 [==============================] - 324s 2s/step - loss: 1.9838 - accuracy: 0.5691 - val_loss: 1.8795 - val_accuracy: 0.5892\n",
      "Epoch 18/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.9476 - accuracy: 0.5831\n",
      "Epoch 00018: val_accuracy improved from 0.58923 to 0.59428, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.18-1.8362.hdf5\n",
      "169/169 [==============================] - 355s 2s/step - loss: 1.9476 - accuracy: 0.5831 - val_loss: 1.8362 - val_accuracy: 0.5943\n",
      "Epoch 19/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.9086 - accuracy: 0.5828\n",
      "Epoch 00019: val_accuracy improved from 0.59428 to 0.59933, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.19-1.8187.hdf5\n",
      "169/169 [==============================] - 336s 2s/step - loss: 1.9086 - accuracy: 0.5828 - val_loss: 1.8187 - val_accuracy: 0.5993\n",
      "Epoch 20/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.8924 - accuracy: 0.5874\n",
      "Epoch 00020: val_accuracy did not improve from 0.59933\n",
      "169/169 [==============================] - 331s 2s/step - loss: 1.8924 - accuracy: 0.5874 - val_loss: 1.7837 - val_accuracy: 0.5926\n",
      "Epoch 21/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.8712 - accuracy: 0.5928\n",
      "Epoch 00021: val_accuracy improved from 0.59933 to 0.62963, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.21-1.7509.hdf5\n",
      "169/169 [==============================] - 311s 2s/step - loss: 1.8712 - accuracy: 0.5928 - val_loss: 1.7509 - val_accuracy: 0.6296\n",
      "Epoch 22/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.8478 - accuracy: 0.5956\n",
      "Epoch 00022: val_accuracy did not improve from 0.62963\n",
      "169/169 [==============================] - 317s 2s/step - loss: 1.8478 - accuracy: 0.5956 - val_loss: 1.7459 - val_accuracy: 0.6061\n",
      "Epoch 23/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.8101 - accuracy: 0.6013\n",
      "Epoch 00023: val_accuracy did not improve from 0.62963\n",
      "169/169 [==============================] - 305s 2s/step - loss: 1.8101 - accuracy: 0.6013 - val_loss: 1.7168 - val_accuracy: 0.6178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.7764 - accuracy: 0.6122\n",
      "Epoch 00024: val_accuracy did not improve from 0.62963\n",
      "169/169 [==============================] - 342s 2s/step - loss: 1.7764 - accuracy: 0.6122 - val_loss: 1.7024 - val_accuracy: 0.6145\n",
      "Epoch 25/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.7450 - accuracy: 0.6193\n",
      "Epoch 00025: val_accuracy did not improve from 0.62963\n",
      "169/169 [==============================] - 323s 2s/step - loss: 1.7450 - accuracy: 0.6193 - val_loss: 1.6854 - val_accuracy: 0.6111\n",
      "Epoch 26/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.7309 - accuracy: 0.6206\n",
      "Epoch 00026: val_accuracy did not improve from 0.62963\n",
      "169/169 [==============================] - 320s 2s/step - loss: 1.7309 - accuracy: 0.6206 - val_loss: 1.6743 - val_accuracy: 0.6229\n",
      "Epoch 27/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.7030 - accuracy: 0.6222\n",
      "Epoch 00027: val_accuracy did not improve from 0.62963\n",
      "169/169 [==============================] - 365s 2s/step - loss: 1.7030 - accuracy: 0.6222 - val_loss: 1.6522 - val_accuracy: 0.6229\n",
      "Epoch 28/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6906 - accuracy: 0.6257\n",
      "Epoch 00028: val_accuracy improved from 0.62963 to 0.64646, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.28-1.5958.hdf5\n",
      "169/169 [==============================] - 322s 2s/step - loss: 1.6906 - accuracy: 0.6257 - val_loss: 1.5958 - val_accuracy: 0.6465\n",
      "Epoch 29/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6950 - accuracy: 0.6269\n",
      "Epoch 00029: val_accuracy did not improve from 0.64646\n",
      "169/169 [==============================] - 341s 2s/step - loss: 1.6950 - accuracy: 0.6269 - val_loss: 1.5977 - val_accuracy: 0.6296\n",
      "Epoch 30/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6540 - accuracy: 0.6369\n",
      "Epoch 00030: val_accuracy did not improve from 0.64646\n",
      "169/169 [==============================] - 315s 2s/step - loss: 1.6540 - accuracy: 0.6369 - val_loss: 1.5812 - val_accuracy: 0.6431\n",
      "Epoch 31/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6452 - accuracy: 0.6328\n",
      "Epoch 00031: val_accuracy did not improve from 0.64646\n",
      "169/169 [==============================] - 323s 2s/step - loss: 1.6452 - accuracy: 0.6328 - val_loss: 1.5580 - val_accuracy: 0.6279\n",
      "Epoch 32/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6179 - accuracy: 0.6333\n",
      "Epoch 00032: val_accuracy improved from 0.64646 to 0.65152, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.32-1.5627.hdf5\n",
      "169/169 [==============================] - 336s 2s/step - loss: 1.6179 - accuracy: 0.6333 - val_loss: 1.5627 - val_accuracy: 0.6515\n",
      "Epoch 33/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6073 - accuracy: 0.6417\n",
      "Epoch 00033: val_accuracy did not improve from 0.65152\n",
      "169/169 [==============================] - 328s 2s/step - loss: 1.6073 - accuracy: 0.6417 - val_loss: 1.5300 - val_accuracy: 0.6498\n",
      "Epoch 34/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.5839 - accuracy: 0.6415\n",
      "Epoch 00034: val_accuracy did not improve from 0.65152\n",
      "169/169 [==============================] - 319s 2s/step - loss: 1.5839 - accuracy: 0.6415 - val_loss: 1.5056 - val_accuracy: 0.6515\n",
      "Epoch 35/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.5593 - accuracy: 0.6496\n",
      "Epoch 00035: val_accuracy improved from 0.65152 to 0.65320, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.35-1.5077.hdf5\n",
      "169/169 [==============================] - 360s 2s/step - loss: 1.5593 - accuracy: 0.6496 - val_loss: 1.5077 - val_accuracy: 0.6532\n",
      "Epoch 36/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.5558 - accuracy: 0.6456\n",
      "Epoch 00036: val_accuracy did not improve from 0.65320\n",
      "169/169 [==============================] - 334s 2s/step - loss: 1.5558 - accuracy: 0.6456 - val_loss: 1.5092 - val_accuracy: 0.6414\n",
      "Epoch 37/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.5570 - accuracy: 0.6535\n",
      "Epoch 00037: val_accuracy did not improve from 0.65320\n",
      "169/169 [==============================] - 347s 2s/step - loss: 1.5570 - accuracy: 0.6535 - val_loss: 1.5124 - val_accuracy: 0.6347\n",
      "Epoch 38/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.5138 - accuracy: 0.6613\n",
      "Epoch 00038: val_accuracy improved from 0.65320 to 0.66498, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.38-1.4689.hdf5\n",
      "169/169 [==============================] - 313s 2s/step - loss: 1.5138 - accuracy: 0.6613 - val_loss: 1.4689 - val_accuracy: 0.6650\n",
      "Epoch 39/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.5140 - accuracy: 0.6631\n",
      "Epoch 00039: val_accuracy did not improve from 0.66498\n",
      "169/169 [==============================] - 341s 2s/step - loss: 1.5140 - accuracy: 0.6631 - val_loss: 1.4563 - val_accuracy: 0.6465\n",
      "Epoch 40/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.4976 - accuracy: 0.6639\n",
      "Epoch 00040: val_accuracy did not improve from 0.66498\n",
      "169/169 [==============================] - 335s 2s/step - loss: 1.4976 - accuracy: 0.6639 - val_loss: 1.4906 - val_accuracy: 0.6397\n",
      "Epoch 41/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.5083 - accuracy: 0.6556\n",
      "Epoch 00041: val_accuracy did not improve from 0.66498\n",
      "169/169 [==============================] - 331s 2s/step - loss: 1.5083 - accuracy: 0.6556 - val_loss: 1.4558 - val_accuracy: 0.6532\n",
      "Epoch 42/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.4674 - accuracy: 0.6717\n",
      "Epoch 00042: val_accuracy improved from 0.66498 to 0.68687, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.42-1.4252.hdf5\n",
      "169/169 [==============================] - 338s 2s/step - loss: 1.4674 - accuracy: 0.6717 - val_loss: 1.4252 - val_accuracy: 0.6869\n",
      "Epoch 43/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.4613 - accuracy: 0.6680\n",
      "Epoch 00043: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 342s 2s/step - loss: 1.4613 - accuracy: 0.6680 - val_loss: 1.4185 - val_accuracy: 0.6414\n",
      "Epoch 44/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.4391 - accuracy: 0.6722\n",
      "Epoch 00044: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 352s 2s/step - loss: 1.4391 - accuracy: 0.6722 - val_loss: 1.4151 - val_accuracy: 0.6582\n",
      "Epoch 45/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.4366 - accuracy: 0.6731\n",
      "Epoch 00045: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 343s 2s/step - loss: 1.4366 - accuracy: 0.6731 - val_loss: 1.4309 - val_accuracy: 0.6549\n",
      "Epoch 46/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.4217 - accuracy: 0.6722\n",
      "Epoch 00046: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 360s 2s/step - loss: 1.4217 - accuracy: 0.6722 - val_loss: 1.3957 - val_accuracy: 0.6582\n",
      "Epoch 47/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.4267 - accuracy: 0.6756\n",
      "Epoch 00047: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 345s 2s/step - loss: 1.4267 - accuracy: 0.6756 - val_loss: 1.4001 - val_accuracy: 0.6717\n",
      "Epoch 48/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3833 - accuracy: 0.6948\n",
      "Epoch 00048: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 378s 2s/step - loss: 1.3833 - accuracy: 0.6948 - val_loss: 1.3675 - val_accuracy: 0.6633\n",
      "Epoch 49/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3844 - accuracy: 0.6872\n",
      "Epoch 00049: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 336s 2s/step - loss: 1.3844 - accuracy: 0.6872 - val_loss: 1.3570 - val_accuracy: 0.6599\n",
      "Epoch 50/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3841 - accuracy: 0.6865\n",
      "Epoch 00050: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 309s 2s/step - loss: 1.3841 - accuracy: 0.6865 - val_loss: 1.3521 - val_accuracy: 0.6650\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - ETA: 0s - loss: 1.3599 - accuracy: 0.6865\n",
      "Epoch 00051: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 322s 2s/step - loss: 1.3599 - accuracy: 0.6865 - val_loss: 1.3461 - val_accuracy: 0.6650\n",
      "Epoch 52/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3751 - accuracy: 0.6794\n",
      "Epoch 00052: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 340s 2s/step - loss: 1.3751 - accuracy: 0.6794 - val_loss: 1.3187 - val_accuracy: 0.6717\n",
      "Epoch 53/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3401 - accuracy: 0.6974\n",
      "Epoch 00053: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 340s 2s/step - loss: 1.3401 - accuracy: 0.6974 - val_loss: 1.3438 - val_accuracy: 0.6751\n",
      "Epoch 54/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3269 - accuracy: 0.6980\n",
      "Epoch 00054: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 352s 2s/step - loss: 1.3269 - accuracy: 0.6980 - val_loss: 1.3175 - val_accuracy: 0.6717\n",
      "Epoch 55/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3430 - accuracy: 0.6900\n",
      "Epoch 00055: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 338s 2s/step - loss: 1.3430 - accuracy: 0.6900 - val_loss: 1.3122 - val_accuracy: 0.6751\n",
      "Epoch 56/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3015 - accuracy: 0.7013\n",
      "Epoch 00056: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 333s 2s/step - loss: 1.3015 - accuracy: 0.7013 - val_loss: 1.3407 - val_accuracy: 0.6566\n",
      "Epoch 57/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3178 - accuracy: 0.6976\n",
      "Epoch 00057: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 326s 2s/step - loss: 1.3178 - accuracy: 0.6976 - val_loss: 1.3166 - val_accuracy: 0.6801\n",
      "Epoch 58/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2966 - accuracy: 0.6996\n",
      "Epoch 00058: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 318s 2s/step - loss: 1.2966 - accuracy: 0.6996 - val_loss: 1.2972 - val_accuracy: 0.6734\n",
      "Epoch 59/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2804 - accuracy: 0.7056\n",
      "Epoch 00059: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 323s 2s/step - loss: 1.2804 - accuracy: 0.7056 - val_loss: 1.2977 - val_accuracy: 0.6852\n",
      "Epoch 60/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2894 - accuracy: 0.7050\n",
      "Epoch 00060: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 359s 2s/step - loss: 1.2894 - accuracy: 0.7050 - val_loss: 1.2836 - val_accuracy: 0.6616\n",
      "Epoch 61/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2768 - accuracy: 0.6943\n",
      "Epoch 00061: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 336s 2s/step - loss: 1.2768 - accuracy: 0.6943 - val_loss: 1.2743 - val_accuracy: 0.6869\n",
      "Epoch 62/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2579 - accuracy: 0.7102\n",
      "Epoch 00062: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 323s 2s/step - loss: 1.2579 - accuracy: 0.7102 - val_loss: 1.3123 - val_accuracy: 0.6734\n",
      "Epoch 63/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2622 - accuracy: 0.7028\n",
      "Epoch 00063: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 310s 2s/step - loss: 1.2622 - accuracy: 0.7028 - val_loss: 1.2762 - val_accuracy: 0.6785\n",
      "Epoch 64/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2468 - accuracy: 0.7061\n",
      "Epoch 00064: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 319s 2s/step - loss: 1.2468 - accuracy: 0.7061 - val_loss: 1.2590 - val_accuracy: 0.6818\n",
      "Epoch 65/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2420 - accuracy: 0.7143\n",
      "Epoch 00065: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 316s 2s/step - loss: 1.2420 - accuracy: 0.7143 - val_loss: 1.2557 - val_accuracy: 0.6818\n",
      "Epoch 66/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2348 - accuracy: 0.7122\n",
      "Epoch 00066: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 343s 2s/step - loss: 1.2348 - accuracy: 0.7122 - val_loss: 1.2551 - val_accuracy: 0.6852\n",
      "Epoch 67/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2336 - accuracy: 0.7059\n",
      "Epoch 00067: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 317s 2s/step - loss: 1.2336 - accuracy: 0.7059 - val_loss: 1.2455 - val_accuracy: 0.6801\n",
      "Epoch 68/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2125 - accuracy: 0.7213\n",
      "Epoch 00068: val_accuracy did not improve from 0.68687\n",
      "169/169 [==============================] - 319s 2s/step - loss: 1.2125 - accuracy: 0.7213 - val_loss: 1.2546 - val_accuracy: 0.6801\n",
      "Epoch 69/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1907 - accuracy: 0.7257\n",
      "Epoch 00069: val_accuracy improved from 0.68687 to 0.69529, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.69-1.2355.hdf5\n",
      "169/169 [==============================] - 335s 2s/step - loss: 1.1907 - accuracy: 0.7257 - val_loss: 1.2355 - val_accuracy: 0.6953\n",
      "Epoch 70/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2031 - accuracy: 0.7211\n",
      "Epoch 00070: val_accuracy did not improve from 0.69529\n",
      "169/169 [==============================] - 344s 2s/step - loss: 1.2031 - accuracy: 0.7211 - val_loss: 1.2529 - val_accuracy: 0.6852\n",
      "Epoch 71/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.2137 - accuracy: 0.7178\n",
      "Epoch 00071: val_accuracy did not improve from 0.69529\n",
      "169/169 [==============================] - 345s 2s/step - loss: 1.2137 - accuracy: 0.7178 - val_loss: 1.2383 - val_accuracy: 0.6768\n",
      "Epoch 72/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1726 - accuracy: 0.7280\n",
      "Epoch 00072: val_accuracy did not improve from 0.69529\n",
      "169/169 [==============================] - 344s 2s/step - loss: 1.1726 - accuracy: 0.7280 - val_loss: 1.2410 - val_accuracy: 0.6869\n",
      "Epoch 73/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1861 - accuracy: 0.7307\n",
      "Epoch 00073: val_accuracy improved from 0.69529 to 0.69697, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.73-1.1960.hdf5\n",
      "169/169 [==============================] - 312s 2s/step - loss: 1.1861 - accuracy: 0.7307 - val_loss: 1.1960 - val_accuracy: 0.6970\n",
      "Epoch 74/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1752 - accuracy: 0.7235\n",
      "Epoch 00074: val_accuracy did not improve from 0.69697\n",
      "169/169 [==============================] - 386s 2s/step - loss: 1.1752 - accuracy: 0.7235 - val_loss: 1.2045 - val_accuracy: 0.6751\n",
      "Epoch 75/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1634 - accuracy: 0.7257\n",
      "Epoch 00075: val_accuracy did not improve from 0.69697\n",
      "169/169 [==============================] - 323s 2s/step - loss: 1.1634 - accuracy: 0.7257 - val_loss: 1.2298 - val_accuracy: 0.6650\n",
      "Epoch 76/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1750 - accuracy: 0.7220\n",
      "Epoch 00076: val_accuracy did not improve from 0.69697\n",
      "169/169 [==============================] - 351s 2s/step - loss: 1.1750 - accuracy: 0.7220 - val_loss: 1.1914 - val_accuracy: 0.6869\n",
      "Epoch 77/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1727 - accuracy: 0.7222\n",
      "Epoch 00077: val_accuracy did not improve from 0.69697\n",
      "169/169 [==============================] - 333s 2s/step - loss: 1.1727 - accuracy: 0.7222 - val_loss: 1.2052 - val_accuracy: 0.6801\n",
      "Epoch 78/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1433 - accuracy: 0.7346\n",
      "Epoch 00078: val_accuracy did not improve from 0.69697\n",
      "169/169 [==============================] - 339s 2s/step - loss: 1.1433 - accuracy: 0.7346 - val_loss: 1.2210 - val_accuracy: 0.6902\n",
      "Epoch 79/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1355 - accuracy: 0.7319\n",
      "Epoch 00079: val_accuracy improved from 0.69697 to 0.70202, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.79-1.1622.hdf5\n",
      "169/169 [==============================] - 318s 2s/step - loss: 1.1355 - accuracy: 0.7319 - val_loss: 1.1622 - val_accuracy: 0.7020\n",
      "Epoch 80/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1377 - accuracy: 0.7317\n",
      "Epoch 00080: val_accuracy did not improve from 0.70202\n",
      "169/169 [==============================] - 339s 2s/step - loss: 1.1377 - accuracy: 0.7317 - val_loss: 1.1912 - val_accuracy: 0.6869\n",
      "Epoch 81/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1178 - accuracy: 0.7428\n",
      "Epoch 00081: val_accuracy did not improve from 0.70202\n",
      "169/169 [==============================] - 310s 2s/step - loss: 1.1178 - accuracy: 0.7428 - val_loss: 1.1942 - val_accuracy: 0.6953\n",
      "Epoch 82/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1014 - accuracy: 0.7413\n",
      "Epoch 00082: val_accuracy improved from 0.70202 to 0.70539, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.82-1.1572.hdf5\n",
      "169/169 [==============================] - 327s 2s/step - loss: 1.1014 - accuracy: 0.7413 - val_loss: 1.1572 - val_accuracy: 0.7054\n",
      "Epoch 83/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1059 - accuracy: 0.7419\n",
      "Epoch 00083: val_accuracy improved from 0.70539 to 0.70707, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.83-1.1656.hdf5\n",
      "169/169 [==============================] - 358s 2s/step - loss: 1.1059 - accuracy: 0.7419 - val_loss: 1.1656 - val_accuracy: 0.7071\n",
      "Epoch 84/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1004 - accuracy: 0.7393\n",
      "Epoch 00084: val_accuracy did not improve from 0.70707\n",
      "169/169 [==============================] - 301s 2s/step - loss: 1.1004 - accuracy: 0.7393 - val_loss: 1.1843 - val_accuracy: 0.7054\n",
      "Epoch 85/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0982 - accuracy: 0.7396\n",
      "Epoch 00085: val_accuracy did not improve from 0.70707\n",
      "169/169 [==============================] - 337s 2s/step - loss: 1.0982 - accuracy: 0.7396 - val_loss: 1.1419 - val_accuracy: 0.7003\n",
      "Epoch 86/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0921 - accuracy: 0.7467\n",
      "Epoch 00086: val_accuracy did not improve from 0.70707\n",
      "169/169 [==============================] - 348s 2s/step - loss: 1.0921 - accuracy: 0.7467 - val_loss: 1.1606 - val_accuracy: 0.6936\n",
      "Epoch 87/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0834 - accuracy: 0.7463\n",
      "Epoch 00087: val_accuracy did not improve from 0.70707\n",
      "169/169 [==============================] - 311s 2s/step - loss: 1.0834 - accuracy: 0.7463 - val_loss: 1.1528 - val_accuracy: 0.7037\n",
      "Epoch 88/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0528 - accuracy: 0.7554\n",
      "Epoch 00088: val_accuracy improved from 0.70707 to 0.71044, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.88-1.1561.hdf5\n",
      "169/169 [==============================] - 350s 2s/step - loss: 1.0528 - accuracy: 0.7554 - val_loss: 1.1561 - val_accuracy: 0.7104\n",
      "Epoch 89/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0874 - accuracy: 0.7450\n",
      "Epoch 00089: val_accuracy did not improve from 0.71044\n",
      "169/169 [==============================] - 360s 2s/step - loss: 1.0874 - accuracy: 0.7450 - val_loss: 1.1618 - val_accuracy: 0.6902\n",
      "Epoch 90/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0585 - accuracy: 0.7474\n",
      "Epoch 00090: val_accuracy did not improve from 0.71044\n",
      "169/169 [==============================] - 327s 2s/step - loss: 1.0585 - accuracy: 0.7474 - val_loss: 1.1486 - val_accuracy: 0.6953\n",
      "Epoch 91/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0601 - accuracy: 0.7485\n",
      "Epoch 00091: val_accuracy did not improve from 0.71044\n",
      "169/169 [==============================] - 319s 2s/step - loss: 1.0601 - accuracy: 0.7485 - val_loss: 1.1274 - val_accuracy: 0.7003\n",
      "Epoch 92/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0644 - accuracy: 0.7478\n",
      "Epoch 00092: val_accuracy did not improve from 0.71044\n",
      "169/169 [==============================] - 327s 2s/step - loss: 1.0644 - accuracy: 0.7478 - val_loss: 1.1371 - val_accuracy: 0.7104\n",
      "Epoch 93/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0521 - accuracy: 0.7489\n",
      "Epoch 00093: val_accuracy did not improve from 0.71044\n",
      "169/169 [==============================] - 315s 2s/step - loss: 1.0521 - accuracy: 0.7489 - val_loss: 1.1359 - val_accuracy: 0.7054\n",
      "Epoch 94/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0388 - accuracy: 0.7652\n",
      "Epoch 00094: val_accuracy improved from 0.71044 to 0.71717, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.94-1.1098.hdf5\n",
      "169/169 [==============================] - 260s 2s/step - loss: 1.0388 - accuracy: 0.7652 - val_loss: 1.1098 - val_accuracy: 0.7172\n",
      "Epoch 95/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0291 - accuracy: 0.7565\n",
      "Epoch 00095: val_accuracy did not improve from 0.71717\n",
      "169/169 [==============================] - 271s 2s/step - loss: 1.0291 - accuracy: 0.7565 - val_loss: 1.1062 - val_accuracy: 0.7121\n",
      "Epoch 96/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.7674\n",
      "Epoch 00096: val_accuracy did not improve from 0.71717\n",
      "169/169 [==============================] - 258s 2s/step - loss: 1.0047 - accuracy: 0.7674 - val_loss: 1.1199 - val_accuracy: 0.6953\n",
      "Epoch 97/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0237 - accuracy: 0.7528\n",
      "Epoch 00097: val_accuracy did not improve from 0.71717\n",
      "169/169 [==============================] - 268s 2s/step - loss: 1.0237 - accuracy: 0.7528 - val_loss: 1.1103 - val_accuracy: 0.7155\n",
      "Epoch 98/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0293 - accuracy: 0.7596\n",
      "Epoch 00098: val_accuracy did not improve from 0.71717\n",
      "169/169 [==============================] - 230s 1s/step - loss: 1.0293 - accuracy: 0.7596 - val_loss: 1.1035 - val_accuracy: 0.7172\n",
      "Epoch 99/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0136 - accuracy: 0.7585\n",
      "Epoch 00099: val_accuracy did not improve from 0.71717\n",
      "169/169 [==============================] - 246s 1s/step - loss: 1.0136 - accuracy: 0.7585 - val_loss: 1.1182 - val_accuracy: 0.7121\n",
      "Epoch 100/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0012 - accuracy: 0.7607\n",
      "Epoch 00100: val_accuracy improved from 0.71717 to 0.71886, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.100-1.0931.hdf5\n",
      "169/169 [==============================] - 272s 2s/step - loss: 1.0012 - accuracy: 0.7607 - val_loss: 1.0931 - val_accuracy: 0.7189\n",
      "Epoch 101/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0023 - accuracy: 0.7715\n",
      "Epoch 00101: val_accuracy did not improve from 0.71886\n",
      "169/169 [==============================] - 229s 1s/step - loss: 1.0023 - accuracy: 0.7715 - val_loss: 1.1013 - val_accuracy: 0.7088\n",
      "Epoch 102/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9989 - accuracy: 0.7633\n",
      "Epoch 00102: val_accuracy improved from 0.71886 to 0.72054, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.102-1.1022.hdf5\n",
      "169/169 [==============================] - 248s 1s/step - loss: 0.9989 - accuracy: 0.7633 - val_loss: 1.1022 - val_accuracy: 0.7205\n",
      "Epoch 103/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9958 - accuracy: 0.7563\n",
      "Epoch 00103: val_accuracy did not improve from 0.72054\n",
      "169/169 [==============================] - 248s 1s/step - loss: 0.9958 - accuracy: 0.7563 - val_loss: 1.0901 - val_accuracy: 0.7172\n",
      "Epoch 104/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9898 - accuracy: 0.7652\n",
      "Epoch 00104: val_accuracy did not improve from 0.72054\n",
      "169/169 [==============================] - 227s 1s/step - loss: 0.9898 - accuracy: 0.7652 - val_loss: 1.0937 - val_accuracy: 0.7054\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - ETA: 0s - loss: 0.9762 - accuracy: 0.7704\n",
      "Epoch 00105: val_accuracy improved from 0.72054 to 0.72222, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.105-1.0844.hdf5\n",
      "169/169 [==============================] - 244s 1s/step - loss: 0.9762 - accuracy: 0.7704 - val_loss: 1.0844 - val_accuracy: 0.7222\n",
      "Epoch 106/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9657 - accuracy: 0.7811\n",
      "Epoch 00106: val_accuracy did not improve from 0.72222\n",
      "169/169 [==============================] - 246s 1s/step - loss: 0.9657 - accuracy: 0.7811 - val_loss: 1.0907 - val_accuracy: 0.7205\n",
      "Epoch 107/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9789 - accuracy: 0.7667\n",
      "Epoch 00107: val_accuracy did not improve from 0.72222\n",
      "169/169 [==============================] - 238s 1s/step - loss: 0.9789 - accuracy: 0.7667 - val_loss: 1.1067 - val_accuracy: 0.7104\n",
      "Epoch 108/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9727 - accuracy: 0.7722\n",
      "Epoch 00108: val_accuracy improved from 0.72222 to 0.72391, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.108-1.0799.hdf5\n",
      "169/169 [==============================] - 224s 1s/step - loss: 0.9727 - accuracy: 0.7722 - val_loss: 1.0799 - val_accuracy: 0.7239\n",
      "Epoch 109/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9717 - accuracy: 0.7670\n",
      "Epoch 00109: val_accuracy did not improve from 0.72391\n",
      "169/169 [==============================] - 238s 1s/step - loss: 0.9717 - accuracy: 0.7670 - val_loss: 1.0998 - val_accuracy: 0.7037\n",
      "Epoch 110/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9754 - accuracy: 0.7637\n",
      "Epoch 00110: val_accuracy improved from 0.72391 to 0.72896, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.110-1.0805.hdf5\n",
      "169/169 [==============================] - 250s 1s/step - loss: 0.9754 - accuracy: 0.7637 - val_loss: 1.0805 - val_accuracy: 0.7290\n",
      "Epoch 111/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9479 - accuracy: 0.7739\n",
      "Epoch 00111: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 234s 1s/step - loss: 0.9479 - accuracy: 0.7739 - val_loss: 1.0811 - val_accuracy: 0.7155\n",
      "Epoch 112/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9344 - accuracy: 0.7802\n",
      "Epoch 00112: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 225s 1s/step - loss: 0.9344 - accuracy: 0.7802 - val_loss: 1.0431 - val_accuracy: 0.7172\n",
      "Epoch 113/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.7794\n",
      "Epoch 00113: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 242s 1s/step - loss: 0.9368 - accuracy: 0.7794 - val_loss: 1.0735 - val_accuracy: 0.7155\n",
      "Epoch 114/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9468 - accuracy: 0.7750\n",
      "Epoch 00114: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 254s 2s/step - loss: 0.9468 - accuracy: 0.7750 - val_loss: 1.0994 - val_accuracy: 0.7088\n",
      "Epoch 115/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9403 - accuracy: 0.7752\n",
      "Epoch 00115: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 260s 2s/step - loss: 0.9403 - accuracy: 0.7752 - val_loss: 1.0483 - val_accuracy: 0.7239\n",
      "Epoch 116/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9232 - accuracy: 0.7800\n",
      "Epoch 00116: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 206s 1s/step - loss: 0.9232 - accuracy: 0.7800 - val_loss: 1.0747 - val_accuracy: 0.7121\n",
      "Epoch 117/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9379 - accuracy: 0.7754\n",
      "Epoch 00117: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 219s 1s/step - loss: 0.9379 - accuracy: 0.7754 - val_loss: 1.0686 - val_accuracy: 0.7239\n",
      "Epoch 118/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9086 - accuracy: 0.7863\n",
      "Epoch 00118: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 241s 1s/step - loss: 0.9086 - accuracy: 0.7863 - val_loss: 1.0504 - val_accuracy: 0.7205\n",
      "Epoch 119/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9135 - accuracy: 0.7787\n",
      "Epoch 00119: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 258s 2s/step - loss: 0.9135 - accuracy: 0.7787 - val_loss: 1.0415 - val_accuracy: 0.7273\n",
      "Epoch 120/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9066 - accuracy: 0.7857\n",
      "Epoch 00120: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 239s 1s/step - loss: 0.9066 - accuracy: 0.7857 - val_loss: 1.0300 - val_accuracy: 0.7222\n",
      "Epoch 121/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8989 - accuracy: 0.7896\n",
      "Epoch 00121: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 256s 2s/step - loss: 0.8989 - accuracy: 0.7896 - val_loss: 1.0735 - val_accuracy: 0.7256\n",
      "Epoch 122/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9103 - accuracy: 0.7813\n",
      "Epoch 00122: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 250s 1s/step - loss: 0.9103 - accuracy: 0.7813 - val_loss: 1.0642 - val_accuracy: 0.7189\n",
      "Epoch 123/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8965 - accuracy: 0.7819\n",
      "Epoch 00123: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 222s 1s/step - loss: 0.8965 - accuracy: 0.7819 - val_loss: 1.0364 - val_accuracy: 0.7239\n",
      "Epoch 124/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8771 - accuracy: 0.7885\n",
      "Epoch 00124: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 248s 1s/step - loss: 0.8771 - accuracy: 0.7885 - val_loss: 1.0386 - val_accuracy: 0.7104\n",
      "Epoch 125/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8933 - accuracy: 0.7861\n",
      "Epoch 00125: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 251s 1s/step - loss: 0.8933 - accuracy: 0.7861 - val_loss: 1.0535 - val_accuracy: 0.7290\n",
      "Epoch 126/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8887 - accuracy: 0.7863\n",
      "Epoch 00126: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 258s 2s/step - loss: 0.8887 - accuracy: 0.7863 - val_loss: 1.0339 - val_accuracy: 0.7138\n",
      "Epoch 127/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8714 - accuracy: 0.7993\n",
      "Epoch 00127: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 231s 1s/step - loss: 0.8714 - accuracy: 0.7993 - val_loss: 1.0558 - val_accuracy: 0.7189\n",
      "Epoch 128/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8755 - accuracy: 0.7878\n",
      "Epoch 00128: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 251s 1s/step - loss: 0.8755 - accuracy: 0.7878 - val_loss: 1.0642 - val_accuracy: 0.7121\n",
      "Epoch 129/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8565 - accuracy: 0.8017\n",
      "Epoch 00129: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 212s 1s/step - loss: 0.8565 - accuracy: 0.8017 - val_loss: 1.0281 - val_accuracy: 0.7138\n",
      "Epoch 130/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8833 - accuracy: 0.7863\n",
      "Epoch 00130: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 237s 1s/step - loss: 0.8833 - accuracy: 0.7863 - val_loss: 1.0512 - val_accuracy: 0.7121\n",
      "Epoch 131/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8602 - accuracy: 0.7948\n",
      "Epoch 00131: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 236s 1s/step - loss: 0.8602 - accuracy: 0.7948 - val_loss: 1.0294 - val_accuracy: 0.7290\n",
      "Epoch 132/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8685 - accuracy: 0.7917\n",
      "Epoch 00132: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 270s 2s/step - loss: 0.8685 - accuracy: 0.7917 - val_loss: 1.0370 - val_accuracy: 0.7088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8575 - accuracy: 0.7969\n",
      "Epoch 00133: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 264s 2s/step - loss: 0.8575 - accuracy: 0.7969 - val_loss: 0.9919 - val_accuracy: 0.7290\n",
      "Epoch 134/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8774 - accuracy: 0.7896\n",
      "Epoch 00134: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 228s 1s/step - loss: 0.8774 - accuracy: 0.7896 - val_loss: 1.0416 - val_accuracy: 0.7273\n",
      "Epoch 135/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8659 - accuracy: 0.7919\n",
      "Epoch 00135: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 241s 1s/step - loss: 0.8659 - accuracy: 0.7919 - val_loss: 1.0475 - val_accuracy: 0.7138\n",
      "Epoch 136/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8453 - accuracy: 0.7987\n",
      "Epoch 00136: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 236s 1s/step - loss: 0.8453 - accuracy: 0.7987 - val_loss: 1.0170 - val_accuracy: 0.7189\n",
      "Epoch 137/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8584 - accuracy: 0.7922\n",
      "Epoch 00137: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 217s 1s/step - loss: 0.8584 - accuracy: 0.7922 - val_loss: 1.0217 - val_accuracy: 0.7239\n",
      "Epoch 138/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8286 - accuracy: 0.8046\n",
      "Epoch 00138: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 248s 1s/step - loss: 0.8286 - accuracy: 0.8046 - val_loss: 1.0242 - val_accuracy: 0.7290\n",
      "Epoch 139/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8273 - accuracy: 0.8031\n",
      "Epoch 00139: val_accuracy did not improve from 0.72896\n",
      "169/169 [==============================] - 245s 1s/step - loss: 0.8273 - accuracy: 0.8031 - val_loss: 1.0350 - val_accuracy: 0.7290\n",
      "Epoch 140/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8334 - accuracy: 0.8037\n",
      "Epoch 00140: val_accuracy improved from 0.72896 to 0.73064, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.140-1.0354.hdf5\n",
      "169/169 [==============================] - 228s 1s/step - loss: 0.8334 - accuracy: 0.8037 - val_loss: 1.0354 - val_accuracy: 0.7306\n",
      "Epoch 141/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8299 - accuracy: 0.7961\n",
      "Epoch 00141: val_accuracy did not improve from 0.73064\n",
      "169/169 [==============================] - 292s 2s/step - loss: 0.8299 - accuracy: 0.7961 - val_loss: 1.0167 - val_accuracy: 0.7239\n",
      "Epoch 142/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8260 - accuracy: 0.8028\n",
      "Epoch 00142: val_accuracy did not improve from 0.73064\n",
      "169/169 [==============================] - 235s 1s/step - loss: 0.8260 - accuracy: 0.8028 - val_loss: 0.9913 - val_accuracy: 0.7290\n",
      "Epoch 143/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.7995 - accuracy: 0.8156\n",
      "Epoch 00143: val_accuracy did not improve from 0.73064\n",
      "169/169 [==============================] - 227s 1s/step - loss: 0.7995 - accuracy: 0.8156 - val_loss: 1.0102 - val_accuracy: 0.7273\n",
      "Epoch 144/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8089 - accuracy: 0.8061\n",
      "Epoch 00144: val_accuracy did not improve from 0.73064\n",
      "169/169 [==============================] - 266s 2s/step - loss: 0.8089 - accuracy: 0.8061 - val_loss: 1.0173 - val_accuracy: 0.7273\n",
      "Epoch 145/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8092 - accuracy: 0.8044\n",
      "Epoch 00145: val_accuracy did not improve from 0.73064\n",
      "169/169 [==============================] - 218s 1s/step - loss: 0.8092 - accuracy: 0.8044 - val_loss: 1.0221 - val_accuracy: 0.7172\n",
      "Epoch 146/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8036 - accuracy: 0.8076\n",
      "Epoch 00146: val_accuracy improved from 0.73064 to 0.73906, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.146-0.9855.hdf5\n",
      "169/169 [==============================] - 234s 1s/step - loss: 0.8036 - accuracy: 0.8076 - val_loss: 0.9855 - val_accuracy: 0.7391\n",
      "Epoch 147/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.7935 - accuracy: 0.8174\n",
      "Epoch 00147: val_accuracy did not improve from 0.73906\n",
      "169/169 [==============================] - 226s 1s/step - loss: 0.7935 - accuracy: 0.8174 - val_loss: 1.0201 - val_accuracy: 0.7205\n",
      "Epoch 148/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.7938 - accuracy: 0.8124\n",
      "Epoch 00148: val_accuracy did not improve from 0.73906\n",
      "169/169 [==============================] - 278s 2s/step - loss: 0.7938 - accuracy: 0.8124 - val_loss: 0.9708 - val_accuracy: 0.7357\n",
      "Epoch 149/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8065 - accuracy: 0.8111\n",
      "Epoch 00149: val_accuracy improved from 0.73906 to 0.74747, saving model to ./trained_weights/efficientnet/CUB200/standard\\model_fine_tune.149-0.9963.hdf5\n",
      "169/169 [==============================] - 245s 1s/step - loss: 0.8065 - accuracy: 0.8111 - val_loss: 0.9963 - val_accuracy: 0.7475\n",
      "Epoch 150/150\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8020 - accuracy: 0.8074\n",
      "Epoch 00150: val_accuracy did not improve from 0.74747\n",
      "169/169 [==============================] - 242s 1s/step - loss: 0.8020 - accuracy: 0.8074 - val_loss: 1.0059 - val_accuracy: 0.7256\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% Trains for 5 epochs.\n",
    "if args.train_using_builtin_fit_method:\n",
    "    model.trainable = True\n",
    "    model.compile(optimizer=optimizers.SGD(lr=0.001/10, momentum = 0.9), \n",
    "                  loss=[categorical_crossentropy], \n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    model.load_weights(filepath=weights_path+'/model_transfer_epoch_50.hdf5')\n",
    "    \n",
    "    #%%\n",
    "    save_path=weights_path+'/model_fine_tune.{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(save_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_weights_only = True)\n",
    "    callbacks_list = [checkpoint]\n",
    "    #%%\n",
    "    history = model.fit(train_gen, epochs=150, verbose=1, callbacks=callbacks_list, validation_data=test_gen, shuffle=True)\n",
    "    \n",
    "    plt.style.use('seaborn')\n",
    "    #plt.style.available\n",
    "    #['fivethirtyeight',\n",
    "     #'seaborn-pastel',\n",
    "     #'seaborn-whitegrid',\n",
    "     #'ggplot',\n",
    "     #'grayscale']\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    #plt.savefig(fname='model_accuracy_'+db+'.png')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    #plt.savefig(fname='model_loss_'+db+'.png')\n",
    "    \n",
    "    #%% stop execution\n",
    "    #sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath=weights_path+\"/model_fine_tune_epoch_150.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "papermill": {
     "duration": 7.678019,
     "end_time": "2020-12-02T09:00:50.963669",
     "exception": false,
     "start_time": "2020-12-02T09:00:43.285650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 24s 132ms/step\n",
      "[[23  1  4 ...  0  0  0]\n",
      " [ 0 24  0 ...  0  0  0]\n",
      " [ 0  2 23 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 24  0  0]\n",
      " [ 0  0  0 ...  0 23  0]\n",
      " [ 0  0  0 ...  0  0 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81        30\n",
      "           1       0.77      0.80      0.79        30\n",
      "           2       0.70      0.82      0.75        28\n",
      "           3       0.65      0.87      0.74        30\n",
      "           4       0.86      0.86      0.86        14\n",
      "           5       0.82      0.82      0.82        11\n",
      "           6       0.92      0.96      0.94        23\n",
      "           7       0.65      0.83      0.73        18\n",
      "           8       0.38      0.31      0.34        29\n",
      "           9       0.96      0.83      0.89        30\n",
      "          10       0.74      0.47      0.57        30\n",
      "          11       1.00      0.92      0.96        26\n",
      "          12       0.96      0.83      0.89        30\n",
      "          13       0.87      0.90      0.89        30\n",
      "          14       0.89      0.86      0.87        28\n",
      "          15       0.92      0.86      0.89        28\n",
      "          16       0.92      0.89      0.91        27\n",
      "          17       1.00      1.00      1.00        15\n",
      "          18       0.84      0.90      0.87        29\n",
      "          19       0.89      0.83      0.86        29\n",
      "          20       0.97      0.97      0.97        30\n",
      "          21       0.73      0.73      0.73        26\n",
      "          22       0.63      0.66      0.64        29\n",
      "          23       0.86      0.86      0.86        22\n",
      "          24       0.67      0.53      0.59        30\n",
      "          25       0.88      0.73      0.80        30\n",
      "          26       0.53      0.57      0.55        30\n",
      "          27       0.96      0.79      0.87        29\n",
      "          28       0.33      0.43      0.38        30\n",
      "          29       0.38      0.33      0.36        30\n",
      "          30       0.90      0.63      0.75        30\n",
      "          31       0.71      0.65      0.68        23\n",
      "          32       0.68      0.79      0.73        29\n",
      "          33       0.92      0.83      0.87        29\n",
      "          34       0.78      0.93      0.85        30\n",
      "          35       0.93      0.93      0.93        30\n",
      "          36       0.38      0.38      0.38        29\n",
      "          37       0.68      0.63      0.66        30\n",
      "          38       0.25      0.34      0.29        29\n",
      "          39       0.84      0.53      0.65        30\n",
      "          40       0.76      0.83      0.79        30\n",
      "          41       0.96      0.87      0.91        30\n",
      "          42       0.61      0.38      0.47        29\n",
      "          43       0.86      0.83      0.85        30\n",
      "          44       0.81      0.73      0.77        30\n",
      "          45       0.61      0.93      0.74        30\n",
      "          46       0.90      0.87      0.88        30\n",
      "          47       0.97      0.93      0.95        30\n",
      "          48       0.62      0.53      0.57        30\n",
      "          49       0.65      0.87      0.74        30\n",
      "          50       0.83      0.50      0.62        30\n",
      "          51       0.83      0.80      0.81        30\n",
      "          52       1.00      1.00      1.00        30\n",
      "          53       0.83      0.83      0.83        30\n",
      "          54       1.00      0.87      0.93        30\n",
      "          55       0.76      0.73      0.75        30\n",
      "          56       1.00      0.93      0.97        30\n",
      "          57       0.81      0.79      0.80        28\n",
      "          58       0.40      0.07      0.11        30\n",
      "          59       0.41      0.52      0.45        29\n",
      "          60       0.91      1.00      0.95        30\n",
      "          61       0.25      0.17      0.20        30\n",
      "          62       0.89      0.80      0.84        30\n",
      "          63       0.50      0.63      0.56        30\n",
      "          64       0.50      0.30      0.37        20\n",
      "          65       0.41      0.70      0.52        30\n",
      "          66       0.84      0.53      0.65        30\n",
      "          67       0.59      0.80      0.68        30\n",
      "          68       0.92      0.73      0.81        30\n",
      "          69       0.91      1.00      0.95        30\n",
      "          70       0.43      0.33      0.38        30\n",
      "          71       0.50      0.37      0.42        30\n",
      "          72       0.96      0.87      0.91        30\n",
      "          73       0.75      1.00      0.86        30\n",
      "          74       1.00      0.93      0.96        27\n",
      "          75       0.62      0.93      0.75        30\n",
      "          76       0.84      0.70      0.76        30\n",
      "          77       0.74      0.90      0.81        29\n",
      "          78       0.77      0.80      0.79        30\n",
      "          79       0.96      0.73      0.83        30\n",
      "          80       0.87      0.87      0.87        30\n",
      "          81       0.71      0.80      0.75        30\n",
      "          82       1.00      0.93      0.97        30\n",
      "          83       0.83      0.83      0.83        23\n",
      "          84       0.93      0.83      0.88        30\n",
      "          85       0.79      0.90      0.84        30\n",
      "          86       0.88      0.73      0.80        30\n",
      "          87       0.93      0.83      0.88        30\n",
      "          88       0.96      0.80      0.87        30\n",
      "          89       0.84      0.87      0.85        30\n",
      "          90       0.60      0.60      0.60        30\n",
      "          91       0.84      0.87      0.85        30\n",
      "          92       0.85      0.93      0.89        30\n",
      "          93       0.97      0.93      0.95        30\n",
      "          94       0.86      0.80      0.83        30\n",
      "          95       0.95      0.70      0.81        30\n",
      "          96       0.85      0.76      0.80        29\n",
      "          97       0.89      0.83      0.86        30\n",
      "          98       0.69      0.60      0.64        30\n",
      "          99       0.88      1.00      0.94        30\n",
      "         100       0.76      0.95      0.84        20\n",
      "         101       0.29      0.43      0.35        30\n",
      "         102       0.38      0.67      0.49        30\n",
      "         103       0.79      0.73      0.76        30\n",
      "         104       0.65      0.68      0.67        19\n",
      "         105       1.00      0.87      0.93        30\n",
      "         106       0.38      0.47      0.42        30\n",
      "         107       0.85      0.73      0.79        30\n",
      "         108       0.93      0.83      0.88        30\n",
      "         109       0.73      1.00      0.85        30\n",
      "         110       0.68      0.63      0.66        30\n",
      "         111       0.64      0.70      0.67        30\n",
      "         112       0.54      0.65      0.59        20\n",
      "         113       0.86      0.83      0.85        30\n",
      "         114       0.44      0.41      0.43        29\n",
      "         115       0.32      0.27      0.29        30\n",
      "         116       0.52      0.45      0.48        29\n",
      "         117       0.61      0.37      0.46        30\n",
      "         118       0.64      0.55      0.59        29\n",
      "         119       0.94      0.53      0.68        30\n",
      "         120       0.67      0.67      0.67        30\n",
      "         121       0.92      0.77      0.84        30\n",
      "         122       0.61      0.57      0.59        30\n",
      "         123       0.69      0.69      0.69        29\n",
      "         124       0.59      0.69      0.63        29\n",
      "         125       0.77      0.67      0.71        30\n",
      "         126       0.47      0.60      0.53        30\n",
      "         127       0.58      0.83      0.68        30\n",
      "         128       0.81      0.43      0.57        30\n",
      "         129       0.43      0.50      0.46        30\n",
      "         130       0.51      0.63      0.57        30\n",
      "         131       0.84      0.87      0.85        30\n",
      "         132       0.92      0.80      0.86        30\n",
      "         133       0.90      0.93      0.92        30\n",
      "         134       0.75      0.50      0.60        30\n",
      "         135       0.68      0.63      0.66        30\n",
      "         136       0.58      0.60      0.59        30\n",
      "         137       0.95      0.67      0.78        30\n",
      "         138       0.79      0.87      0.83        30\n",
      "         139       0.81      0.97      0.88        30\n",
      "         140       0.56      0.69      0.62        29\n",
      "         141       0.52      0.73      0.61        30\n",
      "         142       0.65      0.50      0.57        30\n",
      "         143       0.33      0.30      0.32        30\n",
      "         144       0.41      0.43      0.42        30\n",
      "         145       0.44      0.37      0.40        30\n",
      "         146       0.62      0.83      0.71        30\n",
      "         147       0.87      0.87      0.87        30\n",
      "         148       0.88      0.72      0.79        29\n",
      "         149       0.77      0.80      0.79        30\n",
      "         150       0.83      0.95      0.89        21\n",
      "         151       0.71      0.73      0.72        30\n",
      "         152       0.50      0.55      0.52        29\n",
      "         153       0.80      0.67      0.73        30\n",
      "         154       0.40      0.57      0.47        30\n",
      "         155       0.50      0.77      0.61        30\n",
      "         156       0.64      0.62      0.63        29\n",
      "         157       0.83      0.80      0.81        30\n",
      "         158       0.97      0.97      0.97        30\n",
      "         159       0.93      0.93      0.93        29\n",
      "         160       0.54      0.63      0.58        30\n",
      "         161       0.81      0.70      0.75        30\n",
      "         162       0.79      0.63      0.70        30\n",
      "         163       0.93      0.93      0.93        30\n",
      "         164       0.96      0.80      0.87        30\n",
      "         165       0.96      0.90      0.93        29\n",
      "         166       0.75      0.60      0.67        30\n",
      "         167       0.71      0.86      0.78        29\n",
      "         168       0.87      0.90      0.88        29\n",
      "         169       0.86      0.80      0.83        30\n",
      "         170       0.87      0.67      0.75        30\n",
      "         171       0.67      0.73      0.70        30\n",
      "         172       0.43      0.63      0.51        30\n",
      "         173       0.71      0.67      0.69        30\n",
      "         174       0.60      0.60      0.60        30\n",
      "         175       0.74      0.67      0.70        30\n",
      "         176       0.84      0.90      0.87        30\n",
      "         177       0.76      0.62      0.68        26\n",
      "         178       0.39      0.52      0.45        29\n",
      "         179       0.61      0.83      0.70        30\n",
      "         180       0.95      0.72      0.82        29\n",
      "         181       0.69      0.83      0.76        30\n",
      "         182       0.63      0.80      0.71        30\n",
      "         183       0.78      0.83      0.81        30\n",
      "         184       0.77      0.90      0.83        30\n",
      "         185       0.83      0.83      0.83        30\n",
      "         186       0.85      0.85      0.85        20\n",
      "         187       1.00      0.97      0.98        30\n",
      "         188       0.88      0.97      0.92        30\n",
      "         189       0.87      0.90      0.88        29\n",
      "         190       0.96      0.87      0.91        30\n",
      "         191       0.97      0.93      0.95        30\n",
      "         192       0.53      0.57      0.55        30\n",
      "         193       0.92      0.80      0.86        30\n",
      "         194       0.71      0.73      0.72        30\n",
      "         195       0.58      0.63      0.60        30\n",
      "         196       0.87      0.67      0.75        30\n",
      "         197       0.77      0.80      0.79        30\n",
      "         198       0.74      0.77      0.75        30\n",
      "         199       0.96      0.87      0.91        30\n",
      "\n",
      "    accuracy                           0.73      5794\n",
      "   macro avg       0.75      0.73      0.73      5794\n",
      "weighted avg       0.74      0.73      0.73      5794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test accuracy on unseen data\n",
    "if args.dataset == 'CUB200' and official_split:\n",
    "    #load best weights\n",
    "    model.load_weights(filepath=weights_path+'/model_fine_tune.149-0.9963.hdf5')\n",
    "    #model.load_weights(filepath=weights_path+'/model_fine_tune_epoch_150.hdf5')\n",
    "    \n",
    "    #model.evaluate(actual_test_gen,verbose=1)\n",
    "     \n",
    "    pred_probs= model.predict(actual_test_gen,verbose=1)\n",
    "    \n",
    "    pred_classes = np.argmax(pred_probs,1)\n",
    "    #actual_classes = np.argmax(test_gen.classes,1)\n",
    "    actual_classes = actual_test_gen.classes\n",
    "    print(confusion_matrix(actual_classes,pred_classes))\n",
    "    print(classification_report(actual_classes,pred_classes)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(actual_test_gen,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-02T09:01:05.954641Z",
     "iopub.status.busy": "2020-12-02T09:01:05.951393Z",
     "iopub.status.idle": "2020-12-02T09:01:05.958062Z",
     "shell.execute_reply": "2020-12-02T09:01:05.957242Z"
    },
    "papermill": {
     "duration": 7.555548,
     "end_time": "2020-12-02T09:01:05.958208",
     "exception": false,
     "start_time": "2020-12-02T09:00:58.402660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('./trained_weights'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 11667.954103,
   "end_time": "2020-12-02T09:01:14.885863",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-02T05:46:46.931760",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
